<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-07-05 Tue 08:52 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AI Introduction</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/white.css" />
</head>
<body>
<div id="content" class="content">
<h1 class="title">AI Introduction</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgefacd02">1. 和AI聊聊天</a>
<ul>
<li><a href="#orge936ce6">1.1. ELIZA</a></li>
<li><a href="#org6baba3b">1.2. ALICE</a></li>
<li><a href="#org7f6d91d">1.3. Mitsuku</a></li>
</ul>
</li>
<li><a href="#org75460c4">2. AI, Machine Learning與Deep Learning</a>
<ul>
<li><a href="#orgf9a9d2c">2.1. AI與早期專家系統的差異</a></li>
<li><a href="#orgdc11413">2.2. AI</a></li>
<li><a href="#orga67dd11">2.3. 機器學習</a></li>
<li><a href="#org7bc4a04">2.4. 類神經網路與深度學習</a></li>
<li><a href="#orgcd294ee">2.5. 深度學習</a></li>
<li><a href="#org3dd825e">2.6. Deep Learning 的概念於 2006 年提出，何以至 2012 年才得到有效應用？</a></li>
</ul>
</li>
<li><a href="#org1bbe1fb">3. AI的發展沿革</a>
<ul>
<li><a href="#org7b5a9d4">3.1. 三個里程碑</a></li>
<li><a href="#orge481465">3.2. AI 發展的起落</a></li>
<li><a href="#org7950b24">3.3. AI Development 大事記</a></li>
<li><a href="#org68fa0bf">3.4. AI 應用與影響</a></li>
</ul>
</li>
<li><a href="#orgee8c3e5">4. AI 的三大學派</a>
<ul>
<li><a href="#org409bf37">4.1. 符號主義學派(知識圖譜: 模仿人類邏輯與抽像推理),</a></li>
<li><a href="#orgfc40e8e">4.2. 連接主義學派(深度學習: 模仿大腦皮層神經網路)</a></li>
<li><a href="#orgc2b3a9f">4.3. 行為主義學派(強化學習: 模仿生物奬懲學習機制)</a></li>
</ul>
</li>
<li><a href="#org732149b">5. AI 的五大迷思</a>
<ul>
<li><a href="#orgd3234c7">5.1. 迷思一：資料等於價值</a></li>
<li><a href="#org05a2ef2">5.2. 迷思二：牽涉電腦與資料就是 MIS 部門的工作</a></li>
<li><a href="#org1f542c3">5.3. 迷思三：資料分析就是產出報表</a></li>
<li><a href="#org2f937ff">5.4. 迷思四：電腦決策不可能贏過人的專業經驗</a></li>
<li><a href="#orgef95bdf">5.5. 迷思五：導入系統或平台就可以解決營運問題</a></li>
</ul>
</li>
<li><a href="#org73bf51f">6. AI 擅長的解題領域</a>
<ul>
<li><a href="#org5bc4c21">6.1. 與情境無關的領域</a></li>
<li><a href="#orga278fc9">6.2. 樣本數多的領域</a></li>
</ul>
</li>
<li><a href="#org03ad3a0">7. AI 各項產業應用</a>
<ul>
<li><a href="#org285be1b">7.1. 製造業</a></li>
<li><a href="#org1629aa8">7.2. 零售與金融業</a></li>
</ul>
</li>
<li><a href="#org4ea5d89">8. AI v.s. security</a>
<ul>
<li><a href="#orge43c91d">8.1. 釣魚網站偵測實戰</a></li>
<li><a href="#orga9f2d00">8.2. Text Classification</a></li>
<li><a href="#org336b4ae">8.3. AI and Botnet Detection</a></li>
</ul>
</li>
<li><a href="#org0c1290f">9. AI 的學習之路</a>
<ul>
<li><a href="#orge50ca60">9.1. About 學習 AI</a></li>
<li><a href="#orgd728c51">9.2. AI Application Ideas</a></li>
<li><a href="#orga0c5395">9.3. 相關的比賽</a></li>
<li><a href="#org968ee42">9.4. AI 時代的 I</a></li>
<li><a href="#org907d92f">9.5. 學習資源</a></li>
</ul>
</li>
<li><a href="#org465a292">10. AI 的實作平台</a>
<ul>
<li><a href="#org64284f9">10.1. Google Colab</a></li>
<li><a href="#orgea0bd45">10.2. Jupyter Notebook</a></li>
</ul>
</li>
<li><a href="#orgb19b313">11. 學習資源</a>
<ul>
<li><a href="#org116e180">11.1. Machine Learning [台大李宏毅]</a></li>
<li><a href="#orga5a544c">11.2. Deep Learning for Human Language Processing (DLHLP) 2020</a></li>
<li><a href="#org0c2470a">11.3. Digital Speech Processing</a></li>
<li><a href="#org645587e">11.4. test</a></li>
</ul>
</li>
</ul>
</div>
</div>


<div id="outline-container-orgefacd02" class="outline-2">
<h2 id="orgefacd02"><span class="section-number-2">1.</span> 和AI聊聊天</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-orge936ce6" class="outline-3">
<h3 id="orge936ce6"><span class="section-number-3">1.1.</span> ELIZA</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/ELIZA#cite_note-turing-1">What is it</a><br /></li>
<li><a href="https://web.njit.edu/~ronkowit/eliza.html">web-based version</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org6baba3b" class="outline-3">
<h3 id="org6baba3b"><span class="section-number-3">1.2.</span> ALICE</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Artificial_Linguistic_Internet_Computer_Entity">About ALICE</a><br /></li>
<li><a href="http://www.mfellmann.net/content/alice.html">web-based version</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org7f6d91d" class="outline-3">
<h3 id="org7f6d91d"><span class="section-number-3">1.3.</span> Mitsuku</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Mitsuku">About Mitsuku</a><br /></li>
<li><a href="https://chat.kuki.ai/">Try it</a><br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org75460c4" class="outline-2">
<h2 id="org75460c4"><span class="section-number-2">2.</span> AI, <a href="MachineLearning.html">Machine Learning</a>與<a href="DeepLearning.html">Deep Learning</a></h2>
<div class="outline-text-2" id="text-2">
<p>
人工智慧、機器學習與深度學習是三個常被混為一談的概念，如圖<a href="#orgb9dcb36">1</a>，深度學習是機器學習的一種類型，而機器學習又是人工智慧的一個分支，相較於機器學習，早期實作人工智慧的一種策略是專家系統(Expert System)。<br />
</p>

<div id="orgb9dcb36" class="figure">
<p><img src="images/AMD.png" alt="AMD.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 1: </span>AI, Machine, Deep Learning</p>
</div>
</div>

<div id="outline-container-orgf9a9d2c" class="outline-3">
<h3 id="orgf9a9d2c"><span class="section-number-3">2.1.</span> AI與早期專家系統的差異</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>專家系統:由人訂規則，告訴電腦判別的方法：狗鼻子較長、耳朵較大&#x2026;<br /></li>
<li><a href="MachineLearning.html">機器學習</a>:給電腦大量標註貓狗的照片，由<a href="MachineLearning.html">機器學習</a>演算法自行歸納辨別二者的方法。<br /></li>
</ul>
</div>
</div>

<div id="outline-container-orgdc11413" class="outline-3">
<h3 id="orgdc11413"><span class="section-number-3">2.2.</span> AI</h3>
<div class="outline-text-3" id="text-2-2">
<p>
AI是一個涵蓋面極廣的名詞，從1964年<a href="https://en.wikipedia.org/wiki/MIT_Computer_Science_and_Artificial_Intelligence_Laboratory">MIT AI Lab</a>的<a href="https://web.njit.edu/~ronkowit/eliza.html">ELIZA</a>對話機器人，到最近的自駕車，再到科幻電影中俱備人類情感的機器人都可以是AI的範圍。在實作上，AI 可以是簡單的 decision tree 或 rule-based 的專家系統(知識庫 + 推理機制)，也可以是包含數十億神經元的類神經網路。那麼，這和我們常聽到的機器學習、深度學習、神經網絡又有什麼關係呢？<br />
</p>
</div>
</div>

<div id="outline-container-orga67dd11" class="outline-3">
<h3 id="orga67dd11"><span class="section-number-3">2.3.</span> 機器學習</h3>
<div class="outline-text-3" id="text-2-3">
<p>
在AI的發展中，人們想過以各種方式來達成讓機器具備人類智慧的目的，有人希望能將大量的人類智慧教給電腦，這部份包含了人類在各領域的知識以及推理規則；另一派學者則認為人類的智識大過於廣泛而且不斷的有新知識生成，與其把所有的知識教給電腦，不如讓電腦具備學習的能力，如此電腦就可以自己去學習新的知識，這便是所謂的機器學習。<br />
</p>

<p>
在開發機器學習模型時，我們會基於觀測值計算出一些衍生變數(derived variables)，再將其加入決策判斷的條件中，以增加 model 的預測準確度。例如，由男生的身高體重判斷高血壓的機率，而 BMI 即為一更佳的衍生變數。而<a href="MachineLearning.html">機器學習</a>模型的成效往往取決於特徵工程的品質，但在某些領域下，特徵工程很難靠領域專家取得好的結果，例如非結構化資料以及序列資料：<br />
</p>
<ul class="org-ul">
<li>非結構化資料：聲音、影像、影片<br /></li>
<li>序列資料：sensor 資料、金融市場資料、交易資料<br /></li>
</ul>

<p>
機器學習有各種不同的實作策略（演算法），而類神經網路就是其中之一。<br />
</p>
</div>
</div>

<div id="outline-container-org7bc4a04" class="outline-3">
<h3 id="org7bc4a04"><span class="section-number-3">2.4.</span> 類神經網路與深度學習</h3>
<div class="outline-text-3" id="text-2-4">
<p>
如何讓電腦俱備學習能力？在實作上也有多不同策略，類神經網路就是希望藉由模擬人類腦神經結構的方式來達到這個目的的一種方式，Hinton 於 2006 年提出的 Boltzmann Machine 為一種多層神經網路。典型的類神經網路架構(如圖<a href="#org5aeb789">2</a>)由輸入層、隱藏層、輸出層組成，學術界稱層數大於3的類神經網路為深度學習。<br />
</p>

<div id="org5aeb789" class="figure">
<p><img src="images/ANN-640x314.jpeg" alt="ANN-640x314.jpeg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 2: </span>類神經網路架構</p>
</div>

<p>
所以，當你聽到深度學習這個名詞時，有兩件事是可以確定的：<br />
</p>
<ol class="org-ol">
<li>這一定是機器學習<br /></li>
<li>這一定是類神經網路<br /></li>
</ol>

<p>
前面提到 <b>在某些領域下，特徵工程很難靠領域專家取得好的結果</b> ，深度學習的強大之處就在於深度學習連特徵工程也可以自行完成，即，由原始資中自行產生衍生變數。<br />
</p>
</div>
</div>

<div id="outline-container-orgcd294ee" class="outline-3">
<h3 id="orgcd294ee"><span class="section-number-3">2.5.</span> 深度學習</h3>
<div class="outline-text-3" id="text-2-5">
<p class="verse">
深度學習與其他機器學習方式最主要的差異在於能否自動進行「特徵工程」(feature engineering)<br />
</p>

<p>
考慮採取傳統<a href="MachineLearning.html">機器學習</a>或深度學習時，一個重要關鍵是資料量，若資料量太小，深度學習不一定會有更好的表現。Google Translate 在訓練文件量少於一億篇時，傳統<a href="MachineLearning.html">機器學習</a>表現較佳；在文件量超過十億後，深度學習效果就超越傳統<a href="MachineLearning.html">機器學習</a>。<br />
</p>

<div id="org70032d9" class="figure">
<p><img src="images/BLEU.png" alt="BLEU.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 3: </span>BLEU scores for English-Spanish systems trained on 0.4M to 385.7M words of parallel data. Source: Koehn and Knowles (2017) and GPU</p>
</div>
</div>
</div>

<div id="outline-container-org3dd825e" class="outline-3">
<h3 id="org3dd825e"><span class="section-number-3">2.6.</span> Deep Learning 的概念於 2006 年提出，何以至 2012 年才得到有效應用？</h3>
<div class="outline-text-3" id="text-2-6">
</div>
<ol class="org-ol">
<li><a id="org2325ad8"></a>計算速度: GPU 的計算能力由 2018 年起才有突破性的成長<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup><br />
<div class="outline-text-4" id="text-2-6-1">

<div id="org61f2d7d" class="figure">
<p><img src="images/GPUCPU1.jpg" alt="GPUCPU1.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 4: </span>Floating-point operations per second for the CPU and GPU</p>
</div>

<div id="orgbd9ae54" class="figure">
<p><img src="images/GPUCPU2.jpg" alt="GPUCPU2.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 5: </span>Memory bandwidth for the CPU and GPU</p>
</div>
</div>
</li>
<li><a id="org08b09a5"></a>大量數據<br /></li>
<li><a id="orgad0f02f"></a>軟體<br />
<div class="outline-text-4" id="text-2-6-3">
<p>
數學模型、軟體工具(Tensorflow)<br />
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org1bbe1fb" class="outline-2">
<h2 id="org1bbe1fb"><span class="section-number-2">3.</span> AI的發展沿革</h2>
<div class="outline-text-2" id="text-3">
<p>
不論是從 1942 年的<a href="https://zh.wikipedia.org/zh-tw/%E9%98%BF%E5%A1%94%E7%BA%B3%E7%B4%A2%E5%A4%AB-%E8%B4%9D%E7%91%9E%E8%AE%A1%E7%AE%97%E6%9C%BA">ABC</a>或是 1944 年的<a href="https://zh.wikipedia.org/wiki/%E9%A6%AC%E5%85%8B%E4%B8%80%E8%99%9F">MarK I</a>，電腦的發明都過去半個世紀了，為何到 2010 年後，人工智慧才成為熱門話題？<br />
</p>
</div>
<div id="outline-container-org7b5a9d4" class="outline-3">
<h3 id="org7b5a9d4"><span class="section-number-3">3.1.</span> 三個里程碑</h3>
<div class="outline-text-3" id="text-3-1">
<ol class="org-ol">
<li>1950: 設定 AI 目標<br /></li>
<li>1980: 以 Machine Learning 為主要手段<br /></li>
<li>1980 - 1990: Neural Network<br /></li>
<li>2006: Deep learning (ImageNet Classification with deep convolutioanl neural networks, 引用達上萬次)<br /></li>
<li>2010: Deep Learning<br /></li>
</ol>
</div>
</div>
<div id="outline-container-orge481465" class="outline-3">
<h3 id="orge481465"><span class="section-number-3">3.2.</span> AI 發展的起落</h3>
<div class="outline-text-3" id="text-3-2">
</div>
<ol class="org-ol">
<li><a id="org862bf3a"></a>第一波(符號還輯)：把人類的知識與思考放入電腦<br />
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li>1956 年，John McCarthy<br /></li>
<li>1957 年，Herbert A. Somin(諾貝爾經濟學奬得主)預言電腦能在十年內敗人類(西洋棋)，此預言於 1997由<a href="https://zh.wikipedia.org/zh-tw/%E6%B7%B1%E8%97%8D_(%E8%B6%85%E7%B4%9A%E9%9B%BB%E8%85%A6)">IBM Deep</a>實現。<br /></li>
<li>這階段的失敗原因：連人類自己都還搞不清楚自己的思考過程<br /></li>
</ul>
</div>
</li>
<li><a id="orga7b16b7"></a>第二波(專家系統)：讓電腦按照人類定義的規則做決策<br />
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li>1970 年，專家系統，一連串條件判斷的推導<br /></li>
<li>第一波失敗原因：野心太大，這次讓電腦依照人類設定好的規則來思考<br /></li>
<li>expert system 在 1980 年代廣受應用，Fortune 500 大公司有三分之二將之應用於營運工作中，如訂單處理、信用卡徵審、稅務處理。<br /></li>
<li>1990 年後 expoert system 逐漸勢微，原因是能力有限，距離人類心目中的人工智慧差距尚大。<br /></li>
<li>Polanyi&rsquo;s Paradox(博藍尼悖論): We can know more than we cantell, i.e., many of the tasks we perform rely on tacit, intuitive knowledge that is diffucult to codify and automate.<br /></li>
</ul>
</div>
</li>
<li><a id="orgaa4e2e7"></a>第三波(<a href="MachineLearning.html">機器學習</a>)：電腦從資枓歸納規則，關鍵要素為資料與演算法<br />
<div class="outline-text-4" id="text-3-2-3">
<ul class="org-ul">
<li>2006 年：Geofffrey Hinton 提出 Restricted Boltzmann Machine，成功訓練多層神經網路(multi-layer neural networks)，可用來描述更複雜的非線性函數，並稱之為深度學習(Deep Learning)。<br /></li>
<li>2012 年 10 月,Hinton 帶兩個學生參力 ILSVRC 比賽，以深度學習配合 GPU 的運算速度拿下冠軍。<br /></li>
<li>ILSVRC: ImageNet Large Scale Visual Recongnition Challenge, 先讓程式看 120 萬張訓練照片，共 1000 種分類，接下來要求程式為 15 萬張測試照片進行分類。<br /></li>
<li>2013 年，Google 收購 Hinton 和他兩位學生創立的公司：DNNresearch<br /></li>
<li>2015 年，Microsoft 在 ILSVRC 以 3.5%的錯誤率奪冠，首次超過人類(5%)。<br /></li>
</ul>
<p>
以上參考: <a href="https://www.books.com.tw/products/0010821934">人工智慧在台灣</a><br />
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org7950b24" class="outline-3">
<h3 id="org7950b24"><span class="section-number-3">3.3.</span> AI Development 大事記</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<ol class="org-ol">
<li><a id="org325a72d"></a>IBM Deep Blue<br /></li>
<li><a id="orgceee268"></a>IBM Watson<br /></li>
<li><a id="orge639d84"></a>AlphaGo<br /></li>
<li><a id="orgf85d229"></a>AI Method<br /></li>
<li><a id="org951856f"></a>Google AI: 以平行處理來加速 Deep learning 的 tried and error<br /></li>
<li><a id="org071204b"></a>Deep learning 能快速發展的原因<br />
<div class="outline-text-4" id="text-3-3-6">
<ul class="org-ul">
<li>Deep Network Architectures &amp; Training Strategies: 網路架構越來越大<br /></li>
<li>GPUs: 運算能力越來越強<br /></li>
<li>Data: 可參與運算的資料越來越多<br /></li>
</ul>
</div>
</li>
<li><a id="orgaae8536"></a>GAN: Generative Adversarial Network:<br />
<ol class="org-ol">
<li><a id="org1d8d63e"></a>生成對抗網路<br /></li>
<li><a id="orga268e3a"></a>generator 與 discrimator 二者透過相互競爭來改善<br /></li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-org68fa0bf" class="outline-3">
<h3 id="org68fa0bf"><span class="section-number-3">3.4.</span> AI 應用與影響</h3>
<div class="outline-text-3" id="text-3-4">
</div>
<ol class="org-ol">
<li><a id="org36acbf1"></a>Weak AI v.s. Strong AI<br />
<div class="outline-text-4" id="text-3-4-1">
<ul class="org-ul">
<li>Strong AI: 能思考、有主觀意識，又稱 General AI, FUll AI<br /></li>
<li>Tesla CEO Elon Musk: 2017 年 7 月在美國提倡規管 AI 發展的法案<br /></li>
</ul>
</div>
</li>
<li><a id="orgcf883f1"></a>AI 研究趨勢<br />
<div class="outline-text-4" id="text-3-4-2">
<ul class="org-ul">
<li>大規模<a href="MachineLearning.html">機器學習</a><br /></li>
<li>深度學習<br /></li>
<li>強化學習<br /></li>
<li>計算機視覺(偵測)<br /></li>
<li>自然語言處理<br /></li>
<li>協作系統<br /></li>
<li>Iot 物聯網<br /></li>
<li>交通 / 無人機<br /></li>
<li>家庭 / 服務機器人<br /></li>
<li>醫療: 長照、疾病判斷<br /></li>
<li>教育<br /></li>
<li>低資源社區<br /></li>
<li>公共安全: 監視器<br /></li>
<li>就業和勞資<br /></li>
<li>娛樂<br /></li>
</ul>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-orgee8c3e5" class="outline-2">
<h2 id="orgee8c3e5"><span class="section-number-2">4.</span> AI 的三大學派</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org409bf37" class="outline-3">
<h3 id="org409bf37"><span class="section-number-3">4.1.</span> 符號主義學派(知識圖譜: 模仿人類邏輯與抽像推理),</h3>
<div class="outline-text-3" id="text-4-1">
<p>
是指基於符號運算的人工智慧學派，他們認為知識可以用符號來表示，認知可以通過符號運算來實現。例如，專家系統等。<br />
</p>
</div>
<ol class="org-ol">
<li><a id="org69a58e0"></a>主要觀點：思維的基本是符號，思維過程即符號運算；智能的核心是知識，利用知識推理進行問題求解；智能活動的基礎是物理符號系統，人腦、電腦都是物理符號系統；知識可用符號表示，可建立基於符號邏輯的智能理論體系。該學派認為人工智慧源於數理邏輯，其主要的理論基礎是物理符號假設。<br /></li>
<li><a id="org1e11264"></a>主要科學方法：基於實驗心理學與計算軟體計算相結合的，以思維過程的功能模擬為重點的「黑箱」方法。<br /></li>
<li><a id="org8ed4e88"></a>代表性成果：1956 年問世的第一個啟發程序 LT 邏輯理論機；1968 年發表的第一個專家系統 DENTRAL 化學分析專家系統。<br /></li>
<li><a id="org1eff383"></a>發展途徑：啟發程序→專家系統。<br /></li>
</ol>
</div>
<div id="outline-container-orgfc40e8e" class="outline-3">
<h3 id="orgfc40e8e"><span class="section-number-3">4.2.</span> 連接主義學派(深度學習: 模仿大腦皮層神經網路)</h3>
<div class="outline-text-3" id="text-4-2">
<p>
是指神經網絡學派，在神經網絡方面，繼魯梅爾哈特研製出 BP 網絡之後，1987 年，首屆國際人工神經網絡學術大會在聖迭戈（San-Diego）舉行，掀起了人工神經網絡的第二次高潮。之後，隨著模糊邏輯和進化計算的逐步成熟，又形成了「計算智能」這個統一的學科範疇。<br />
</p>
</div>
<ol class="org-ol">
<li><a id="org0e96457"></a>主要觀點：智能活動的基元是神經細胞，智能活動過程是神經網絡的狀態演化過程，智能活動的基礎是神經細胞的突觸聯結機制，智能系統的工作模式仿人腦模式。該學派認為人工智慧源於仿生學，特別是對人腦模型的研究，其主要理論基礎為神經網絡及神經網絡間的連接機制與學習算法。<br /></li>
<li><a id="orgcddf985"></a>主要科學方法：基於神經生理學與生理學的、以神經系統的結構模擬為重點的數學模擬與物理模擬方法。<br /></li>
<li><a id="org3989ab7"></a>代表性成果：1943 年問世的第一個人工神經細胞——MP 模型；1960 年研製的感知機；1982 年提出的全互連型人工神經網絡——Hopfield 網絡；1986 年開發的多層感知機——BP 神經網絡。<br /></li>
<li><a id="org106ee7c"></a>發展途徑：人工神經細胞→人工神經網絡。<br /></li>
</ol>
</div>
<div id="outline-container-orgc2b3a9f" class="outline-3">
<h3 id="orgc2b3a9f"><span class="section-number-3">4.3.</span> 行為主義學派(強化學習: 模仿生物奬懲學習機制)</h3>
<div class="outline-text-3" id="text-4-3">
<p>
是指進化主義學派，在行為模擬方面，麻省理工學院的布魯克教授 1991 年研製成功了能在未知的動態環境中漫遊的有 6 條腿的機器蟲。<br />
</p>
</div>
<ol class="org-ol">
<li><a id="orge893dc9"></a>主要觀點：智能行為的基礎是「感知——行動」的反應機制，智能系統的智能行為，需要在真實世界的複雜境遇中進行學習和訓練，在與周圍環境的信息交互與適應過程中不斷進化和體現。該學派認為人工智慧應著重研究在複雜環境下對行為的控制，其主要的理論基礎是控制論。<br /></li>
<li><a id="org9a1533b"></a>主要科學方法：基於智能控制系統的理論、方法和技術，以生物控制系統的智能行為模擬為重點，研究擬人的智能控制行為。<br /></li>
<li><a id="org43b6488"></a>代表性成果：1952 年研製成功的第一個「控制論動物」——香農老鼠；1991 年布魯克斯演示的新型智能機器人。<br /></li>
<li><a id="org0281673"></a>發展途徑：控制論動物→智能機器人。<br />
<div class="outline-text-4" id="text-4-3-4">
<p>
(以上參考網址：原文網址：<a href="https://kknews.cc/tech/pp8kvlz.html%E3%80%81https://kknews.cc/tech/5gn2gll.html">https://kknews.cc/tech/pp8kvlz.html%E3%80%81https://kknews.cc/tech/5gn2gll.html</a>)<br />
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org732149b" class="outline-2">
<h2 id="org732149b"><span class="section-number-2">5.</span> AI 的五大迷思</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgd3234c7" class="outline-3">
<h3 id="orgd3234c7"><span class="section-number-3">5.1.</span> 迷思一：資料等於價值</h3>
<div class="outline-text-3" id="text-5-1">
<p>
資料若沒有經過妥善的加工處理和萃取分析，本身並無太大價值，需要將對的資料用在對的場景。例如，電信公司的通聯記錄，行銷公司只會拿來做行銷，治安機關則可以拿來追查詐騙集團；又如 X 光片的判斷品質決定了 AI model 的成效。資料等於價值的另一反例為 AlphaZero。<br />
</p>
</div>
</div>
<div id="outline-container-org05a2ef2" class="outline-3">
<h3 id="org05a2ef2"><span class="section-number-3">5.2.</span> 迷思二：牽涉電腦與資料就是 MIS 部門的工作</h3>
<div class="outline-text-3" id="text-5-2">
<p>
AI 的導入需要跨部門支持，其開發團隊需要資料科學家(數學、統計)、領域專家(領域知識)、資訊人員(程式設計、資料庫)，最後在驗證模型成效時更需要跨部門的支持。<br />
</p>
</div>
</div>
<div id="outline-container-org1f542c3" class="outline-3">
<h3 id="org1f542c3"><span class="section-number-3">5.3.</span> 迷思三：資料分析就是產出報表</h3>
<div class="outline-text-3" id="text-5-3">
<p>
資料分析不應只限於公司內部資料庫中的結構化資料，而應包含非結構化資料(影像、聲音、影片、文字、互動)<br />
</p>
</div>
</div>
<div id="outline-container-org2f937ff" class="outline-3">
<h3 id="org2f937ff"><span class="section-number-3">5.4.</span> 迷思四：電腦決策不可能贏過人的專業經驗</h3>
<div class="outline-text-3" id="text-5-4">
<p>
主要原因在人類的短期記憶有限、能留意到的弱訊號太少，此外，有些工作需要極快的反應時間(如股市交易)。1995 年 Amazon 曾讓 50 位資深編輯就「推薦書單」與演算法進行 PK，自此後 Amazon 所有商品推薦都由<a href="MachineLearning.html">機器學習</a>進行。<br />
</p>
</div>
</div>
<div id="outline-container-orgef95bdf" class="outline-3">
<h3 id="orgef95bdf"><span class="section-number-3">5.5.</span> 迷思五：導入系統或平台就可以解決營運問題</h3>
<div class="outline-text-3" id="text-5-5">
<p>
AI 不是一個資訊系統(如 ERP)，而是一種根據已知預測未知的方法，它沒有標準做法，其應用情境與方式會隨著企業的狀況與及需求有所不同。因此，問題不在「有沒有導入 AI」，而是「AI 應用的深度與廣度」。<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org73bf51f" class="outline-2">
<h2 id="org73bf51f"><span class="section-number-2">6.</span> AI 擅長的解題領域</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org5bc4c21" class="outline-3">
<h3 id="org5bc4c21"><span class="section-number-3">6.1.</span> 與情境無關的領域</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>如棋類遊戲等封閉系統就是與情境無關；反之，個人商品推薦則否，因為影響使用者是否購買特定商品的因素有太多是電商觀測不到的，例如，當天的心情。同理，戰爭的爆發其背後的因素也有可能出人意料之外，如特洛伊。<br /></li>
<li>一些工作雖然與情境相關，但卻因為這些情境可人為控制，所以也適合以 AI 解決，如，人臉辨識可能因為拍照時人的角度、戴口罩、太陽眼鏡、帽子、背景光線、天氣等因素而導致辨識困難，但這些情境因素都可以事先控制，如：要求對象拿下口罩正向面對攝影機。<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orga278fc9" class="outline-3">
<h3 id="orga278fc9"><span class="section-number-3">6.2.</span> 樣本數多的領域</h3>
<div class="outline-text-3" id="text-6-2">
<ul class="org-ul">
<li>如颱風一年最多 20 個，累積 50 年也不過 1000 個，不足以建立高複雜度且精確的學習模型(尤其牽涉的的變數很多時)<br /></li>
</ul>

<div id="orgc9d85d6" class="figure">
<p><img src="images/AITW.jpg" alt="AITW.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 6: </span>AI 擅長的解題領域</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org03ad3a0" class="outline-2">
<h2 id="org03ad3a0"><span class="section-number-2">7.</span> AI 各項產業應用</h2>
<div class="outline-text-2" id="text-7">

<div id="org5b096f7" class="figure">
<p><img src="images/enterprise.jpg" alt="enterprise.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 7: </span>各產業投資 AI 效益</p>
</div>
</div>
<div id="outline-container-org285be1b" class="outline-3">
<h3 id="org285be1b"><span class="section-number-3">7.1.</span> 製造業</h3>
<div class="outline-text-3" id="text-7-1">
<ol class="org-ol">
<li>瑕疵檢測：金屬表面、玻璃、印刷電路、電子產品、牛仔褲、農產品，由 AI 取代人眼。在某家製造商的資料中，人眼檢測瑕疵漏網率為 5%、AI 為 0.01%；人眼檢測速度為每天 30 萬張影像、一台 10 萬左右的電腦每天可檢測 1440 萬張。<br /></li>
<li>自動流程控制：製造業共通的挑戰為設人竹廿月參數的調控及最佳化，或稱為自動流程控制。生產流程中，如馬達轉速、電流、電壓、環境溫度&#x2026;等等需要監控、會影響產品良率的因素可能高達上千個，這些高維度的因素彼此又有交互作用(通常維度高過 5 個，且參數間有交互作用，人類就無法精確掌握)，而且製程可能很長，調整參數後可能隔天才能確認。AI 介入化工製程的例子可以將良率由六成調至 98%<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>。<br /></li>
<li>預測性維護：包括預測機器何時會出錯以提前進廠保養、預測耗才何時更換最為有利。此類工作涉及訊號鄋理，如：監控馬達電壓、轉速、震動、聲音來判斷馬達是否即將固障；監控機器手臂行程順暢度、夾具穩定度來判斷機器手臂是否有固障徵兆。<sup><a id="fnr.2.100" class="footref" href="#fn.2" role="doc-backlink">2</a></sup><br /></li>
<li>原料組合最佳化：製造業的工作在於取得一種或多種原料，經過物理或化學加工過程後製成產品；但每批原枓可能來自不同供應商、品質、等級或特性可能有所差異，如何在各原料、供應商、等級、成本的排列中找出最高 CP 值的組合即為重要工作。以染整業為例，新的布料與顏色平均要花 3~7 天的打色嚐試才能達到客戶允收範圍，以第一次打色為例，軟體模擬加上師傅經驗調整，成功率約七成；而藉由以深度學習建出模型來描述布料、目標顏色及染料濃度間的關係，可以將成功率達到九成<sup><a id="fnr.2.100" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>。<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org1629aa8" class="outline-3">
<h3 id="org1629aa8"><span class="section-number-3">7.2.</span> 零售與金融業</h3>
<div class="outline-text-3" id="text-7-2">
<p>
零售及金融之所以相對容易切入 AI 是因為這兩個產業的核心業務就是在處理資訊流。<br />
依據 Gartner 的報告，資料分析可以分四個層次：<br />
</p>
<ol class="org-ol">
<li>描述：評估現況及了解問題。解釋發生了什麼？<br /></li>
<li>解釋：提供問題的初步診斷。解釋為什麼發生？<br /></li>
<li>預測：提供改善和解決問題的工具。未來會不會發生？<br /></li>
<li>最佳化：提供改善和解決問題的工具。如何讓他發生？<br /></li>
</ol>
</div>
<ol class="org-ol">
<li><a id="org161d591"></a>圖表式的決策反而可能誤導<br />
<div class="outline-text-4" id="text-7-2-1">
<p>
以零售業的產銷量問題為例，假設影響因素有：店點、擺設位置、售價，折扣活動、集點活動、包裝、季節&#x2026;，若以圖表顯示，每張圖表一次頂多呈現 1~2 個變數的關係，無法同時呈現所有變數<sup><a id="fnr.2.100" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>。<br />
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org4ea5d89" class="outline-2">
<h2 id="org4ea5d89"><span class="section-number-2">8.</span> AI v.s. security</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-orge43c91d" class="outline-3">
<h3 id="orge43c91d"><span class="section-number-3">8.1.</span> 釣魚網站偵測實戰</h3>
<div class="outline-text-3" id="text-8-1">
<p>
<a href="https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter02">github data</a><br />
</p>
</div>

<ol class="org-ol">
<li><a id="orgd77f90f"></a>資料集<br />
<div class="outline-text-4" id="text-8-1-1">
<p>
UCI Machine Learning Repository (Phishing Websites Data Set).<br />
<a href="https://archive.ics.uci.edu/ml/datasets/Phishing+Websites">https://archive.ics.uci.edu/ml/datasets/Phishing+Websites</a><br />
</p>

<p>
The dataset is provided as an arff file<br />
</p>

<p>
處理過的資料集:<br />
{30 Attributes (having_IP_Address URL_Length, abnormal_URL and so on)}+ {1 Attribute (Result)}<br />
</p>

<p>
-1,1,1,1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,-1,0,1,1,1,1,-1,-1,-1,-1,1,1,-1,-1<br />
</p>

<p>
真正要能上線跑的演算法不多，因為會面臨資料量太大(流量)的問題，會導致記憶體不足&#x2026;.<br />
</p>
</div>
</li>

<li><a id="orgd317ab9"></a>papers<br />
<div class="outline-text-4" id="text-8-1-2">
<ul class="org-ul">
<li>Mohammad, Rami, McCluskey, T.L. and Thabtah, Fadi (2012). An Assessment of Features Related to Phishing Websites using an Automated Technique. In: International Conferece For Internet Technology And Secured Transactions. ICITST 2012 . IEEE, London, UK, pp. 492-497. ISBN 978-1-4673-5325-0<br /></li>
<li>Mohammad, Rami, Thabtah, Fadi Abdeljaber and McCluskey, T.L. (2014). Predicting phishing websites based on self-structuring neural network. Neural Computing and Applications, 25 (2). pp. 443-458. ISSN 0941-0643<br /></li>
<li>Mohammad, Rami, McCluskey, T.L. and Thabtah, Fadi Abdeljaber (2014). Intelligent Rule based Phishing Websites Classification. IET Information Security, 8 (3). pp. 153-160. ISSN 1751-8709<br /></li>
</ul>
</div>
</li>

<li><a id="orgc6b1f79"></a>使用 LogisticRegression<br />
<div class="outline-text-4" id="text-8-1-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> *
<span class="linenr"> 3: </span>  <span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LogisticRegression
<span class="linenr"> 4: </span>  <span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> accuracy_score
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span>  <span style="color: #dcaeea;">training_data</span> = np.genfromtxt(<span style="color: #98be65;">'dataset.csv'</span>, delimiter=<span style="color: #98be65;">','</span>, dtype=np.int32)
<span class="linenr"> 7: </span>  inputs = training_data[:,:-<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 8: </span>  outputs = training_data[:, -<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>  training_inputs = inputs[:<span style="color: #da8548; font-weight: bold;">2000</span>]
<span class="linenr">11: </span>  training_outputs = outputs[:<span style="color: #da8548; font-weight: bold;">2000</span>]
<span class="linenr">12: </span>  testing_inputs = inputs[<span style="color: #da8548; font-weight: bold;">2000</span>:]
<span class="linenr">13: </span>  testing_outputs = outputs[<span style="color: #da8548; font-weight: bold;">2000</span>:]
<span class="linenr">14: </span>
<span class="linenr">15: </span>  classifier = LogisticRegression()
<span class="linenr">16: </span>  classifier.fit(training_inputs, training_outputs)
<span class="linenr">17: </span>  predictions = classifier.predict(testing_inputs)
<span class="linenr">18: </span>  accuracy = <span style="color: #da8548; font-weight: bold;">100.0</span> * accuracy_score(testing_outputs, predictions)
<span class="linenr">19: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">"The accuracy of your Logistic Regression on testing data is: "</span> + <span style="color: #c678dd;">str</span>(accuracy))
</pre>
</div>
</div>
</li>

<li><a id="orga336a70"></a>使用 DecisionTreeClassifier<br />
<div class="outline-text-4" id="text-8-1-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> tree
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> accuracy_score
<span class="linenr"> 3: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span>  <span style="color: #dcaeea;">training_data</span> = np.genfromtxt(<span style="color: #98be65;">'dataset.csv'</span>, delimiter=<span style="color: #98be65;">','</span>, dtype=np.int32)
<span class="linenr"> 6: </span>  inputs = training_data[:,:-<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 7: </span>  outputs = training_data[:, -<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span>  training_inputs = inputs[:<span style="color: #da8548; font-weight: bold;">2000</span>]
<span class="linenr">10: </span>  training_outputs = outputs[:<span style="color: #da8548; font-weight: bold;">2000</span>]
<span class="linenr">11: </span>  testing_inputs = inputs[<span style="color: #da8548; font-weight: bold;">2000</span>:]
<span class="linenr">12: </span>  testing_outputs = outputs[<span style="color: #da8548; font-weight: bold;">2000</span>:]
<span class="linenr">13: </span>
<span class="linenr">14: </span>  classifier = tree.DecisionTreeClassifier()
<span class="linenr">15: </span>  classifier.fit(training_inputs, training_outputs)
<span class="linenr">16: </span>  predictions = classifier.predict(testing_inputs)
<span class="linenr">17: </span>  accuracy = <span style="color: #da8548; font-weight: bold;">100.0</span> * accuracy_score(testing_outputs, predictions)
<span class="linenr">18: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">"The accuracy of your decision tree on testing data is: "</span> + <span style="color: #c678dd;">str</span>(accuracy))
</pre>
</div>
</div>
</li>
</ol>
</div>

<div id="outline-container-orga9f2d00" class="outline-3">
<h3 id="orga9f2d00"><span class="section-number-3">8.2.</span> Text Classification</h3>
<div class="outline-text-3" id="text-8-2">
<p>
<a href="https://github.com/MyDearGreatTeacher/TensorSecurity/blob/master/code/AI_security/3_TextClassification%E8%88%87%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E9%A0%90%E6%B8%AC.md">Text classification github</a><br />
</p>

<p>
二元分類: binary classification<br />
</p>

<p>
spam detection[email, SMS]<br />
</p>
</div>

<ol class="org-ol">
<li><a id="org52d4518"></a>papers<br />
<div class="outline-text-4" id="text-8-2-1">
<ul class="org-ul">
<li>MS Spam Collection Dataset, Collection of SMS messages tagged as spam or legitimate, <a href="https://www.kaggle.com/uciml/sms-spam-collection-dataset/data">https://www.kaggle.com/uciml/sms-spam-collection-dataset/data</a><br /></li>
<li>The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.<br /></li>
<li>2009 年博士論文, A CORPUS LINGUISTICS STUDY OF SMS TEXT MESSAGING, CAROLINE TAGG, <a href="https://etheses.bham.ac.uk/id/eprint/253/1/Tagg09PhD.pdf">https://etheses.bham.ac.uk/id/eprint/253/1/Tagg09PhD.pdf</a><br /></li>
</ul>
</div>
</li>

<li><a id="orgeafb622"></a>資料集<br />
<div class="outline-text-4" id="text-8-2-2">
<p>
<a href="https://github.com/CorkyMaigre/sms-spam-ml/blob/master/dataset/SMSSpamCollection">https://github.com/CorkyMaigre/sms-spam-ml/blob/master/dataset/SMSSpamCollection</a><br />
</p>

<div class="org-src-container">
<pre class="src src-sh">  ham   Go until jurong point, crazy.. Available only<span style="color: #51afef;"> in</span> bugis n great world la e buffet... Cine there got amore wat...
  ham   Ok lar... Joking wif u oni...
  spam  Free entry<span style="color: #51afef;"> in</span> <span style="color: #da8548; font-weight: bold;">2</span> a wkly comp to win FA Cup final tkts 21st May <span style="color: #da8548; font-weight: bold;">2005.</span> Text FA to <span style="color: #da8548; font-weight: bold;">87121</span> to receive entry question(std txt rate)T&amp;C<span style="color: #98be65;">'s apply 08452810075over18'</span>s
  ham   U dun say so early hor... U c already then say...
  ham   Nah I don<span style="color: #98be65;">'t think he goes to usf, he lives around here though</span>
<span style="color: #98be65;">  spam  FreeMsg Hey there darling it'</span>s been <span style="color: #da8548; font-weight: bold;">3</span> week<span style="color: #98be65;">'s now and no word back! I'</span>d like some fun you up for it still? Tb ok! XxX std chgs to send, &#163;1.50 to rcv
  ham   Even my brother is not like to speak with me. They treat me like aids patent.
  ham   As per your request <span style="color: #98be65;">'Melle Melle (Oru Minnaminunginte Nurungu Vettam)'</span> has been set as your callertune for all Callers. Press *9 to copy your friends Callertune
  spam  WINNER!! As a valued network customer you have been selected to receivea &#163;900 prize reward! To claim call <span style="color: #da8548; font-weight: bold;">09061701461.</span> Claim code KL341. Valid <span style="color: #da8548; font-weight: bold;">12</span> hours only.
  spam  Had your mobile <span style="color: #da8548; font-weight: bold;">11</span> months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on <span style="color: #da8548; font-weight: bold;">08002986030</span>
  ham   I<span style="color: #98be65;">'m gonna be home soon and i don'</span>t want to talk about this stuff anymore tonight, k? I<span style="color: #98be65;">'ve cried enough today.</span>
<span style="color: #98be65;">  spam  SIX chances to win CASH! From 100 to 20,000 pounds txt&gt; CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info</span>
<span style="color: #98be65;">  spam  URGENT! You have won a 1 week FREE membership in our &#163;100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&amp;C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18</span>
<span style="color: #98be65;">  ham   I'</span>ve been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.
  ham   I HAVE A DATE ON SUNDAY WITH WILL!!
  spam  XXXMobileMovieClub: To use your credit, click the WAP link<span style="color: #51afef;"> in</span> the next txt message or click here&gt;&gt; http://wap. xxxmobilemovieclub.com?<span style="color: #dcaeea;">n</span>=QJKGIGHJJGCBL
  ham   Oh k...i<span style="color: #98be65;">'m watching here:)</span>
<span style="color: #98be65;">  ham   Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.</span>
<span style="color: #98be65;">  ham   Fine if that&#65533;s the way u feel. That&#65533;s the way its gota b</span>
<span style="color: #98be65;">  spam  England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/&#250;1.20 POBOXox36504W45WQ 16+</span>
<span style="color: #98be65;">  ham   Is that seriously how you spell his name?</span>
<span style="color: #98be65;">  ham   I&#8216;m going to try for 2 months ha ha only joking</span>
<span style="color: #98be65;">  ham   So &#252; pay first lar... Then when is da stock comin...</span>
<span style="color: #98be65;">  ham   Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?</span>
<span style="color: #98be65;">  ham   Ffffffffff. Alright no way I can meet up with you sooner?</span>
<span style="color: #98be65;">  ham   Just forced myself to eat a slice. I'</span>m really not hungry tho. This sucks. Mark is getting worried. He knows I<span style="color: #98be65;">'m sick when I turn down pizza. Lol</span>
<span style="color: #98be65;">  ham   Lol your always so convincing.</span>
<span style="color: #98be65;">  ham   Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom'</span>s left over dinner ? Do you feel my Love ?
  ham   I<span style="color: #98be65;">'m back &amp;amp; we'</span>re packing the car now, I<span style="color: #98be65;">'ll let you know if there'</span>s room
  ham   Ahhh. Work. I vaguely remember that! What does it feel like? Lol
  ham   Wait that<span style="color: #98be65;">'s still not all that clear, were you not sure about me being sarcastic or that that'</span>s why x doesn<span style="color: #98be65;">'t want to live with us</span>
<span style="color: #98be65;">  ham   Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won'</span>t go there! Not doing too badly cheers. You?

</pre>
</div>
</div>
</li>

<li><a id="org5566b76"></a>使用 LogisticRegression<br />
<div class="outline-text-4" id="text-8-2-3">
<ul class="org-ul">
<li>Hands-on-Machine-Learning-for-Cyber-Security/Chapter05/sms_spam.py /<br /></li>
<li><a href="https://github.com/PacktPublishing/Hands-on-Machine-Learning-for-Cyber-Security/blob/master/Chapter05/sms_spam.py">https://github.com/PacktPublishing/Hands-on-Machine-Learning-for-Cyber-Security/blob/master/Chapter05/sms_spam.py</a><br /></li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 2: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span>  <span style="color: #51afef;">from</span> sklearn.feature_extraction.text <span style="color: #51afef;">import</span> TfidfVectorizer
<span class="linenr"> 4: </span>  <span style="color: #51afef;">from</span> sklearn.linear_model.logistic <span style="color: #51afef;">import</span> LogisticRegression
<span class="linenr"> 5: </span>  <span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split, cross_val_score
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span>  <span style="color: #dcaeea;">dataframe</span> = pd.read_csv(<span style="color: #98be65;">'SMSSpamCollectionDataSet'</span>, delimiter=<span style="color: #98be65;">'\t'</span>,header=<span style="color: #a9a1e1;">None</span>)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span>  <span style="color: #dcaeea;">X_train_dataset</span>, <span style="color: #dcaeea;">X_test_dataset</span>, <span style="color: #dcaeea;">y_train_dataset</span>, <span style="color: #dcaeea;">y_test_dataset</span> = train_test_split(dataframe[<span style="color: #da8548; font-weight: bold;">1</span>],dataframe[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">10: </span>
<span class="linenr">11: </span>  vectorizer = TfidfVectorizer()
<span class="linenr">12: </span>  X_train_dataset = vectorizer.fit_transform(X_train_dataset)
<span class="linenr">13: </span>
<span class="linenr">14: </span>  classifier_log = LogisticRegression()
<span class="linenr">15: </span>  classifier_log.fit(X_train_dataset, y_train_dataset)
<span class="linenr">16: </span>
<span class="linenr">17: </span>  X_test_dataset = vectorizer.transform( [<span style="color: #98be65;">'URGENT! Your Mobile No 1234 was awarded a Prize'</span>, <span style="color: #98be65;">'Hey honey, whats up?'</span>] )
<span class="linenr">18: </span>
<span class="linenr">19: </span>  predictions_logistic = classifier.predict(X_test_dataset)
<span class="linenr">20: </span>  <span style="color: #c678dd;">print</span>(predictions)
</pre>
</div>
</div>
</li>

<li><a id="org05d942a"></a>TensorFlow_RNN for 垃圾短信預測<br />
<div class="outline-text-4" id="text-8-2-4">
<p>
TensorFlow 機器學習實戰指南 (美)尼克‧麥克盧爾<br />
 9.2 用 TensorFlow 實現 RNN 模型進行垃圾短信預測<br />
 <a href="https://github.com/PacktPublishing/TensorFlow-Machine-Learning-Cookbook-Second-Edition">https://github.com/PacktPublishing/TensorFlow-Machine-Learning-Cookbook-Second-Edition</a><br />
</p>


<div class="org-src-container">
<pre class="src src-python"><span class="linenr">  1: </span>  <span style="color: #51afef;">import</span> os
<span class="linenr">  2: </span>  <span style="color: #51afef;">import</span> re
<span class="linenr">  3: </span>  <span style="color: #51afef;">import</span> io
<span class="linenr">  4: </span>  <span style="color: #51afef;">import</span> requests
<span class="linenr">  5: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">  6: </span>  <span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">  7: </span>  <span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr">  8: </span>  <span style="color: #51afef;">from</span> zipfile <span style="color: #51afef;">import</span> ZipFile
<span class="linenr">  9: </span>  <span style="color: #51afef;">from</span> tensorflow.python.framework <span style="color: #51afef;">import</span> ops
<span class="linenr"> 10: </span>  ops.reset_default_graph()
<span class="linenr"> 11: </span>
<span class="linenr"> 12: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Start a graph</span>
<span class="linenr"> 13: </span>  <span style="color: #dcaeea;">sess</span> = tf.Session()
<span class="linenr"> 14: </span>
<span class="linenr"> 15: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Set RNN parameters</span>
<span class="linenr"> 16: </span>  <span style="color: #dcaeea;">epochs</span> = <span style="color: #da8548; font-weight: bold;">20</span>
<span class="linenr"> 17: </span>  <span style="color: #dcaeea;">batch_size</span> = <span style="color: #da8548; font-weight: bold;">250</span>
<span class="linenr"> 18: </span>  <span style="color: #dcaeea;">max_sequence_length</span> = <span style="color: #da8548; font-weight: bold;">25</span>
<span class="linenr"> 19: </span>  <span style="color: #dcaeea;">rnn_size</span> = <span style="color: #da8548; font-weight: bold;">10</span>
<span class="linenr"> 20: </span>  <span style="color: #dcaeea;">embedding_size</span> = <span style="color: #da8548; font-weight: bold;">50</span>
<span class="linenr"> 21: </span>  <span style="color: #dcaeea;">min_word_frequency</span> = <span style="color: #da8548; font-weight: bold;">10</span>
<span class="linenr"> 22: </span>  <span style="color: #dcaeea;">learning_rate</span> = <span style="color: #da8548; font-weight: bold;">0.0005</span>
<span class="linenr"> 23: </span>  <span style="color: #dcaeea;">dropout_keep_prob</span> = tf.placeholder(tf.float32)
<span class="linenr"> 24: </span>
<span class="linenr"> 25: </span>
<span class="linenr"> 26: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Download or open data</span>
<span class="linenr"> 27: </span>  <span style="color: #dcaeea;">data_dir</span> = <span style="color: #98be65;">'temp'</span>
<span class="linenr"> 28: </span>  <span style="color: #dcaeea;">data_file</span> = <span style="color: #98be65;">'text_data.txt'</span>
<span class="linenr"> 29: </span>  <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(data_dir):
<span class="linenr"> 30: </span>      os.makedirs(data_dir)
<span class="linenr"> 31: </span>
<span class="linenr"> 32: </span>  <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.isfile(os.path.join(data_dir, data_file)):
<span class="linenr"> 33: </span>      <span style="color: #dcaeea;">zip_url</span> = <span style="color: #98be65;">'http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'</span>
<span class="linenr"> 34: </span>      <span style="color: #dcaeea;">r</span> = requests.get(zip_url)
<span class="linenr"> 35: </span>      <span style="color: #dcaeea;">z</span> = ZipFile(io.BytesIO(r.content))
<span class="linenr"> 36: </span>      <span style="color: #c678dd;">file</span> = z.read(<span style="color: #98be65;">'SMSSpamCollection'</span>)
<span class="linenr"> 37: </span>      <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Format Data</span>
<span class="linenr"> 38: </span>      <span style="color: #dcaeea;">text_data</span> = <span style="color: #c678dd;">file</span>.decode()
<span class="linenr"> 39: </span>      <span style="color: #dcaeea;">text_data</span> = text_data.encode(<span style="color: #98be65;">'ascii'</span>, errors=<span style="color: #98be65;">'ignore'</span>)
<span class="linenr"> 40: </span>      text_data = text_data.decode().split(<span style="color: #98be65;">'\n'</span>)
<span class="linenr"> 41: </span>
<span class="linenr"> 42: </span>      <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Save data to text file</span>
<span class="linenr"> 43: </span>      <span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(os.path.join(data_dir, data_file), <span style="color: #98be65;">'w'</span>) <span style="color: #51afef;">as</span> file_conn:
<span class="linenr"> 44: </span>          <span style="color: #51afef;">for</span> text <span style="color: #51afef;">in</span> text_data:
<span class="linenr"> 45: </span>              file_conn.write(<span style="color: #98be65;">"{}\n"</span>.<span style="color: #c678dd;">format</span>(text))
<span class="linenr"> 46: </span>  <span style="color: #51afef;">else</span>:
<span class="linenr"> 47: </span>      <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Open data from text file</span>
<span class="linenr"> 48: </span>      text_data = []
<span class="linenr"> 49: </span>      <span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(os.path.join(data_dir, data_file), <span style="color: #98be65;">'r'</span>) <span style="color: #51afef;">as</span> file_conn:
<span class="linenr"> 50: </span>          <span style="color: #51afef;">for</span> row <span style="color: #51afef;">in</span> file_conn:
<span class="linenr"> 51: </span>              text_data.append(row)
<span class="linenr"> 52: </span>      text_data = text_data[:-<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 53: </span>
<span class="linenr"> 54: </span>  text_data = [x.split(<span style="color: #98be65;">'\t'</span>) <span style="color: #51afef;">for</span> x <span style="color: #51afef;">in</span> text_data <span style="color: #51afef;">if</span> <span style="color: #c678dd;">len</span>(x) &gt;= <span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 55: </span>  [<span style="color: #dcaeea;">text_data_target</span>, <span style="color: #dcaeea;">text_data_train</span>] = [<span style="color: #c678dd;">list</span>(x) <span style="color: #51afef;">for</span> x <span style="color: #51afef;">in</span> <span style="color: #c678dd;">zip</span>(*text_data)]
<span class="linenr"> 56: </span>
<span class="linenr"> 57: </span>
<span class="linenr"> 58: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create a text cleaning function</span>
<span class="linenr"> 59: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">clean_text</span>(text_string):
<span class="linenr"> 60: </span>      text_string = re.sub(r<span style="color: #98be65;">'([^\s\w]|_|[0-9])+'</span>, <span style="color: #98be65;">''</span>, text_string)
<span class="linenr"> 61: </span>      text_string = <span style="color: #98be65;">" "</span>.join(text_string.split())
<span class="linenr"> 62: </span>      text_string = text_string.lower()
<span class="linenr"> 63: </span>      <span style="color: #51afef;">return</span> text_string
<span class="linenr"> 64: </span>
<span class="linenr"> 65: </span>
<span class="linenr"> 66: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Clean texts</span>
<span class="linenr"> 67: </span>  text_data_train = [clean_text(x) <span style="color: #51afef;">for</span> x <span style="color: #51afef;">in</span> text_data_train]
<span class="linenr"> 68: </span>
<span class="linenr"> 69: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Change texts into numeric vectors</span>
<span class="linenr"> 70: </span>  vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(max_sequence_length,
<span class="linenr"> 71: </span>                                                                       min_frequency=min_word_frequency)
<span class="linenr"> 72: </span>  text_processed = np.array(<span style="color: #c678dd;">list</span>(vocab_processor.fit_transform(text_data_train)))
<span class="linenr"> 73: </span>
<span class="linenr"> 74: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Shuffle and split data</span>
<span class="linenr"> 75: </span>  text_processed = np.array(text_processed)
<span class="linenr"> 76: </span>  text_data_target = np.array([<span style="color: #da8548; font-weight: bold;">1</span> <span style="color: #51afef;">if</span> x == <span style="color: #98be65;">'ham'</span> <span style="color: #51afef;">else</span> <span style="color: #da8548; font-weight: bold;">0</span> <span style="color: #51afef;">for</span> x <span style="color: #51afef;">in</span> text_data_target])
<span class="linenr"> 77: </span>  shuffled_ix = np.random.permutation(np.arange(<span style="color: #c678dd;">len</span>(text_data_target)))
<span class="linenr"> 78: </span>  x_shuffled = text_processed[shuffled_ix]
<span class="linenr"> 79: </span>  y_shuffled = text_data_target[shuffled_ix]
<span class="linenr"> 80: </span>
<span class="linenr"> 81: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Split train/test set</span>
<span class="linenr"> 82: </span>  ix_cutoff = <span style="color: #c678dd;">int</span>(<span style="color: #c678dd;">len</span>(y_shuffled)*<span style="color: #da8548; font-weight: bold;">0.80</span>)
<span class="linenr"> 83: </span>  <span style="color: #dcaeea;">x_train</span>, <span style="color: #dcaeea;">x_test</span> = x_shuffled[:ix_cutoff], x_shuffled[ix_cutoff:]
<span class="linenr"> 84: </span>  <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = y_shuffled[:ix_cutoff], y_shuffled[ix_cutoff:]
<span class="linenr"> 85: </span>  vocab_size = <span style="color: #c678dd;">len</span>(vocab_processor.vocabulary_)
<span class="linenr"> 86: </span>  <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Vocabulary Size: {:d}"</span>.<span style="color: #c678dd;">format</span>(vocab_size))
<span class="linenr"> 87: </span>  <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"80-20 Train Test split: {:d} -- {:d}"</span>.<span style="color: #c678dd;">format</span>(<span style="color: #c678dd;">len</span>(y_train), <span style="color: #c678dd;">len</span>(y_test)))
<span class="linenr"> 88: </span>
<span class="linenr"> 89: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create placeholders</span>
<span class="linenr"> 90: </span>  x_data = tf.placeholder(tf.int32, [<span style="color: #a9a1e1;">None</span>, max_sequence_length])
<span class="linenr"> 91: </span>  y_output = tf.placeholder(tf.int32, [<span style="color: #a9a1e1;">None</span>])
<span class="linenr"> 92: </span>
<span class="linenr"> 93: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create embedding</span>
<span class="linenr"> 94: </span>  embedding_mat = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -<span style="color: #da8548; font-weight: bold;">1.0</span>, <span style="color: #da8548; font-weight: bold;">1.0</span>))
<span class="linenr"> 95: </span>  embedding_output = tf.nn.embedding_lookup(embedding_mat, x_data)
<span class="linenr"> 96: </span>
<span class="linenr"> 97: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Define the RNN cell</span>
<span class="linenr"> 98: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">tensorflow change &gt;= 1.0, rnn is put into tensorflow.contrib directory. Prior version not test.</span>
<span class="linenr"> 99: </span>  <span style="color: #51afef;">if</span> tf.__version__[<span style="color: #da8548; font-weight: bold;">0</span>] &gt;= <span style="color: #98be65;">'1'</span>:
<span class="linenr">100: </span>      cell = tf.contrib.rnn.BasicRNNCell(num_units=rnn_size)
<span class="linenr">101: </span>  <span style="color: #51afef;">else</span>:
<span class="linenr">102: </span>      cell = tf.nn.rnn_cell.BasicRNNCell(num_units=rnn_size)
<span class="linenr">103: </span>
<span class="linenr">104: </span>  <span style="color: #dcaeea;">output</span>, <span style="color: #dcaeea;">state</span> = tf.nn.dynamic_rnn(cell, embedding_output, dtype=tf.float32)
<span class="linenr">105: </span>  output = tf.nn.dropout(output, dropout_keep_prob)
<span class="linenr">106: </span>
<span class="linenr">107: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Get output of RNN sequence</span>
<span class="linenr">108: </span>  output = tf.transpose(output, [<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">2</span>])
<span class="linenr">109: </span>  last = tf.gather(output, <span style="color: #c678dd;">int</span>(output.get_shape()[<span style="color: #da8548; font-weight: bold;">0</span>]) - <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">110: </span>
<span class="linenr">111: </span>  weight = tf.Variable(tf.truncated_normal([rnn_size, <span style="color: #da8548; font-weight: bold;">2</span>], stddev=<span style="color: #da8548; font-weight: bold;">0.1</span>))
<span class="linenr">112: </span>  bias = tf.Variable(tf.constant(<span style="color: #da8548; font-weight: bold;">0.1</span>, shape=[<span style="color: #da8548; font-weight: bold;">2</span>]))
<span class="linenr">113: </span>  logits_out = tf.matmul(last, weight) + bias
<span class="linenr">114: </span>
<span class="linenr">115: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Loss function</span>
<span class="linenr">116: </span>  losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_out, labels=y_output)
<span class="linenr">117: </span>  loss = tf.reduce_mean(losses)
<span class="linenr">118: </span>
<span class="linenr">119: </span>  accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits_out, <span style="color: #da8548; font-weight: bold;">1</span>), tf.cast(y_output, tf.int64)), tf.float32))
<span class="linenr">120: </span>
<span class="linenr">121: </span>  optimizer = tf.train.RMSPropOptimizer(learning_rate)
<span class="linenr">122: </span>  train_step = optimizer.minimize(loss)
<span class="linenr">123: </span>
<span class="linenr">124: </span>  init = tf.global_variables_initializer()
<span class="linenr">125: </span>  sess.run(init)
<span class="linenr">126: </span>
<span class="linenr">127: </span>  train_loss = []
<span class="linenr">128: </span>  test_loss = []
<span class="linenr">129: </span>  train_accuracy = []
<span class="linenr">130: </span>  test_accuracy = []
<span class="linenr">131: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Start training</span>
<span class="linenr">132: </span>  <span style="color: #51afef;">for</span> epoch <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(epochs):
<span class="linenr">133: </span>
<span class="linenr">134: </span>      <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Shuffle training data</span>
<span class="linenr">135: </span>      shuffled_ix = np.random.permutation(np.arange(<span style="color: #c678dd;">len</span>(x_train)))
<span class="linenr">136: </span>      x_train = x_train[shuffled_ix]
<span class="linenr">137: </span>      y_train = y_train[shuffled_ix]
<span class="linenr">138: </span>      num_batches = <span style="color: #c678dd;">int</span>(<span style="color: #c678dd;">len</span>(x_train)/batch_size) + <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">139: </span>      <span style="color: #5B6268;"># </span><span style="color: #5B6268;">TO DO CALCULATE GENERATIONS ExACTLY</span>
<span class="linenr">140: </span>      <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(num_batches):
<span class="linenr">141: </span>          <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Select train data</span>
<span class="linenr">142: </span>          min_ix = i * batch_size
<span class="linenr">143: </span>          max_ix = np.<span style="color: #c678dd;">min</span>([<span style="color: #c678dd;">len</span>(x_train), ((i+<span style="color: #da8548; font-weight: bold;">1</span>) * batch_size)])
<span class="linenr">144: </span>          x_train_batch = x_train[min_ix:max_ix]
<span class="linenr">145: </span>          y_train_batch = y_train[min_ix:max_ix]
<span class="linenr">146: </span>
<span class="linenr">147: </span>          <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Run train step</span>
<span class="linenr">148: </span>          train_dict = {x_data: x_train_batch, y_output: y_train_batch, dropout_keep_prob:<span style="color: #da8548; font-weight: bold;">0.5</span>}
<span class="linenr">149: </span>          sess.run(train_step, feed_dict=train_dict)
<span class="linenr">150: </span>
<span class="linenr">151: </span>      <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Run loss and accuracy for training</span>
<span class="linenr">152: </span>      temp_train_loss, temp_train_acc = sess.run([loss, accuracy], feed_dict=train_dict)
<span class="linenr">153: </span>      train_loss.append(temp_train_loss)
<span class="linenr">154: </span>      train_accuracy.append(temp_train_acc)
<span class="linenr">155: </span>
<span class="linenr">156: </span>      <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Run Eval Step</span>
<span class="linenr">157: </span>      test_dict = {x_data: x_test, y_output: y_test, dropout_keep_prob:<span style="color: #da8548; font-weight: bold;">1.0</span>}
<span class="linenr">158: </span>      temp_test_loss, temp_test_acc = sess.run([loss, accuracy], feed_dict=test_dict)
<span class="linenr">159: </span>      test_loss.append(temp_test_loss)
<span class="linenr">160: </span>      test_accuracy.append(temp_test_acc)
<span class="linenr">161: </span>      <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Epoch: {}, Test Loss: {:.2}, Test Acc: {:.2}'</span>.<span style="color: #c678dd;">format</span>(epoch+<span style="color: #da8548; font-weight: bold;">1</span>, temp_test_loss, temp_test_acc))
<span class="linenr">162: </span>
<span class="linenr">163: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Plot loss over time</span>
<span class="linenr">164: </span>  epoch_seq = np.arange(<span style="color: #da8548; font-weight: bold;">1</span>, epochs+<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">165: </span>  plt.plot(epoch_seq, train_loss, <span style="color: #98be65;">'k--'</span>, label=<span style="color: #98be65;">'Train Set'</span>)
<span class="linenr">166: </span>  plt.plot(epoch_seq, test_loss, <span style="color: #98be65;">'r-'</span>, label=<span style="color: #98be65;">'Test Set'</span>)
<span class="linenr">167: </span>  plt.title(<span style="color: #98be65;">'Softmax Loss'</span>)
<span class="linenr">168: </span>  plt.xlabel(<span style="color: #98be65;">'Epochs'</span>)
<span class="linenr">169: </span>  plt.ylabel(<span style="color: #98be65;">'Softmax Loss'</span>)
<span class="linenr">170: </span>  plt.legend(loc=<span style="color: #98be65;">'upper left'</span>)
<span class="linenr">171: </span>  plt.show()
<span class="linenr">172: </span>
<span class="linenr">173: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Plot accuracy over time</span>
<span class="linenr">174: </span>  plt.plot(epoch_seq, train_accuracy, <span style="color: #98be65;">'k--'</span>, label=<span style="color: #98be65;">'Train Set'</span>)
<span class="linenr">175: </span>  plt.plot(epoch_seq, test_accuracy, <span style="color: #98be65;">'r-'</span>, label=<span style="color: #98be65;">'Test Set'</span>)
<span class="linenr">176: </span>  plt.title(<span style="color: #98be65;">'Test Accuracy'</span>)
<span class="linenr">177: </span>  plt.xlabel(<span style="color: #98be65;">'Epochs'</span>)
<span class="linenr">178: </span>  plt.ylabel(<span style="color: #98be65;">'Accuracy'</span>)
<span class="linenr">179: </span>  plt.legend(loc=<span style="color: #98be65;">'upper left'</span>)
<span class="linenr">180: </span>  plt.show()
</pre>
</div>
</div>
</li>
</ol>
</div>

<div id="outline-container-org336b4ae" class="outline-3">
<h3 id="org336b4ae"><span class="section-number-3">8.3.</span> AI and Botnet Detection</h3>
<div class="outline-text-3" id="text-8-3">
<p>
<a href="https://github.com/MyDearGreatTeacher/TensorSecurity/tree/master/code/AI_security/%E7%99%BC%E5%B1%95%E8%B6%A8%E5%8B%A2/Botnet">Botnet github</a><br />
IOT honey pot<br />
</p>
</div>

<ol class="org-ol">
<li><a id="org384a574"></a>案例分析<br />
<div class="outline-text-4" id="text-8-3-1">
<p>
Hands-On Artificial Intelligence for Cybersecurity<br />
Alessandro Parisi August 2019<br />
CH 5 Network Anomaly Detection with AI<br />
</p>
</div>
</li>

<li><a id="org38cba80"></a>資料集<br />
<div class="outline-text-4" id="text-8-3-2">
<p>
<a href="https://github.com/MyDearGreatTeacher/AI201909/blob/master/data/network-logs.csv">https://github.com/MyDearGreatTeacher/AI201909/blob/master/data/network-logs.csv</a><br />
</p>

<p>
!wget <a href="https://raw.githubusercontent.com/MyDearGreatTeacher/AI201909/master/data/network-logs.csv">https://raw.githubusercontent.com/MyDearGreatTeacher/AI201909/master/data/network-logs.csv</a><br />
</p>



<div class="org-src-container">
<pre class="src src-csv">  REMOTE_PORT<span style="color: #46D9FF;">   </span>LATENCY<span style="color: #46D9FF;"> </span>THROUGHPUT<span style="color: #46D9FF;">  </span>ANOMALY
  21<span style="color: #46D9FF;">    </span>15.94287532<span style="color: #46D9FF;"> </span>16.20299807<span style="color: #46D9FF;"> </span>0
  20<span style="color: #46D9FF;">    </span>12.66645095<span style="color: #46D9FF;"> </span>15.89908374<span style="color: #46D9FF;"> </span>1
  80<span style="color: #46D9FF;">    </span>13.89454962<span style="color: #46D9FF;"> </span>12.95800822<span style="color: #46D9FF;"> </span>0
  21<span style="color: #46D9FF;">    </span>13.62081292<span style="color: #46D9FF;"> </span>15.45947525<span style="color: #46D9FF;"> </span>0
  21<span style="color: #46D9FF;">    </span>15.70548485<span style="color: #46D9FF;"> </span>15.33956527<span style="color: #46D9FF;"> </span>0
  23<span style="color: #46D9FF;">    </span>15.59318973<span style="color: #46D9FF;"> </span>15.61238106<span style="color: #46D9FF;"> </span>0
  21<span style="color: #46D9FF;">    </span>15.48906755<span style="color: #46D9FF;"> </span>15.64087368<span style="color: #46D9FF;"> </span>0
  80<span style="color: #46D9FF;">    </span>15.52704801<span style="color: #46D9FF;"> </span>15.63568031<span style="color: #46D9FF;"> </span>0
  21<span style="color: #46D9FF;">    </span>14.07506707<span style="color: #46D9FF;"> </span>15.76531533<span style="color: #46D9FF;"> </span>0
  ......
</pre>
</div>

<div class="org-src-container">
<pre class="src src-csv">  &#24310;&#36978;&#65288;Latency&#65289;&#65306;&#19968;&#20491;&#23553;&#21253;&#24478;&#20358;&#28304;&#31471;&#36865;&#20986;&#24460;&#65292;&#21040;&#30446;&#30340;&#31471;&#25509;&#25910;&#21040;&#36889;&#20491;&#23553;&#21253;&#65292;&#20013;&#38291;&#25152;&#33457;&#30340;&#26178;&#38291;&#12290;
  &#38971;&#23532;&#65288;Bandwidth&#65289;&#65306;&#20659;&#36664;&#23186;&#20171;&#30340;&#26368;&#22823;&#21534;&#21520;&#37327;&#65288;throughput&#65289;&#12290;

  https://blog.gtwang.org/web-development/network-lantency-and-bandwidth/
</pre>
</div>
</div>
</li>

<li><a id="orgfd0a261"></a>基本統計分析<br />
<div class="outline-text-4" id="text-8-3-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>!wget https://raw.githubusercontent.com/MyDearGreatTeacher/AI201909/master/data/network-logs.csv
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 4: </span>  <span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 5: </span>  <span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 6: </span>  %matplotlib inline
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span>  <span style="color: #dcaeea;">dataset</span> = pd.read_csv(<span style="color: #98be65;">'network-logs.csv'</span>)
<span class="linenr"> 9: </span>  <span style="color: #dcaeea;">hist_dist</span> = dataset[[<span style="color: #98be65;">'LATENCY'</span>, <span style="color: #98be65;">'THROUGHPUT'</span>]].hist(grid=<span style="color: #a9a1e1;">False</span>, figsize=(<span style="color: #da8548; font-weight: bold;">10</span>,<span style="color: #da8548; font-weight: bold;">4</span>))
<span class="linenr">10: </span>
<span class="linenr">11: </span>  data = dataset[[<span style="color: #98be65;">'LATENCY'</span>, <span style="color: #98be65;">'THROUGHPUT'</span>]].values
<span class="linenr">12: </span>
<span class="linenr">13: </span>  plt.scatter(data[:, <span style="color: #da8548; font-weight: bold;">0</span>], data[:, <span style="color: #da8548; font-weight: bold;">1</span>], alpha=<span style="color: #da8548; font-weight: bold;">0.6</span>)
<span class="linenr">14: </span>  plt.xlabel(<span style="color: #98be65;">'LATENCY'</span>)
<span class="linenr">15: </span>  plt.ylabel(<span style="color: #98be65;">'THROUGHPUT'</span>)
<span class="linenr">16: </span>  plt.title(<span style="color: #98be65;">'DATA FLOW'</span>)
<span class="linenr">17: </span>  plt.show()
</pre>
</div>
</div>
</li>

<li><a id="orga353804"></a>機器學習<br />
<div class="outline-text-4" id="text-8-3-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span>  <span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span>  <span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> *
<span class="linenr"> 5: </span>  <span style="color: #51afef;">from</span> sklearn.tree <span style="color: #51afef;">import</span> *
<span class="linenr"> 6: </span>  <span style="color: #51afef;">from</span> sklearn.naive_bayes <span style="color: #51afef;">import</span> *
<span class="linenr"> 7: </span>  <span style="color: #51afef;">from</span> sklearn.neighbors <span style="color: #51afef;">import</span> *
<span class="linenr"> 8: </span>  <span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> accuracy_score
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>  <span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span class="linenr">11: </span>
<span class="linenr">12: </span>  <span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">13: </span>  %matplotlib inline
<span class="linenr">14: </span>
<span class="linenr">15: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Load the data.</span>
<span class="linenr">16: </span>  <span style="color: #dcaeea;">dataset</span> = pd.read_csv(<span style="color: #98be65;">'network-logs.csv'</span>)
<span class="linenr">17: </span>
<span class="linenr">18: </span>
<span class="linenr">19: </span>  <span style="color: #dcaeea;">samples</span> = dataset.iloc[:, [<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">2</span>]].values <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#21482;&#21462;&#31532;1&#12289;2&#27396;&#30340;&#36039;&#26009;&#30070;features</span>
<span class="linenr">20: </span>  <span style="color: #dcaeea;">targets</span> = dataset[<span style="color: #98be65;">'ANOMALY'</span>].values
<span class="linenr">21: </span>
<span class="linenr">22: </span>  <span style="color: #dcaeea;">training_samples</span>, <span style="color: #dcaeea;">testing_samples</span>, <span style="color: #dcaeea;">training_targets</span>, <span style="color: #dcaeea;">testing_targets</span> = train_test_split(
<span class="linenr">23: </span>           samples, targets, test_size=<span style="color: #da8548; font-weight: bold;">0.3</span>, random_state=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">24: </span>
</pre>
</div>

<p>
接下來就可以套用各種分類演算法<br />
</p>
</div>

<ol class="org-ol">
<li><a id="org67a66dd"></a>使用 k-Nearest Neighbors model<br />
<div class="outline-text-5" id="text-8-3-4-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span>  <span style="color: #dcaeea;">knc</span> = KNeighborsClassifier(n_neighbors=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">2: </span>  knc.fit(training_samples,training_targets)
<span class="linenr">3: </span>  knc_prediction = knc.predict(testing_samples)
<span class="linenr">4: </span>  knc_accuracy = <span style="color: #da8548; font-weight: bold;">100.0</span> * accuracy_score(testing_targets, knc_prediction)
<span class="linenr">5: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">"K-Nearest Neighbours accuracy: "</span> + <span style="color: #c678dd;">str</span>(knc_accuracy))
<span class="linenr">6: </span>
<span class="linenr">7: </span>
</pre>
</div>
</div>
</li>

<li><a id="org8b9d722"></a>使用 Decision tree model<br />
<div class="outline-text-5" id="text-8-3-4-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span>  <span style="color: #dcaeea;">dtc</span> = DecisionTreeClassifier(random_state=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">2: </span>  dtc.fit(training_samples,training_targets)
<span class="linenr">3: </span>  dtc_prediction = dtc.predict(testing_samples)
<span class="linenr">4: </span>  dtc_accuracy = <span style="color: #da8548; font-weight: bold;">100.0</span> * accuracy_score(testing_targets, dtc_prediction)
<span class="linenr">5: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">"Decision Tree accuracy: "</span> + <span style="color: #c678dd;">str</span>(dtc_accuracy))
</pre>
</div>
</div>
</li>

<li><a id="org84c1786"></a>使用 Gaussian Naive Bayes model<br />
<div class="outline-text-5" id="text-8-3-4-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span>  <span style="color: #dcaeea;">gnb</span> = GaussianNB()
<span class="linenr">2: </span>  gnb.fit(training_samples,training_targets)
<span class="linenr">3: </span>  <span style="color: #dcaeea;">gnb_prediction</span> = gnb.predict(testing_samples)
<span class="linenr">4: </span>  <span style="color: #dcaeea;">gnb_accuracy</span> = <span style="color: #da8548; font-weight: bold;">100.0</span> * accuracy_score(testing_targets, gnb_prediction)
<span class="linenr">5: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">"Gaussian Naive Bayes accuracy: "</span> + <span style="color: #c678dd;">str</span>(gnb_accuracy))
<span class="linenr">6: </span>
</pre>
</div>
</div>
</li>
</ol>
</li>

<li><a id="org9bc3b93"></a>結果<br />
<div class="outline-text-4" id="text-8-3-5">
<ul class="org-ul">
<li>K-Nearest Neighbours accuracy: 95.90163934426229<br /></li>
<li>Decision Tree accuracy: 96.72131147540983<br /></li>
<li>Gaussian Naive Bayes accuracy: 98.36065573770492<br /></li>
</ul>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org0c1290f" class="outline-2">
<h2 id="org0c1290f"><span class="section-number-2">9.</span> AI 的學習之路</h2>
<div class="outline-text-2" id="text-9">
</div>
<div id="outline-container-orge50ca60" class="outline-3">
<h3 id="orge50ca60"><span class="section-number-3">9.1.</span> About 學習 AI</h3>
<div class="outline-text-3" id="text-9-1">
</div>
<ol class="org-ol">
<li><a id="org3178f1b"></a>做資料分析時，難的不是演算法，而是如何訂定一些 feature<br /></li>
<li><a id="orga4b00c9"></a>要做 AI，沒有資料怎麼辦？<br />
<div class="outline-text-4" id="text-9-1-2">
<ul class="org-ul">
<li>拍照<br /></li>
<li>找專家先分類<br /></li>
<li>把資料丟進去跑<br /></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgd728c51" class="outline-3">
<h3 id="orgd728c51"><span class="section-number-3">9.2.</span> AI Application Ideas</h3>
<div class="outline-text-3" id="text-9-2">
</div>
<ol class="org-ol">
<li><a id="org229865c"></a>Video<br />
<ol class="org-ol">
<li><a id="orgda36613"></a>錄影時自動偵測被錄者(講者)的位置，然後進行錄影架的左右旋轉、鏡頭的 zoom in/out<br /></li>
<li><a id="orgbda86a1"></a>電影中某角色出現的片斷擷取<br /></li>
<li><a id="orgba76d94"></a>手語解讀<br /></li>
<li><a id="org622b743"></a>黑白電影轉彩色<br /></li>
</ol>
</li>
<li><a id="orgb832ccc"></a>圖片<br />
<ol class="org-ol">
<li><a id="org1e62a5b"></a>自行車選手編號自動識別<br /></li>
<li><a id="orgc1b46f9"></a>輸入物品圖片判斷價格<br /></li>
</ol>
</li>
<li><a id="orgf5a2f7f"></a>聲音<br />
<ol class="org-ol">
<li><a id="org7d3c556"></a>用別人的聲音唱歌<br /></li>
</ol>
</li>
<li><a id="org8d11b2f"></a>文字<br />
<ol class="org-ol">
<li><a id="org28dd6dc"></a>劇本產生器<br /></li>
</ol>
</li>
<li><a id="org087d944"></a>測驗<br /></li>
<li><a id="org4dd873c"></a>指數<br />
<ol class="org-ol">
<li><a id="orgd387e99"></a>股票與 PTT 關係<br /></li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-orga0c5395" class="outline-3">
<h3 id="orga0c5395"><span class="section-number-3">9.3.</span> 相關的比賽</h3>
<div class="outline-text-3" id="text-9-3">
</div>
<ol class="org-ol">
<li><a id="org014d258"></a>台灣的比賽：AIDEA: 人工智慧平台競賽<br />
<ol class="org-ol">
<li><a id="orga7434eb"></a>參加比賽<br />
<div class="outline-text-5" id="text-9-3-1-1">
<ul class="org-ul">
<li><a href="https://aidea-web.tw/aicup_mango">台灣高經濟作物 - 愛文芒果影像辨識正式賽</a><br /></li>
</ul>
</div>
</li>
</ol>
</li>
<li><a id="orgc186ddd"></a>國外的比賽<br />
<div class="outline-text-4" id="text-9-3-2">
<ul class="org-ul">
<li><a href="https://www.kaggle.com/">https://www.kaggle.com/</a><br /></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org968ee42" class="outline-3">
<h3 id="org968ee42"><span class="section-number-3">9.4.</span> AI 時代的 I</h3>
<div class="outline-text-3" id="text-9-4">
<ul class="org-ul">
<li>能做什麼？什麼會被取代？要能歸維、推理、跨領域、具備創造力<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org907d92f" class="outline-3">
<h3 id="org907d92f"><span class="section-number-3">9.5.</span> 學習資源</h3>
<div class="outline-text-3" id="text-9-5">
</div>
<ol class="org-ol">
<li><a id="orgdb1f6a9"></a>書單<br />
<div class="outline-text-4" id="text-9-5-1">
<ul class="org-ul">
<li><a href="https://www.sanmin.com.tw/Product/Index/005848506">OpenCV 3計算機視覺：Python語言實現(原書第2版)</a><br /></li>
<li><a href="https://www.books.com.tw/products/0010761759">Deep Learning：用Python進行深度學習的基礎理論實作</a><br /></li>
<li><a href="https://paperswithcode.com/sota">Browse State-of-the-Art</a><br /></li>
<li><a href="https://www.books.com.tw/products/0010822932">Deep learning 深度學習必讀：Keras 大神帶你用 Python 實作</a><br /></li>
</ul>
</div>
</li>
<li><a id="orga992d1b"></a>線上資源<br />
<div class="outline-text-4" id="text-9-5-2">
<ul class="org-ul">
<li><a href="https://github.com/MyDearGreatTeacher/TensorSecurity">MyDearGreatTeacher/TensorSecurity</a><br /></li>
<li><a href="https://github.com/MyDearGreatTeacher/PyTorch/blob/master/code/LinearRegression.py">MyDearGreatTeacher/PyTorch</a><br /></li>
<li><a href="https://github.com/MyDearGreatTeacher/AI201909">MyDearGreatTeacher/AI201909</a><br /></li>
<li><a href="https://github.com/MyDearGreatTeacher?tab=repositories">MyDearGreatTeacher</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">MIT Convolutional Neural Networks for Visual Recognition (Spring 2017)</a><br /></li>
<li><a href="https://www.packtpub.com/catalogsearch/result/?q=python&amp;released=Available&amp;language=Python">packt電子書</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=J6Ok8p463C4">Getting Started with Keras (AI Adventures) Youtube</a><br /></li>
<li><a href="https://blog.csdn.net/sunqiande88/article/details/80100891">PyTorch實戰2: ResNet-18實現Cifar-10圖像分類</a><br /></li>
<li><a href="https://github.com/activatedgeek/LeNet-5">LeNet-5</a><br /></li>
<li><a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a><br /></li>
<li><a href="https://github.com/nlpinaction/learning-nlp">自然语言处理算法与实战</a><br /></li>
</ul>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org465a292" class="outline-2">
<h2 id="org465a292"><span class="section-number-2">10.</span> AI 的實作平台</h2>
<div class="outline-text-2" id="text-10">
</div>
<div id="outline-container-org64284f9" class="outline-3">
<h3 id="org64284f9"><span class="section-number-3">10.1.</span> Google Colab</h3>
<div class="outline-text-3" id="text-10-1">
</div>
<ol class="org-ol">
<li><a id="orgf8064f0"></a>基本操作<br />
<div class="outline-text-4" id="text-10-1-1">
<ul class="org-ul">
<li>Google 提供的 VM<br /></li>
</ul>
<div class="org-src-container">
<pre class="src src-shell"><span class="linenr">1: </span><span style="color: #51afef; font-weight: bold;">!</span>pwd
<span class="linenr">2: </span><span style="color: #51afef; font-weight: bold;">!</span>cat /proc/meminfo
<span class="linenr">3: </span><span style="color: #51afef; font-weight: bold;">!</span>cat  /proc/cpuinfo
</pre>
</div>
<ul class="org-ul">
<li>use colab to mount google drive<br /></li>
<li>同時最多 5 個 session<br /></li>
<li>每個 session 最多 24hr<br /></li>
<li>查看 colab 已安裝了哪些 package<br /></li>
</ul>
<div class="org-src-container">
<pre class="src src-shell"><span class="linenr">1: </span><span style="color: #51afef; font-weight: bold;">!</span>pip list
</pre>
</div>
</div>
</li>
<li><a id="org2948aea"></a>如何確定有在跑 GPU: <a href="TensorFlow.html">Tensorflow 2020</a><br />
<div class="outline-text-4" id="text-10-1-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr">2: </span><span style="color: #dcaeea;">gpu_name</span> = tf.test.gpu_device_name()
<span class="linenr">3: </span><span style="color: #51afef;">if</span> gpu_name != <span style="color: #98be65;">'/device:GPU:0'</span>:
<span class="linenr">4: </span>  <span style="color: #51afef;">raise</span> <span style="color: #ECBE7B;">SystemError</span>(<span style="color: #98be65;">'&#28961; GPU'</span>)
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'&#26377; GPU: </span>{gpu_name}<span style="color: #98be65;">'</span>)
</pre>
</div>
</div>
</li>
<li><a id="org3eea0aa"></a>如何用 python 上傳本機檔案到 colab<br />
<div class="outline-text-4" id="text-10-1-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> google.colab <span style="color: #51afef;">import</span> files
<span class="linenr">2: </span><span style="color: #dcaeea;">uploaded</span> = files.upload()
</pre>
</div>
</div>
</li>
<li><a id="orgefa0063"></a>如何 mount google drive<br />
<div class="outline-text-4" id="text-10-1-4">
<p>
DEMO<br />
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgea0bd45" class="outline-3">
<h3 id="orgea0bd45"><span class="section-number-3">10.2.</span> Jupyter Notebook</h3>
<div class="outline-text-3" id="text-10-2">
</div>
<ol class="org-ol">
<li><a id="orgf661893"></a><a href="[AI]CNN.html">深度學習:以CNN為例</a><br /></li>
</ol>
</div>
</div>

<div id="outline-container-orgb19b313" class="outline-2">
<h2 id="orgb19b313"><span class="section-number-2">11.</span> 學習資源</h2>
<div class="outline-text-2" id="text-11">
</div>
<div id="outline-container-org116e180" class="outline-3">
<h3 id="org116e180"><span class="section-number-3">11.1.</span> Machine Learning [台大李宏毅]</h3>
<div class="outline-text-3" id="text-11-1">
</div>
<ol class="org-ol">
<li><a id="org2e42139"></a>Lecture 0<br />
<div class="outline-text-4" id="text-11-1-1">
<ul class="org-ul">
<li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html">ML19: 台大[[file:MachineLearning.org][機器學習</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=CXgbekl66jc">ML Lecture 0-1: Introduction of Machine Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=On1N8u1z2Ng">ML Lecture 0-2: Why we need to learn machine learning?</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgd6c8237"></a>Lecture 1<br />
<div class="outline-text-4" id="text-11-1-2">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fegAeph9UaA">ML Lecture 1: Regression - Case Study</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1UqCjFQiiy0">ML Lecture 1: Regression - Demo</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgcb1fbe1"></a>Lecture 2<br />
<div class="outline-text-4" id="text-11-1-3">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=D_S6y0Jm6dQ">ML Lecture 2: Where does the error come from?</a><br /></li>
</ul>
</div>
</li>
<li><a id="org7dc3117"></a>Lecture 3<br />
<div class="outline-text-4" id="text-11-1-4">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=yKKNr-QKz2Q">ML Lecture 3-1: Gradient Descent</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1_HBTJyWgNA">ML Lecture 3-2: Gradient Descent (Demo by AOE)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=wzPAInDF_gI">ML Lecture 3-3: Gradient Descent (Demo by Minecraft)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org078d359"></a>Lecture 4<br />
<div class="outline-text-4" id="text-11-1-5">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fZAZUYEeIMg">ML Lecture 4: Classification</a><br /></li>
</ul>
</div>
</li>
<li><a id="org0f76b12"></a>Lecture 5<br />
<div class="outline-text-4" id="text-11-1-6">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=hSXFuypLukA">ML Lecture 5: Logistic Regression</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgd522aad"></a>Lecture 6<br />
<div class="outline-text-4" id="text-11-1-7">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Dr-WRlEFefw">ML Lecture 6: Brief Introduction of Deep Learning</a><br /></li>
</ul>
</div>
</li>
<li><a id="org9365b74"></a>Lecture 7<br />
<div class="outline-text-4" id="text-11-1-8">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=ibJpTrp5mcE">ML Lecture 7: Backpropagation</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=gDp2LXGnVLQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=3&amp;t=0s">Anomaly Detection (1/7)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4">Next Step of Machine Learning (Hung-yi Lee, NTU, 2019)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org036b19b"></a>Lecture 8<br />
<div class="outline-text-4" id="text-11-1-9">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Lx3l4lOrquw">ML Lecture 8-1: “Hello world” of deep learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=5BJDJd-dzzg">ML Lecture 8-2: Keras 2.0</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=L8unuZNpWw8">ML Lecture 8-3: Keras Demo</a><br /></li>
</ul>
</div>
</li>
<li><a id="org49d888d"></a>Explainable ML<br />
<div class="outline-text-4" id="text-11-1-10">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=lnjrn3bF9lA">Explainable ML (1/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&amp;list=PL9McrqOpq3mUCXF5E8rVLjw8f878zkBfX&amp;index=16">Explainable ML (2/8)</a><br /></li>
<li>Explainable ML (3/8)<br /></li>
<li><a href="https://www.youtube.com/watch?v=yORbWn7UsBs">Explainable ML (4/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (5/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=K1mWgthGS-A">Explainable ML (6/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (7/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Explainable ML (8/8)</a><br /></li>
</ol>
</div>
</li>
<li><a id="org6cb1c4a"></a><span class="todo TODO">TODO</span> Attack ML Models<br />
<div class="outline-text-4" id="text-11-1-11">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=NI6yb0WgMBM">Attack ML Models (1/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=zOdg05BwE7I">Attack ML Models (2/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=F9N5zF7N0qY">Attack ML Models (3/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ">Attack ML Models (4/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=2mgLPZJOHNk">Attack ML Models (5/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=z2nmPDLEXI0">Attack ML Models (6/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=KH48zq2RfBA&amp;t=1s">Attack ML Models (7/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Attack ML Models (8/8)</a><br /></li>
</ol>
</div>
</li>
<li><a id="org0494f1a"></a>Lecture 9<br />
<div class="outline-text-4" id="text-11-1-12">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=xki61j7z-30">ML Lecture 9-1: Tips for Training DNN</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Ky1ku1miDow">ML Lecture 9-2: Keras Demo 2</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=F1vek6ULo9w">ML Lecture 9-3: Fizz Buzz in Tensorflow (sequel)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org38581ec"></a>Lecture 10<br />
<div class="outline-text-4" id="text-11-1-13">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=FrKWiRv254g">ML Lecture 10: Convolutional Neural Network</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=XsC9byQkUH8">ML Lecture 11: Why Deep?</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=fX_guE7JNnY">ML Lecture 12: Semi-supervised</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=iwh5o_M4BNU">ML Lecture 13: Unsupervised Learning - Linear Methods</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=X7PH3NuYW0Q">ML Lecture 14: Unsupervised Learning - Word Embedding</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=GBUEjkpoxXc">ML Lecture 15: Unsupervised Learning - Neighbor Embedding</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=yyKaACh_j3M&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=45&amp;t=0s">Meta Learning – Metric-based (1/3)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Tk5B4seA-AU">ML Lecture 16: Unsupervised Learning - Auto-encoder</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=YNUek8ioAJk">ML Lecture 17: Unsupervised Learning - Deep Generative Model (Part I)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=8zomhgKrsmQ">ML Lecture 18: Unsupervised Learning - Deep Generative Model (Part II)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=48&amp;t=0s">More about Auto-encoder (1/4)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=qD6iD4TFsdQ">ML Lecture 19: Transfer Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=7qT5P9KJnWo&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=25">Life Long Learning (1/7)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ZjfjPzXw6og&amp;feature=youtu.be">Sequence-to-sequence Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=EkAqYbpCYAc&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=33&amp;t=0s">Meta Learning – MAML (1/9)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=QSEPStBgwRQ">ML Lecture 20: Support Vector Machine (SVM)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=xCGidAeyS4M">ML Lecture 21-1: Recurrent Neural Network (Part I)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=rTqmWlnwz_0">ML Lecture 21-2: Recurrent Neural Network (Part II)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=YIuBHB9Ejok&amp;feature=youtu.be">Unsupervised Syntactic Parsing (ft. 莊永松同學)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=tH9FH1DH5n0">ML Lecture 22: Ensemble</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=W8XF3ME8G2I">ML Lecture 23-1: Deep Reinforcement Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=y8UPGr36ccI">ML Lecture 23-2: Policy Gradient (Supplementary Explanation)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=2-JNBzCq77c">ML Lecture 23-3: Reinforcement Learning (including Q-learning)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_">Deep Reinforcement Learning, 2018</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=dPp8rCAnU_A&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=52&amp;t=0s">Network Compression (1/6)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ufcKFjdpT98&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58&amp;t=0s">GAN (Quick Review)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw">Generative Adversarial Network (GAN), 2018</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58">Transformer</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=UYPa347-DdE&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=62&amp;t=0s">ELMO, BERT, GPT</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=uXY18nzdSsM&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=59">Flow-based Generative Model</a><br /></li>
<li><a href="https://brohrer.mcknote.com/zh-Hant/statistics/how_bayesian_inference_works.html">貝葉斯推斷的運作原理</a><br /></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orga5a544c" class="outline-3">
<h3 id="orga5a544c"><span class="section-number-3">11.2.</span> Deep Learning for Human Language Processing (DLHLP) 2020</h3>
<div class="outline-text-3" id="text-11-2">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=nER51ZyJaCQ&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG">[DLHLP 2020] Deep Learning for Human Language Processing (Course Overview)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=AIKu43goh-8&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=2">[DLHLP 2020] Speech Recognition (1/7) - Overview</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=BdUeBa6NbXA&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=3">[DLHLP 2020] Speech Recognition (2/7) - Listen, Attend, Spell</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=CGuLuBaLIeI&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=4">[DLHLP 2020] Speech Recognition (3/7) - CTC, RNN-T and more</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=XWTGY_PNABo&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=5">[DLHLP 2020] Speech Recognition (4/7) - HMM (optional)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=5SSVra6IJY4&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=6">[DLHLP 2020] Speech Recognition (5/7) - Alignment of HMM, CTC and RNN-T (optional)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=gRfTfXCe3LA">[DLHLP 2020] Deep Learning for Question Answering (1/2)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ">[DLHLP 2020] Deep Learning for Question Answering (2/2)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=DOG1L9lvsDY">[DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Bywo7m6ySlk">[DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA">Transformer</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org0c2470a" class="outline-3">
<h3 id="org0c2470a"><span class="section-number-3">11.3.</span> Digital Speech Processing</h3>
<div class="outline-text-3" id="text-11-3">
<ul class="org-ul">
<li><a href="http://ocw.aca.ntu.edu.tw/ntu-ocw/ocw/cou/104S204/1">第一章 Introduction to Digital Speech Processing  </a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org645587e" class="outline-3">
<h3 id="org645587e"><span class="section-number-3">11.4.</span> test</h3>
<div class="outline-text-3" id="text-11-4">
<div class="org-src-container">
<pre class="src src-C"><span class="linenr">1: </span><span style="color: #51afef; font-weight: bold;">#include</span> <span style="color: #98be65;">"stdlib.h"</span>
<span class="linenr">2: </span><span style="color: #51afef; font-weight: bold;">#include</span> <span style="color: #98be65;">"stdio.h"</span>
<span class="linenr">3: </span><span style="color: #ECBE7B;">int</span> <span style="color: #c678dd;">main</span><span style="color: #51afef;">()</span> <span style="color: #51afef;">{</span>
<span class="linenr">4: </span>    printf<span style="color: #c678dd;">(</span><span style="color: #98be65;">"TEST"</span><span style="color: #c678dd;">)</span>;
<span class="linenr">5: </span><span style="color: #51afef;">}</span>
</pre>
</div>

<pre class="example">
TEST
</pre>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.hindawi.com/journals/mpe/2019/2053156/">A Multi-GPU Parallel Algorithm in Hypersonic Flow Computations</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/0010821934?sloc=main">人工智慧在台灣：產業轉型的契機與挑戰，AI應用無所不在，你跟上了嗎？</a><br />
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2022-07-05 Tue 08:52</p>
</div>
</body>
</html>
