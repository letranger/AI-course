<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-07-02 Sat 20:49 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>監督式學習(Supervised Learning)</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/white.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">監督式學習(Supervised Learning)</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org2d271c8">1. 簡介</a>
<ul>
<li><a href="#org95f425d">1.1. 監督式學習的主要類型</a></li>
<li><a href="#org698a6c1">1.2. 特例</a></li>
</ul>
</li>
<li><a href="#org9991376">2. 監督式學習演算法</a>
<ul>
<li><a href="#orga3df5f1">2.1. K-nearest neighbors (KNN)</a></li>
<li><a href="#org3415cd9">2.2. Methods based on tree(Decision tree and Random Forest)</a></li>
<li><a href="#org57edb79">2.3. Boosting</a></li>
<li><a href="#org8d4e424">2.4. SVM(Support Vector Machines)</a></li>
<li><a href="#org7ac72a2">2.5. 神經網路</a></li>
</ul>
</li>
<li><a href="#org066d62c">3. 迴歸原理</a>
<ul>
<li><a href="#org23df5a5">3.1. Step 1</a></li>
<li><a href="#org10396fd">3.2. Step 2: Goodness of Function</a></li>
<li><a href="#orge535a29">3.3. 最短距離分類器</a></li>
<li><a href="#org75198a2">3.4. 迴歸預測流程(以波士頓房價預測為例)</a></li>
</ul>
</li>
<li><a href="#org8d22f84">4. 如何挑選適合的模型</a>
<ul>
<li><a href="#orgbca4930">4.1. overfitting: a more complex model does not always lead to better performance of data training</a></li>
<li><a href="#orgedca430">4.2. 如何預防 overfitting: collect more data</a></li>
</ul>
</li>
<li><a href="#IRIS-KNN">5. 分類實作: IRIS(KNN、DecisionTree)</a>
<ul>
<li><a href="#orga43305a">5.1. 鳶尾花分類問題</a></li>
<li><a href="#org4d2ae75">5.2. KNN實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="iris">iris</span>&#xa0;<span class="KNN">KNN</span>&#xa0;<span class="sklearn">sklearn</span></span></a></li>
<li><a href="#orgda6e036">5.3. 決策樹實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="DecisionTree">DecisionTree</span>&#xa0;<span class="sklearn">sklearn</span></span></a></li>
<li><a href="#org316203a">5.4. bank-loan</a></li>
</ul>
</li>
<li><a href="#org7a86285">6. 分類實作: MNIST(二元分類與多元分類)&#xa0;&#xa0;&#xa0;<span class="tag"><span class="sklearn">sklearn</span>&#xa0;<span class="DSG">DSG</span>&#xa0;<span class="SVM">SVM</span></span></a>
<ul>
<li><a href="#orga4a59df">6.1. MNIST 資料集</a></li>
<li><a href="#org791fe99">6.2. 準備 MNIST 資料</a></li>
<li><a href="#org93d7245">6.3. 查看MNIST內容</a></li>
<li><a href="#orgc268dbd">6.4. 訓練二元分類器</a></li>
<li><a href="#orgd080977">6.5. 多類別分類器</a></li>
<li><a href="#orgcd52da0">6.6. 多標籤分類</a></li>
</ul>
</li>
<li><a href="#orgacdc2f2">7. 分類實作: MNIST(CNN)</a>
<ul>
<li><a href="#org637a136">7.1. 準備 MNIST 資料</a></li>
<li><a href="#org2f0f1c7">7.2. MNIST 的推論處理</a></li>
<li><a href="#org248e404">7.3. Python 與神經網路運算的批次處理</a></li>
<li><a href="#orgb853e80">7.4. MNIST 資料集:以 DNN Sequential 模型為例&#xa0;&#xa0;&#xa0;<span class="tag"><span class="CNN">CNN</span></span></a></li>
<li><a href="#org76585f5">7.5. 其他MNIST教學檔</a></li>
</ul>
</li>
<li><a href="#orge93a902">8. 推薦系統: 受限波爾茲曼機 on MovieLens</a>
<ul>
<li><a href="#orgf4566fe">8.1. 資料準備</a></li>
<li><a href="#org2b4a867">8.2. 定義loss function</a></li>
<li><a href="#orgab8f3a4">8.3. 矩陣分解</a></li>
<li><a href="#orgc1d72c0">8.4. 使用RBMs的協同過濾</a></li>
<li><a href="#org100a22e">8.5. RBM神經網路架構</a></li>
<li><a href="#org223be6e">8.6. 重建RBM元件</a></li>
<li><a href="#org3d2b5f6">8.7. 訓練</a></li>
</ul>
</li>
<li><a href="#org2c41972">9. 深度信念網路(DBNs)</a>
<ul>
<li><a href="#org3b1389d">9.1. MNIST分類</a></li>
<li><a href="#org168ddcd">9.2. Restricted Boltzmann Machines (RBMs)</a></li>
<li><a href="#orgf8f5ea7">9.3. 為DBN訓練三個RBMs</a></li>
<li><a href="#orga454f7a">9.4. 查看RBM誤差</a></li>
<li><a href="#orge685a00">9.5. 檢視特徵偵測器</a></li>
<li><a href="#orgf91ea74">9.6. 查看RBM生成的影像</a></li>
<li><a href="#orgf5f59e5">9.7. 完整的DBN</a></li>
<li><a href="#orgaec32d8">9.8. 訓練DBN</a></li>
<li><a href="#orgbd1c4ac">9.9. 看錯誤</a></li>
<li><a href="#orgcf1a473">9.10. 生成影像以建構更好的影像分類器</a></li>
<li><a href="#org3b31ea2">9.11. 使用DBN來產生新的影像10次</a></li>
<li><a href="#org180ee27">9.12. 使用LightGBM建構影像分類器</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org2d271c8" class="outline-2">
<h2 id="org2d271c8"><span class="section-number-2">1.</span> 簡介</h2>
<div class="outline-text-2" id="text-1">
<p>
監督式學習獲得的結果可以是數值、也可以是類別，以結果分類，我們可以將監督式學分大致分為兩類：迴歸(結果為數值)與為分類(結果為類別)。
</p>
</div>
<div id="outline-container-org95f425d" class="outline-3">
<h3 id="org95f425d"><span class="section-number-3">1.1.</span> 監督式學習的主要類型</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-orgfbbb58d" class="outline-4">
<h4 id="orgfbbb58d"><span class="section-number-4">1.1.1.</span> 分類(Cliasification)</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
分類問題也稱為離散(discrete)預測問題，因為每個分類都是一個離散群組。In supervised learning, the training set you feed to the algorithm includes the desired solutions, called labels<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>.
</p>


<div id="org40c99e2" class="figure">
<p><img src="images/2022-04-30_10-38-58.jpg" alt="2022-04-30_10-38-58.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 1: </span>典型的監督式學習：垃圾郵件分類</p>
</div>

<p>
可再細分為:
</p>
<ul class="org-ul">
<li>Binary classification</li>
<li>Multiclass classification</li>
</ul>

<p>
典型的分類案例: MNIST, IRIS
</p>
</div>
</div>

<div id="outline-container-orgdd44488" class="outline-4">
<h4 id="orgdd44488"><span class="section-number-4">1.1.2.</span> 迴歸(Regression)</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
另一種監督式學習為回歸（regression），即，根據一組預測特徵（predictor，如里程數、車齡、品牌）來預測目標數值（如二手車車價）<sup><a id="fnr.1.100" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>，這個目標數值也是label。
</p>

<p>
有些迴歸演算法也可以用來分類，例如Logistic，它可以輸出一個數值，以這個數值來表示對應到特定類別的機率，例如，某封email為垃圾郵件的機率為20%、某張圖片為狗的機率為70%。
</p>

<p>
迴歸問題可再細分為兩類：
</p>
<ul class="org-ul">
<li>Linear regression:
<ul class="org-ul">
<li>假設輸入變量(x)與單一輸出變量(y)間存在線性關係，並以此建立模型。</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時會導致低度擬合</li>
<li>例: 身高與體重間的關係</li>
</ul></li>
<li>Logistic regression
<ul class="org-ul">
<li>也是線性方法，但使用logist function轉換輸出的預測結果，其輸出結果為類別機率(class probabilities)</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時無法處理分類問題</li>
</ul></li>
</ul>

<p>
典型迴歸案例: Boston Housing Data
</p>
</div>
</div>
</div>

<div id="outline-container-org698a6c1" class="outline-3">
<h3 id="org698a6c1"><span class="section-number-3">1.2.</span> 特例</h3>
<div class="outline-text-3" id="text-1-2">
<p>
監督式學習主要包括分類和回歸，但也包括以下奇特的例子：
</p>
<ul class="org-ul">
<li>序列生成(sequence generation)：給定一張圖，產生一個標題來描述該圖片，有時也可以使用一部份連續的資料進行預測。</li>
<li>語法樹預測(syntax tree prediction)：給定一個句子，以語意的結構為節點，預測並分解成語法樹。</li>
<li>物體偵測(object detection)：給定一張圖片，繪製邊界框來標示圖片內不同的物體。這也可以視為分類問題（給定許多候選邊界框，對每個邊界框的內容進行分類）或并用分類和迴歸技巧，透過向量迴歸預測邊界框。</li>
<li>圖像分割(image segmentation)：給定一張圖片，用像素遮罩(pixel-level mask)來區別不同物體。</li>
<li>Linear Regression: 拿前幾天的空氣 PM 值預估未來的空氣 PM 值</li>
<li>Classification
<ol class="org-ol">
<li>Binary Classification: 垃圾郵件分類</li>
<li>Multi-class Classification: 手語翻譯</li>
<li>k-Nearest Neighbors (KNN)</li>
<li>Naive Bayes Classifiers</li>
<li>Decision Tree</li>
<li>Neural Networks (Deep Learning)</li>
<li>Ensembles of Decision Trees</li>
<li>Linear Models: Logistic regression</li>
</ol></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org9991376" class="outline-2">
<h2 id="org9991376"><span class="section-number-2">2.</span> 監督式學習演算法</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orga3df5f1" class="outline-3">
<h3 id="orga3df5f1"><span class="section-number-3">2.1.</span> K-nearest neighbors (KNN)</h3>
<div class="outline-text-3" id="text-2-1">
<p>
KNN藉由找出與新資料點最相近的 <i>k</i> 個已具有label的資料點，讓這些資料點投票決定新資料點的label。
</p>
<ul class="org-ul">
<li>優點: 能處理更複雜的非線性關係，但仍可被解釋</li>
<li>缺點: 隨著資料與features的數量增加，KNN的效果也會降低； <i>k</i> 值的選擇也會影響KNN的效果，太小的 <i>k</i> 值會導致過度擬合、太高的 <i>k</i> 值則會低度擬合。</li>
<li>應用: 經常用於推薦系統</li>
</ul>
</div>
</div>
<div id="outline-container-org3415cd9" class="outline-3">
<h3 id="org3415cd9"><span class="section-number-3">2.2.</span> Methods based on tree(Decision tree and Random Forest)</h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-org66786f1" class="outline-4">
<h4 id="org66786f1"><span class="section-number-4">2.2.1.</span> Single decision tree: 遍歷所有訓練資枓來建立規則，但容易過度擬合</h4>
</div>
<div id="outline-container-orga34e680" class="outline-4">
<h4 id="orga34e680"><span class="section-number-4">2.2.2.</span> Bagging: 將上述tree加入bootstrap aggregation(如bagging)，即，使用多次隨機實例採樣(multiple random samples of instances)，並為每次採樣建立一棵decision tree，並對每個資料實例進行預測，預測方式為透過平均每棵樹的預測結果，藉由這種方式可以解決decision tree容易過度擬合的問題。</h4>
</div>
<div id="outline-container-orgc6130bb" class="outline-4">
<h4 id="orgc6130bb"><span class="section-number-4">2.2.3.</span> Random forest: 除了將資料實例進行採樣，也對每棵decision tree的分支條件中 <b>待預測label</b> 進䈩隨機採樣，而非使用所有的待預測label。透過這種方式，random forest可以建立出彼此相關性更低的decision，進而改善過度擬合與泛化誤差。</h4>
</div>
</div>
<div id="outline-container-org57edb79" class="outline-3">
<h3 id="org57edb79"><span class="section-number-3">2.3.</span> Boosting</h3>
<div class="outline-text-3" id="text-2-3">
<p>
同樣是建立許多樹，但是它 <b>依多建立每棵decision tree</b> , 利用前一棵decision所習得的資訊來改善下一棵decision tree的預測結果。是所有tree-based solution中表現最好的方式，也是許多machine learning比賽的常勝軍。
</p>
<ul class="org-ul">
<li>優點：performance佳，能處理資料缺失與特徵分類問題</li>
<li>缺點：可解釋性低</li>
</ul>
</div>
</div>
<div id="outline-container-org8d4e424" class="outline-3">
<h3 id="org8d4e424"><span class="section-number-3">2.4.</span> SVM(Support Vector Machines)</h3>
<div class="outline-text-3" id="text-2-4">
<p>
使用演算法和已知的label在空間中建構超平面來分類資料
</p>
</div>
</div>
<div id="outline-container-org7ac72a2" class="outline-3">
<h3 id="org7ac72a2"><span class="section-number-3">2.5.</span> 神經網路</h3>
</div>
</div>

<div id="outline-container-org066d62c" class="outline-2">
<h2 id="org066d62c"><span class="section-number-2">3.</span> 迴歸原理</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org23df5a5" class="outline-3">
<h3 id="org23df5a5"><span class="section-number-3">3.1.</span> Step 1</h3>
<div class="outline-text-3" id="text-3-1">
<ol class="org-ol">
<li>Model: \(y = w*x+b\)</li>
<li>Data: 找一堆現成的資料</li>
</ol>
</div>
</div>
<div id="outline-container-org10396fd" class="outline-3">
<h3 id="org10396fd"><span class="section-number-3">3.2.</span> Step 2: Goodness of Function</h3>
<div class="outline-text-3" id="text-3-2">
<ol class="org-ol">
<li>Training Data</li>
<li>Loss function L: 越小越好
input: a function / output: how bad it is</li>
<li>Pick the &ldquo;Best: Function
\(f* = arg min L(f)\)
上述可以微分來求最佳解，即求 function L 的最小值</li>
<li>數值最佳解: Gradient Descent(找拋物面最低點)</li>
</ol>
</div>
</div>
<div id="outline-container-orge535a29" class="outline-3">
<h3 id="orge535a29"><span class="section-number-3">3.3.</span> 最短距離分類器</h3>
<div class="outline-text-3" id="text-3-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> math
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">from statistics import mean</span>



<span style="color: #5B6268;"># </span><span style="color: #5B6268;">importing reduce()</span>
<span style="color: #51afef;">from</span> functools <span style="color: #51afef;">import</span> <span style="color: #c678dd;">reduce</span>

<span style="color: #51afef;">def</span> <span style="color: #c678dd;">Average</span>(lst):
    <span style="color: #dcaeea;">avgx</span> = <span style="color: #da8548; font-weight: bold;">0</span>
    <span style="color: #dcaeea;">avgy</span> = <span style="color: #da8548; font-weight: bold;">0</span>
    <span style="color: #51afef;">for</span> (x, y) <span style="color: #51afef;">in</span> <span style="color: #dcaeea;">lst</span>:
        avgx += x
        <span style="color: #dcaeea;">avgy</span> += y
    <span style="color: #51afef;">return</span> avgx/<span style="color: #c678dd;">len</span>(lst), avgy/<span style="color: #c678dd;">len</span>(lst)

<span style="color: #51afef;">def</span> <span style="color: #c678dd;">ed</span>(lst, x, y):
    <span style="color: #dcaeea;">dist</span> = <span style="color: #da8548; font-weight: bold;">0</span>
    <span style="color: #51afef;">for</span> (lx, ly) <span style="color: #51afef;">in</span> <span style="color: #dcaeea;">lst</span>:
        dist += (x - lx)*(x - lx) + (y - ly)*(y - ly)
    <span style="color: #51afef;">return</span> math.sqrt(dist)

<span style="color: #dcaeea;">groupA</span> = [[<span style="color: #da8548; font-weight: bold;">4</span>, <span style="color: #da8548; font-weight: bold;">6</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">7</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">8</span>] ,[<span style="color: #da8548; font-weight: bold;">5.8</span>,<span style="color: #da8548; font-weight: bold;">6</span>] ,[<span style="color: #da8548; font-weight: bold;">6</span>,<span style="color: #da8548; font-weight: bold;">6</span>] ,[<span style="color: #da8548; font-weight: bold;">6</span>,<span style="color: #da8548; font-weight: bold;">7</span>] ,[<span style="color: #da8548; font-weight: bold;">7</span>,<span style="color: #da8548; font-weight: bold;">5</span>] ,[<span style="color: #da8548; font-weight: bold;">7</span>,<span style="color: #da8548; font-weight: bold;">7</span>] ,[<span style="color: #da8548; font-weight: bold;">8</span>,<span style="color: #da8548; font-weight: bold;">4</span>] ,[<span style="color: #da8548; font-weight: bold;">9</span>,<span style="color: #da8548; font-weight: bold;">5</span>]]
<span style="color: #dcaeea;">groupB</span> = [[<span style="color: #da8548; font-weight: bold;">2</span>,<span style="color: #da8548; font-weight: bold;">2</span>] ,[<span style="color: #da8548; font-weight: bold;">4</span>,<span style="color: #da8548; font-weight: bold;">2</span>] ,[<span style="color: #da8548; font-weight: bold;">4</span>,<span style="color: #da8548; font-weight: bold;">4</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">4</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">3</span>] ,[<span style="color: #da8548; font-weight: bold;">6</span>,<span style="color: #da8548; font-weight: bold;">2</span>]]

<span style="color: #dcaeea;">tarx</span> = <span style="color: #da8548; font-weight: bold;">5</span>
<span style="color: #dcaeea;">tary</span> = <span style="color: #da8548; font-weight: bold;">5</span>

<span style="color: #dcaeea;">centerX</span>, <span style="color: #dcaeea;">centerY</span> = Average(groupA)
<span style="color: #dcaeea;">sdA</span> = (tarx - centerX)*(tarx - centerX)
<span style="color: #dcaeea;">centerX</span>, <span style="color: #dcaeea;">centerY</span> = Average(groupB)
<span style="color: #dcaeea;">sdB</span> = (tarx - centerX)*(tarx - centerX)

<span style="color: #51afef;">if</span> sdA &lt; sdB:
    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"A"</span>)
<span style="color: #51afef;">else</span>:
    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"B"</span>)

<span style="color: #c678dd;">print</span>(ed(groupA, tarx, tary))
<span style="color: #c678dd;">print</span>(ed(groupB, tarx, tary))


</pre>
</div>

<pre class="example">
B
7.851114570556208
6.708203932499369
</pre>
</div>
</div>
<div id="outline-container-org75198a2" class="outline-3">
<h3 id="org75198a2"><span class="section-number-3">3.4.</span> 迴歸預測流程(以波士頓房價預測為例)</h3>
<div class="outline-text-3" id="text-3-4">
<ol class="org-ol">
<li>Import the required module</li>
<li>Load and configure the Boston housing data set</li>
<li>Chekc the relation between the variable, using pairplot and correlation graph</li>
<li>Descriptive statistics: central tendency and dispersion</li>
<li>Select the required columns</li>
<li>Train the test split</li>
<li>Normalize the data</li>
<li>Build the input pipeline for the TensorFlow model</li>
<li>Model tranining</li>
<li>Predictions</li>
<li>Validation</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org8d22f84" class="outline-2">
<h2 id="org8d22f84"><span class="section-number-2">4.</span> 如何挑選適合的模型</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-orgbca4930" class="outline-3">
<h3 id="orgbca4930"><span class="section-number-3">4.1.</span> overfitting: a more complex model does not always lead to better performance of data training</h3>
</div>
<div id="outline-container-orgedca430" class="outline-3">
<h3 id="orgedca430"><span class="section-number-3">4.2.</span> 如何預防 overfitting: collect more data</h3>
</div>
</div>

<div id="outline-container-IRIS-KNN" class="outline-2">
<h2 id="IRIS-KNN"><span class="section-number-2">5.</span> 分類實作: IRIS(KNN、DecisionTree)</h2>
<div class="outline-text-2" id="text-IRIS-KNN">
<p>
:CUSTOM_ID: IRIS-KNN
</p>
<p>
K-NearestNeighbor分類算法是機器學習裡監督類學習中最簡單的方法之一,由Cover和Hart在1968年提出。kNN算法的核心思想是如果一個樣本在特徵空間中的k個最相鄰的樣本中的大多數屬於某一個類別，則該樣本也屬於這個類別，並具有這個類別上樣本的特性。
</p>

<p>
KNN為 lazy learner(惰性學習器)的典型例子，所謂惰性是指它不會從「訓練數據集」中學習出「判別函數」(discriminative function)，它的作法是把「訓練數據集」記憶起來。其步驟如下：
</p>
<ol class="org-ol">
<li>選定 k 的值和一個「距離度量」(distance metric)。</li>
<li>找出 k 個想要分類的、最相近的鄰近樣本。</li>
<li>以多數決的方式指定類別標籤。</li>
</ol>
</div>
<div id="outline-container-orga43305a" class="outline-3">
<h3 id="orga43305a"><span class="section-number-3">5.1.</span> 鳶尾花分類問題</h3>
<div class="outline-text-3" id="text-5-1">
</div>
<div id="outline-container-org85ee2e4" class="outline-4">
<h4 id="org85ee2e4"><span class="section-number-4">5.1.1.</span> DataSet</h4>
<div class="outline-text-4" id="text-5-1-1">
<p>
收集了3種鳶尾花的四個特徵，分別是花萼(sepal)長寬、花瓣(petal)長寬度，以及對應的鳶尾花種類。
</p>

<div id="org37b0349" class="figure">
<p><img src="images/iris-1.png" alt="iris-1.png" width="400" />
</p>
<p><span class="figure-number">Figure 2: </span>鳶尾花的花萼與花瓣</p>
</div>
</div>
</div>
<div id="outline-container-org1db0189" class="outline-4">
<h4 id="org1db0189"><span class="section-number-4">5.1.2.</span> Mission</h4>
<div class="outline-text-4" id="text-5-1-2">
<p>
輸入花萼和花瓣數據後，推測所屬的鳶尾花類型。
</p>

<div id="org7f82292" class="figure">
<p><img src="images/iris-2.png" alt="iris-2.png" width="600" />
</p>
<p><span class="figure-number">Figure 3: </span>三種鳶尾花</p>
</div>
</div>
</div>
<div id="outline-container-orgffe4a48" class="outline-4">
<h4 id="orgffe4a48"><span class="section-number-4">5.1.3.</span> 實作</h4>
<div class="outline-text-4" id="text-5-1-3">
<ol class="org-ol">
<li><p>
讀取資料集
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> datasets

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35712;&#20837;&#36039;&#26009;</span>
<span style="color: #dcaeea;">iris</span> = datasets.load_iris()
<span style="color: #c678dd;">print</span>(iris.DESCR)
</pre>
</div></li>

<li><p>
取出特徵與標籤
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #dcaeea;">x</span> = iris.data
<span style="color: #dcaeea;">y</span> = iris.target
<span style="color: #c678dd;">print</span>(x[:<span style="color: #da8548; font-weight: bold;">5</span>])
<span style="color: #c678dd;">print</span>(y[:<span style="color: #da8548; font-weight: bold;">5</span>])
</pre>
</div></li>
<li><p>
資料觀察
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25226;nupmy ndarray&#36681;&#28858;pandas dataFrame,&#21152;&#19978;columns title</span>
<span style="color: #dcaeea;">npx</span> = pd.DataFrame(x, columns=[<span style="color: #98be65;">'fac1'</span>,<span style="color: #98be65;">'fac2'</span>,<span style="color: #98be65;">'fac3'</span>,<span style="color: #98be65;">'fac4'</span>])
npy = pd.DataFrame(y.astype(<span style="color: #c678dd;">int</span>), columns=[<span style="color: #98be65;">'category'</span>])
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#21512;&#20341;</span>
dataPD = pd.concat([npx, npy], axis=<span style="color: #da8548; font-weight: bold;">1</span>)
<span style="color: #c678dd;">print</span>(dataPD)
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30059;&#22294;</span>
sns.lmplot(<span style="color: #98be65;">'fac1'</span>, <span style="color: #98be65;">'fac2'</span>, data=dataPD, hue=<span style="color: #98be65;">'category'</span>, fit_reg=<span style="color: #a9a1e1;">False</span>)
plt.show()
</pre>
</div></li>

<li><p>
分割資料集
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21123;&#20998;&#36039;&#26009;&#38598;</span>
<span style="color: #dcaeea;">x_train</span>, <span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = train_test_split(iris.data, iris.target, random_state=<span style="color: #da8548; font-weight: bold;">6</span>)
</pre>
</div>
<ul class="org-ul">
<li>train_test_split()
所接受的變數其實非常單純，基本上為 3 項：『原始的資料』、『Seed』、『比例』
<ol class="org-ol">
<li>原始的資料：就如同上方的 data 一般，是我們打算切成 Training data 以及 Test data 的原始資料</li>
<li>Seed： 亂數種子，可以固定我們切割資料的結果</li>
<li>比例：可以設定 train_size 或 test_size，只要設定一邊即可，範圍在 [0-1] 之間</li>
</ol></li>
<li><p>
scikit-learn.org: sklearn.model_selection.train_test_split
</p>

<p>
Split arrays or matrices into random train and test subsets
</p>

<p>
Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.
</p>
<div class="org-src-container">
<pre class="src src-python"> sklearn.model_selection.train_test_split(*arrays, test_size=<span style="color: #a9a1e1;">None</span>, train_size=<span style="color: #a9a1e1;">None</span>, random_state=<span style="color: #a9a1e1;">None</span>, shuffle=<span style="color: #a9a1e1;">True</span>, stratify=<span style="color: #a9a1e1;">None</span>)[source]
</pre>
</div>
<ul class="org-ul">
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">online docs</a></li>
</ul></li>
</ul></li>

<li><p>
資料標準化
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#36039;&#26009;&#27161;&#28310;&#21270;: &#21033;&#29992;preprocessing&#27169;&#32068;&#35041;&#30340;StandardScaler&#39006;&#21029;</span>
<span style="color: #51afef;">from</span> sklearn.preprocessing <span style="color: #51afef;">import</span> StandardScaler
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21033;&#29992;fit&#26041;&#27861;&#65292;&#23565;X_train&#20013;&#27599;&#20491;&#29305;&#24501;&#20540;&#20272;&#24179;&#22343;&#25976;&#21644;&#27161;&#28310;&#24046;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#28982;&#24460;&#23565;&#27599;&#20491;&#29305;&#24501;&#20540;&#36914;&#34892;&#27161;&#28310;&#21270;(train&#21644;test&#37117;&#35201;&#20570;)</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29305;&#24501;&#24037;&#31243;&#65306;&#27161;&#28310;&#21270;</span>
transfer = StandardScaler()
<span style="color: #dcaeea;">x_train</span> = transfer.fit_transform(x_train)
<span style="color: #dcaeea;">x_test</span> = transfer.fit_transform(x_test)
</pre>
</div></li>

<li><p>
分類
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.neighbors <span style="color: #51afef;">import</span> KNeighborsClassifier
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">KNN &#20998;&#39006;&#22120;</span>
<span style="color: #dcaeea;">estimator</span> = KNeighborsClassifier(n_neighbors=<span style="color: #da8548; font-weight: bold;">1</span>)
estimator.fit(x_train, y_train)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27169;&#22411;&#35413;&#20272;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#19968;&#65306;&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;</span>
y_predict = estimator.predict(x_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'y_predict&#65306;\n'</span>, y_predict)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;:\n'</span>, y_test == y_predict)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#20108;&#65306;&#35336;&#31639;&#28310;&#30906;&#29575;</span>
score = estimator.score(x_test, y_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;:\n'</span>, score)
</pre>
</div></li>
</ol>
</div>
</div>
<div id="outline-container-orgfbecf6f" class="outline-4">
<h4 id="orgfbecf6f"><span class="section-number-4">5.1.4.</span> 作業</h4>
<div class="outline-text-4" id="text-5-1-4">
<p>
修改上述程式碼，以折線圖表示K值與KNN預測準確度間的關係。
</p>
</div>
</div>
</div>
<div id="outline-container-org4d2ae75" class="outline-3">
<h3 id="org4d2ae75"><span class="section-number-3">5.2.</span> KNN實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="iris">iris</span>&#xa0;<span class="KNN">KNN</span>&#xa0;<span class="sklearn">sklearn</span></span></h3>
<div class="outline-text-3" id="text-5-2">
<p>
K-NearestNeighbor分類算法是機器學習裡監督類學習中最簡單的方法之一,由Cover和Hart在1968年提出。kNN算法的核心思想是如果一個樣本在特徵空間中的k個最相鄰的樣本中的大多數屬於某一個類別，則該樣本也屬於這個類別，並具有這個類別上樣本的特性。
</p>

<p>
KNN為 lazy learner(惰性學習器)的典型例子，所謂惰性是指它不會從「訓練數據集」中學習出「判別函數」(discriminative function)，它的作法是把「訓練數據集」記憶起來。其步驟如下：
</p>
<ol class="org-ol">
<li>選定 k 的值和一個「距離度量」(distance metric)。</li>
<li>找出 k 個想要分類的、最相近的鄰近樣本。</li>
<li>以多數決的方式指定類別標籤。</li>
</ol>
</div>

<div id="outline-container-org86ff0a8" class="outline-4">
<h4 id="org86ff0a8"><span class="section-number-4">5.2.1.</span> 實作</h4>
<div class="outline-text-4" id="text-5-2-1">
<ol class="org-ol">
<li><p>
讀取資料集
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> datasets

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35712;&#20837;&#36039;&#26009;</span>
<span style="color: #dcaeea;">iris</span> = datasets.load_iris()
<span style="color: #c678dd;">print</span>(iris.DESCR)
</pre>
</div></li>

<li><p>
取出特徵與標籤
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #dcaeea;">x</span> = iris.data
<span style="color: #dcaeea;">y</span> = iris.target
<span style="color: #c678dd;">print</span>(x[:<span style="color: #da8548; font-weight: bold;">5</span>])
<span style="color: #c678dd;">print</span>(y[:<span style="color: #da8548; font-weight: bold;">5</span>])
</pre>
</div></li>
<li><p>
資料觀察
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25226;nupmy ndarray&#36681;&#28858;pandas dataFrame,&#21152;&#19978;columns title</span>
<span style="color: #dcaeea;">npx</span> = pd.DataFrame(x, columns=[<span style="color: #98be65;">'fac1'</span>,<span style="color: #98be65;">'fac2'</span>,<span style="color: #98be65;">'fac3'</span>,<span style="color: #98be65;">'fac4'</span>])
npy = pd.DataFrame(y.astype(<span style="color: #c678dd;">int</span>), columns=[<span style="color: #98be65;">'category'</span>])
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#21512;&#20341;</span>
dataPD = pd.concat([npx, npy], axis=<span style="color: #da8548; font-weight: bold;">1</span>)
<span style="color: #c678dd;">print</span>(dataPD)
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30059;&#22294;</span>
sns.lmplot(<span style="color: #98be65;">'fac1'</span>, <span style="color: #98be65;">'fac2'</span>, data=dataPD, hue=<span style="color: #98be65;">'category'</span>, fit_reg=<span style="color: #a9a1e1;">False</span>)
plt.show()
</pre>
</div></li>

<li><p>
分割資料集
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21123;&#20998;&#36039;&#26009;&#38598;</span>
<span style="color: #dcaeea;">x_train</span>, <span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = train_test_split(iris.data, iris.target, random_state=<span style="color: #da8548; font-weight: bold;">6</span>)
</pre>
</div>
<ul class="org-ul">
<li>train_test_split()
所接受的變數其實非常單純，基本上為 3 項：『原始的資料』、『Seed』、『比例』
<ol class="org-ol">
<li>原始的資料：就如同上方的 data 一般，是我們打算切成 Training data 以及 Test data 的原始資料</li>
<li>Seed： 亂數種子，可以固定我們切割資料的結果</li>
<li>比例：可以設定 train_size 或 test_size，只要設定一邊即可，範圍在 [0-1] 之間</li>
</ol></li>
<li><p>
scikit-learn.org: sklearn.model_selection.train_test_split
</p>

<p>
Split arrays or matrices into random train and test subsets
</p>

<p>
Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.
</p>
<div class="org-src-container">
<pre class="src src-python"> sklearn.model_selection.train_test_split(*arrays, test_size=<span style="color: #a9a1e1;">None</span>, train_size=<span style="color: #a9a1e1;">None</span>, random_state=<span style="color: #a9a1e1;">None</span>, shuffle=<span style="color: #a9a1e1;">True</span>, stratify=<span style="color: #a9a1e1;">None</span>)[source]
</pre>
</div>
<ul class="org-ul">
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">online docs</a></li>
</ul></li>
</ul></li>

<li><p>
資料標準化
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#36039;&#26009;&#27161;&#28310;&#21270;: &#21033;&#29992;preprocessing&#27169;&#32068;&#35041;&#30340;StandardScaler&#39006;&#21029;</span>
<span style="color: #51afef;">from</span> sklearn.preprocessing <span style="color: #51afef;">import</span> StandardScaler
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21033;&#29992;fit&#26041;&#27861;&#65292;&#23565;X_train&#20013;&#27599;&#20491;&#29305;&#24501;&#20540;&#20272;&#24179;&#22343;&#25976;&#21644;&#27161;&#28310;&#24046;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#28982;&#24460;&#23565;&#27599;&#20491;&#29305;&#24501;&#20540;&#36914;&#34892;&#27161;&#28310;&#21270;(train&#21644;test&#37117;&#35201;&#20570;)</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29305;&#24501;&#24037;&#31243;&#65306;&#27161;&#28310;&#21270;</span>
transfer = StandardScaler()
<span style="color: #dcaeea;">x_train</span> = transfer.fit_transform(x_train)
<span style="color: #dcaeea;">x_test</span> = transfer.fit_transform(x_test)
</pre>
</div></li>

<li><p>
分類
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.neighbors <span style="color: #51afef;">import</span> KNeighborsClassifier
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">KNN &#20998;&#39006;&#22120;</span>
<span style="color: #dcaeea;">estimator</span> = KNeighborsClassifier(n_neighbors=<span style="color: #da8548; font-weight: bold;">1</span>)
estimator.fit(x_train, y_train)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27169;&#22411;&#35413;&#20272;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#19968;&#65306;&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;</span>
y_predict = estimator.predict(x_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'y_predict&#65306;\n'</span>, y_predict)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;:\n'</span>, y_test == y_predict)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#20108;&#65306;&#35336;&#31639;&#28310;&#30906;&#29575;</span>
score = estimator.score(x_test, y_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;:\n'</span>, score)
</pre>
</div></li>
</ol>
</div>
</div>

<div id="outline-container-org163fbe7" class="outline-4">
<h4 id="org163fbe7"><span class="section-number-4">5.2.2.</span> TNFSH作業&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></h4>
<div class="outline-text-4" id="text-5-2-2">
<p>
修改上述程式碼，以折線圖表示K值與KNN預測準確度間的關係。
</p>
</div>
</div>
</div>
<div id="outline-container-orgda6e036" class="outline-3">
<h3 id="orgda6e036"><span class="section-number-3">5.3.</span> 決策樹實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="DecisionTree">DecisionTree</span>&#xa0;<span class="sklearn">sklearn</span></span></h3>
<div class="outline-text-3" id="text-5-3">
<p>
一棵複雜的決策樹
</p>

<div id="orga162fb4" class="figure">
<p><img src="images/SBQNWUA1dDtFsMHv.png" alt="SBQNWUA1dDtFsMHv.png" width="800" />
</p>
<p><span class="figure-number">Figure 4: </span>Caption</p>
</div>
</div>
<div id="outline-container-org1f74f85" class="outline-4">
<h4 id="org1f74f85"><span class="section-number-4">5.3.1.</span> iris</h4>
<div class="outline-text-4" id="text-5-3-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> load_iris
<span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> tree
<span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">Load in our dataset</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;"># &#35712;&#20837;&#40182;&#23614;&#33457;&#36039;&#26009;</span>
<span style="color: #dcaeea;">iris</span> = load_iris()
<span style="color: #dcaeea;">iris_x</span> = iris.data
<span style="color: #dcaeea;">iris_y</span> = iris.target

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20999;&#20998;&#35347;&#32244;&#33287;&#28204;&#35430;&#36039;&#26009;</span>
<span style="color: #dcaeea;">train_x</span>, <span style="color: #dcaeea;">test_x</span>, <span style="color: #dcaeea;">train_y</span>, <span style="color: #dcaeea;">test_y</span> = train_test_split(iris_x, iris_y, test_size = <span style="color: #da8548; font-weight: bold;">0.3</span>)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24314;&#31435;&#20998;&#39006;&#22120;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">Initialize our decision tree object</span>
classification_tree = tree.DecisionTreeClassifier(criterion = <span style="color: #98be65;">"entropy"</span>)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">Train our decision tree (tree induction + pruning)</span>
classification_tree = classification_tree.fit(iris_x, iris_y)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38928;&#28204;</span>
test_y_predicted = classification_tree.predict(test_x)
<span style="color: #c678dd;">print</span>(test_y_predicted)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27161;&#28310;&#31572;&#26696;</span>
<span style="color: #c678dd;">print</span>(test_y)


<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#24471;&#20998;:'</span>,classification_tree.score(iris_x, iris_y))
<span style="color: #51afef;">import</span> graphviz

<span style="color: #51afef;">import</span> pydot
<span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
plt.clf()
dot_data = tree.export_graphviz(classification_tree, out_file=<span style="color: #a9a1e1;">None</span>,
                     feature_names=iris.feature_names,
                     class_names=iris.target_names,
                     filled=<span style="color: #a9a1e1;">True</span>, rounded=<span style="color: #a9a1e1;">True</span>,
                     special_characters=<span style="color: #a9a1e1;">True</span>)
graph = graphviz.Source(dot_data)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">graph.render("images/DecisionTree.png", view=True)</span>
graph.<span style="color: #c678dd;">format</span> = <span style="color: #98be65;">'png'</span>
graph.render(<span style="color: #98be65;">'images/DecisionTree'</span>)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.savefig('images/DecisionTree.png', dpi=300)</span>

</pre>
</div>

<pre class="example">
[0 0 0 0 1 2 0 1 0 2 2 0 2 2 2 2 2 1 1 1 0 2 1 1 2 1 2 2 0 2 0 1 0 2 0 2 2
 0 1 1 1 2 2 0 0]
[0 0 0 0 1 2 0 1 0 2 2 0 2 2 2 2 2 1 1 1 0 2 1 1 2 1 2 2 0 2 0 1 0 2 0 2 2
 0 1 1 1 2 2 0 0]
得分: 1.0
</pre>



<div id="org01af12e" class="figure">
<p><img src="images/DecisionTree.png" alt="DecisionTree.png" width="800" />
</p>
<p><span class="figure-number">Figure 5: </span>Decision Tree</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org316203a" class="outline-3">
<h3 id="org316203a"><span class="section-number-3">5.4.</span> bank-loan<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup></h3>
<div class="outline-text-3" id="text-5-4">
<ol class="org-ol">
<li><p>
Load the data and finish the cleaning process
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #5B6268;">#</span><span style="color: #5B6268;">the dataset is available on kaggle too</span>
<span style="color: #dcaeea;">train</span> = pd.read_csv(<span style="color: #98be65;">'/kaggle/input/bank-loan2/madfhantr.csv'</span>)

<span style="color: #5B6268;">#</span><span style="color: #5B6268;">check for missing values</span>
train.isnull().<span style="color: #c678dd;">sum</span>()
</pre>
</div>

<p>
There are two possible ways to either fill the null values with some value or drop all the missing values(I dropped all the missing values).
</p>

<p>
If you look at the original dataset’s shape, it is (614,13), and the new data-set after dropping the null values is (480,13).
</p>
<div class="org-src-container">
<pre class="src src-python">train.dropna(inplace=<span style="color: #a9a1e1;">True</span>)
</pre>
</div></li>
<li><p>
Take a Look at the data-set
We found there are many categorical values in the dataset
Howevern, The decision tree does not support categorical data as features.
</p>

<p>
So the optimal step to take at this point is you can use feature engineering techniques like label encoding and one hot label encoding.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5B6268;"># </span><span style="color: #5B6268;">I selected few of the columns from the dataset for this tutorial</span>
<span style="color: #dcaeea;">train</span> = train[[<span style="color: #98be65;">'Gender'</span>,<span style="color: #98be65;">'Married'</span>,<span style="color: #98be65;">'Education'</span>,<span style="color: #98be65;">'Self_Employed'</span>,<span style="color: #98be65;">'Credit_History'</span>,<span style="color: #98be65;">'Loan_Status'</span>]]

<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Gender'</span>]=train[<span style="color: #98be65;">'Gender'</span>].replace(to_replace=<span style="color: #98be65;">'Male'</span>,value=<span style="color: #98be65;">'1'</span>)
train[<span style="color: #98be65;">'Gender'</span>]=train[<span style="color: #98be65;">'Gender'</span>].replace(to_replace=<span style="color: #98be65;">'Female'</span>,value=<span style="color: #98be65;">'0'</span>)


train[<span style="color: #98be65;">'Married'</span>]=train[<span style="color: #98be65;">'Married'</span>].replace(to_replace=<span style="color: #98be65;">'Yes'</span>,value=<span style="color: #98be65;">'1'</span>)
train[<span style="color: #98be65;">'Married'</span>]=train[<span style="color: #98be65;">'Married'</span>].replace(to_replace=<span style="color: #98be65;">'No'</span>,value=<span style="color: #98be65;">'0'</span>)


train[<span style="color: #98be65;">'Self_Employed'</span>]=train[<span style="color: #98be65;">'Self_Employed'</span>].replace(to_replace=<span style="color: #98be65;">'No'</span>,value=<span style="color: #98be65;">'0'</span>)
train[<span style="color: #98be65;">'Self_Employed'</span>]=train[<span style="color: #98be65;">'Self_Employed'</span>].replace(to_replace=<span style="color: #98be65;">'Yes'</span>,value=<span style="color: #98be65;">'1'</span>)


train[<span style="color: #98be65;">'Education'</span>]=train[<span style="color: #98be65;">'Education'</span>].replace(to_replace=<span style="color: #98be65;">'Graduate'</span>,value=<span style="color: #98be65;">'1'</span>)
train[<span style="color: #98be65;">'Education'</span>]=train[<span style="color: #98be65;">'Education'</span>].replace(to_replace=<span style="color: #98be65;">'Not Graduate'</span>,value=<span style="color: #98be65;">'0'</span>)
</pre>
</div></li>

<li><p>
Split the data-set into train and test sets
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #dcaeea;">X</span> = train.drop(columns=[<span style="color: #98be65;">'Loan_Status'</span>])
y = train.Loan_Status


<span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span style="color: #dcaeea;">X_train</span>,<span style="color: #dcaeea;">X_test</span>,<span style="color: #dcaeea;">y_train</span>,<span style="color: #dcaeea;">y_test</span> = train_test_split(X,y,test_size=<span style="color: #da8548; font-weight: bold;">0.3</span>,random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
</pre>
</div>
<p>
Why should we split the data before training a machine learning algorithm?
</p>

<p>
Please visit <a href="https://medium.com/@snji.khjuria/everything-you-need-to-know-about-train-dev-test-split-what-how-and-why-6ca17ea6f35">Sanjeev’s article</a> regarding training, development, test, and splitting of the data for detailed reasoning.
</p></li>

<li><p>
Build the model and fit the train set.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.tree <span style="color: #51afef;">import</span> DecisionTreeClassifier
<span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> tree

<span style="color: #dcaeea;">clf</span> = tree.DecisionTreeClassifier(max_depth=<span style="color: #da8548; font-weight: bold;">3</span>)
clf.fit(X_train,y_train)
</pre>
</div>
<p>
Before we visualize the tree, let us do some calculations and find out the root node by using Entropy.
</p>
<ul class="org-ul">
<li>Calculation 1: Find the Entropy of the total dataset</li>

<li>Calculation 2: Now find the Entropy and gain for every column</li>

<li></li>
</ul></li>
<li><p>
Visualize the Decision Tree
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> graphviz
<span style="color: #dcaeea;">dot_data</span> = tree.export_graphviz(clf, out_file=<span style="color: #a9a1e1;">None</span>,
                               feature_names=[<span style="color: #98be65;">'Gender'</span>,<span style="color: #98be65;">'Married'</span>,<span style="color: #98be65;">'Education'</span>,<span style="color: #98be65;">'Self_Employed'</span>,<span style="color: #98be65;">'Credit_History'</span>],
                               class_names=[<span style="color: #98be65;">'Yes'</span>,<span style="color: #98be65;">'No'</span>],filled=<span style="color: #a9a1e1;">True</span>,
                                rounded=<span style="color: #a9a1e1;">True</span>,
                              special_characters=<span style="color: #a9a1e1;">True</span>)
graph = graphviz.Source(dot_data)
graph.render(<span style="color: #98be65;">"Gini"</span>)
graph
</pre>
</div>
<p>
Well, it’s like we got the calculations right!
</p>

<p>
So the same procedure repeats until there is no possibility for further splitting.
</p></li>
<li><p>
Check the score of the model
</p>
<div class="org-src-container">
<pre class="src src-python">clf.score(X_test,y_test)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">output = 0.7986111111111112</span>
</pre>
</div>
<p>
We almost got 80% percent accuracy. Which is a decent score for this type of problem statement?
</p></li>
</ol>
</div>
<div id="outline-container-org85bced7" class="outline-4">
<h4 id="org85bced7"><span class="section-number-4">5.4.1.</span> DEMO</h4>
<div class="outline-text-4" id="text-5-4-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">1. Load the data and finish the cleaning process</span>
<span style="color: #5B6268;">##    </span><span style="color: #5B6268;">the dataset is available on kaggle too</span>
<span style="color: #dcaeea;">train</span> = pd.read_csv(<span style="color: #98be65;">'./madfhantr.csv'</span>)

<span style="color: #5B6268;">#</span><span style="color: #5B6268;">check for missing values</span>
train.isnull().<span style="color: #c678dd;">sum</span>()
<span style="color: #5B6268;">#</span>
train.dropna(inplace=<span style="color: #a9a1e1;">True</span>)
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">2. Take a Look at the data-set</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">I selected few of the columns from the dataset for this tutorial</span>
train = train[[<span style="color: #98be65;">'Gender'</span>,<span style="color: #98be65;">'Married'</span>,<span style="color: #98be65;">'Education'</span>,<span style="color: #98be65;">'Self_Employed'</span>,<span style="color: #98be65;">'Credit_History'</span>,<span style="color: #98be65;">'Loan_Status'</span>]]

train[<span style="color: #98be65;">'Gender'</span>]=train[<span style="color: #98be65;">'Gender'</span>].replace(to_replace=<span style="color: #98be65;">'Male'</span>,value=<span style="color: #98be65;">'1'</span>)
train[<span style="color: #98be65;">'Gender'</span>]=train[<span style="color: #98be65;">'Gender'</span>].replace(to_replace=<span style="color: #98be65;">'Female'</span>,value=<span style="color: #98be65;">'0'</span>)


train[<span style="color: #98be65;">'Married'</span>]=train[<span style="color: #98be65;">'Married'</span>].replace(to_replace=<span style="color: #98be65;">'Yes'</span>,value=<span style="color: #98be65;">'1'</span>)
train[<span style="color: #98be65;">'Married'</span>]=train[<span style="color: #98be65;">'Married'</span>].replace(to_replace=<span style="color: #98be65;">'No'</span>,value=<span style="color: #98be65;">'0'</span>)


train[<span style="color: #98be65;">'Self_Employed'</span>]=train[<span style="color: #98be65;">'Self_Employed'</span>].replace(to_replace=<span style="color: #98be65;">'No'</span>,value=<span style="color: #98be65;">'0'</span>)
train[<span style="color: #98be65;">'Self_Employed'</span>]=train[<span style="color: #98be65;">'Self_Employed'</span>].replace(to_replace=<span style="color: #98be65;">'Yes'</span>,value=<span style="color: #98be65;">'1'</span>)


train[<span style="color: #98be65;">'Education'</span>]=train[<span style="color: #98be65;">'Education'</span>].replace(to_replace=<span style="color: #98be65;">'Graduate'</span>,value=<span style="color: #98be65;">'1'</span>)
train[<span style="color: #98be65;">'Education'</span>]=train[<span style="color: #98be65;">'Education'</span>].replace(to_replace=<span style="color: #98be65;">'Not Graduate'</span>,value=<span style="color: #98be65;">'0'</span>)
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">3. Split the data-set into train and test sets</span>
X = train.drop(columns=[<span style="color: #98be65;">'Loan_Status'</span>])
y = train.Loan_Status


<span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span style="color: #dcaeea;">X_train</span>,<span style="color: #dcaeea;">X_test</span>,<span style="color: #dcaeea;">y_train</span>,<span style="color: #dcaeea;">y_test</span> = train_test_split(X,y,test_size=<span style="color: #da8548; font-weight: bold;">0.3</span>,random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">4. Build the model and fit the train set.</span>
<span style="color: #51afef;">from</span> sklearn.tree <span style="color: #51afef;">import</span> DecisionTreeClassifier
<span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> tree

clf = tree.DecisionTreeClassifier(max_depth=<span style="color: #da8548; font-weight: bold;">3</span>)
clf = clf.fit(X_train,y_train)
<span style="color: #c678dd;">print</span>(clf.score(X_train, y_train))
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">5. Visualize the Decision Tree</span>
<span style="color: #51afef;">import</span> graphviz
dot_data = tree.export_graphviz(clf, out_file=<span style="color: #a9a1e1;">None</span>,
                               feature_names=[<span style="color: #98be65;">'Gender'</span>,<span style="color: #98be65;">'Married'</span>,<span style="color: #98be65;">'Education'</span>,<span style="color: #98be65;">'Self_Employed'</span>,<span style="color: #98be65;">'Credit_History'</span>],
                               class_names=[<span style="color: #98be65;">'Yes'</span>,<span style="color: #98be65;">'No'</span>],filled=<span style="color: #a9a1e1;">True</span>,
                                rounded=<span style="color: #a9a1e1;">True</span>,
                              special_characters=<span style="color: #a9a1e1;">True</span>)
graph = graphviz.Source(dot_data)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">graph.render("Gini")</span>
graph.<span style="color: #c678dd;">format</span> = <span style="color: #98be65;">'png'</span>
graph.render(<span style="color: #98be65;">'images/DecisionTree2'</span>)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">graph</span>
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">6. Check the score of the model</span>
clf.score(X_test,y_test)
</pre>
</div>

<pre class="example">
0.8125
</pre>


<div id="org96228f2" class="figure">
<p><img src="images/DecisionTree2.png" alt="DecisionTree2.png" width="800" />
</p>
<p><span class="figure-number">Figure 6: </span>Bank Load 2</p>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-org7a86285" class="outline-2">
<h2 id="org7a86285"><span class="section-number-2">6.</span> 分類實作: MNIST(二元分類與多元分類)&#xa0;&#xa0;&#xa0;<span class="tag"><span class="sklearn">sklearn</span>&#xa0;<span class="DSG">DSG</span>&#xa0;<span class="SVM">SVM</span></span></h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-orga4a59df" class="outline-3">
<h3 id="orga4a59df"><span class="section-number-3">6.1.</span> MNIST 資料集</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>MNIST 是機器學習領域中相當著名的資料集，因為太多研究者使用，故號稱機器學習領域的「Hello world.」，其重要性不言可喻。</li>
<li>MNIST 資料集由 0~9 的數字影像構成(如圖<a href="#org239764f">7</a>)，共計 70000 張訓練影像、10000 張測試影像。</li>
<li>由美國高中生和人口普查局員工手寫。</li>
<li>一般的 MMIST 資料集的用法為：使用訓練影像進行學習，再利用學習後的模型預測能否正確分類測試影像。</li>
</ul>

<div id="org239764f" class="figure">
<p><img src="images/MNIST.jpg" alt="MNIST.jpg" width="400" />
</p>
<p><span class="figure-number">Figure 7: </span>MNIST 資料集內容範例</p>
</div>
</div>
</div>
<div id="outline-container-org791fe99" class="outline-3">
<h3 id="org791fe99"><span class="section-number-3">6.2.</span> 準備 MNIST 資料</h3>
<div class="outline-text-3" id="text-6-2">
<p>
MNIST 數據集來自美國國家標準與技術研究所, National Institute of Standards and Technology (NIST). 訓練集 (training set) 由來自 250 個不同人手寫的數字構成, 其中 50% 是高中學生, 50% 來自人口普查局 (the Census Bureau) 的工作人員. 測試集(test set) 也是同樣比例的手寫數字數據。MNIST 數據集可在 <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> 獲取, 它包含了四個部分:
</p>
<ol class="org-ol">
<li>Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解壓後 47 MB, 包含 60,000 個樣本)</li>
<li>Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解壓後 60 KB, 包含 60,000 個標籤)</li>
<li>Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解壓後 7.8 MB, 包含 10,000 個樣本)</li>
<li>Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解壓後 10 KB, 包含 10,000 個標籤)</li>
</ol>
</div>
<div id="outline-container-orgc8ca1af" class="outline-4">
<h4 id="orgc8ca1af"><span class="section-number-4">6.2.1.</span> 以Scikit-Learn下載</h4>
<div class="outline-text-4" id="text-6-2-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span style="color: #dcaeea;">mnist</span> = fetch_openml(<span style="color: #98be65;">'mnist_784'</span>, version=<span style="color: #da8548; font-weight: bold;">1</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(mnist.keys())
</pre>
</div>

<pre class="example">
dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])
</pre>

<p>
大部份可以下載的資料組都長會有data、target(label)、DESCR等屬性。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(mnist))
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(mnist[<span style="color: #98be65;">'data'</span>].shape)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(mnist[<span style="color: #98be65;">'target'</span>].shape)
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(mnist[<span style="color: #98be65;">'DESCR'</span>][<span style="color: #da8548; font-weight: bold;">0</span>:<span style="color: #da8548; font-weight: bold;">100</span>])
</pre>
</div>

<pre class="example">
&lt;class 'sklearn.utils.Bunch'&gt;
(70000, 784)
(70000,)
**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges
**Source**: [MNIST Website](http:/
</pre>



<p>
每一個手寫數字以一個長度為784 (28*28)的list儲存
</p>
</div>
</div>
<div id="outline-container-org503c9c0" class="outline-4">
<h4 id="org503c9c0"><span class="section-number-4">6.2.2.</span> 以tensorflow下載</h4>
<div class="outline-text-4" id="text-6-2-2">
<p>
MNIST 資料集是一個適合拿來當作 TensotFlow 的練習素材，在 Tensorflow 的現有套件中，也已經有內建好的 MNIST 資料集，我們只要在安裝好 TensorFlow 的 Python 環境中執行以下程式碼，即可將 MNIST 資料成功讀取進來。.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span id="coderef-get-keras-mnist" class="coderef-off">(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()</span>
</pre>
</div>
<p>
在訓練模型之前，需要將樣本資料劃分為訓練集、測試集，有些情況下還會劃分為訓練集、測試集、驗證集。由上述程式第<a href="#coderef-get-keras-mnist" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-get-keras-mnist');" onmouseout="CodeHighlightOff(this, 'coderef-get-keras-mnist');">3</a>行可知，下載後的 MNIST 資料分成訓練資料(training data)與測試資料(testing data)，其中 x 為圖片、y為所對應數字。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 2: </span><span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 3: </span>(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21028;&#26039;&#36039;&#26009;&#24418;&#29376;</span>
<span class="linenr"> 6: </span><span style="color: #c678dd;">print</span>(x_train.shape)
<span class="linenr"> 7: </span><span style="color: #c678dd;">print</span>(x_test.shape)
<span class="linenr"> 8: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31532;&#19968;&#20491;label&#30340;&#20839;&#23481;</span>
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034;&#24433;&#20687;&#20839;&#23481;</span>
<span class="linenr">11: </span><span style="color: #51afef;">import</span> matplotlib.pylab <span style="color: #51afef;">as</span> plt
<span class="linenr">12: </span><span style="color: #dcaeea;">img</span> = x_train[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">13: </span>plt.imshow(img)
<span class="linenr">14: </span>plt.savefig(<span style="color: #98be65;">"MNIST-Image.png"</span>)
</pre>
</div>
<pre class="example">
(60000, 28, 28)
(10000, 28, 28)
5
</pre>


<p>
由上述程式輸出結果可以看到載入的 x 為大小為 28*28 的圖片共 60000 張，每一筆 MNIST 資料的照片(x)由 784 個 pixels 組成（28*28），照片內容如圖<a href="#org2d23b75">8</a>，訓練集的標籤(y)則為其對應的數字(0～9)，此例為 5。
</p>

<div id="org2d23b75" class="figure">
<p><img src="images/MNIST-Image.png" alt="MNIST-Image.png" width="300" />
</p>
<p><span class="figure-number">Figure 8: </span>MNIST 影像示例</p>
</div>

<p>
x 的影像資料為灰階影像，每個像素的數值介於 0~255 之間，矩陣裡每一項的資料則是代表每個 pixel 顏色深淺的數值，如下圖<a href="#orgdd0513c">9</a>所示：
</p>

<div id="orgdd0513c" class="figure">
<p><img src="images/MNIST-Matrix.png" alt="MNIST-Matrix.png" width="300" />
</p>
<p><span class="figure-number">Figure 9: </span>MNIST 資料矩陣</p>
</div>

<p>
載入的 y 為所對應的數字 0~9，在這我們要運用 keras 中的 np_utils.to_categorical 將 y 轉成 one-hot 的形式，將他轉為一個 10 維的 vector，例如：我們所拿到的資料為 y=3，經過 np_utils.to_categorical，會轉換為 y=[0,0,0,1,0,0,0,0,0,0]。這部份的轉換程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> mnist
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> keras.utils <span style="color: #51afef;">import</span> np_utils
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span>  <span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 5: </span>  <span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 6: </span>  (x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 7: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 8: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#22294;&#29255;&#36681;&#25563;&#28858;&#19968;&#20491;60000*784&#30340;&#21521;&#37327;&#65292;&#20006;&#19988;&#27161;&#28310;&#21270;</span>
<span class="linenr"> 9: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.reshape(x_train.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">10: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.reshape(x_test.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">11: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">12: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">13: </span>  <span style="color: #dcaeea;">x_train</span> = x_train/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">14: </span>  <span style="color: #dcaeea;">x_test</span> = x_test/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">15: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;y&#36681;&#25563;&#25104;one-hot encoding</span>
<span class="linenr">16: </span>  <span style="color: #dcaeea;">y_train</span> = np_utils.to_categorical(y_train, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">17: </span>  <span style="color: #dcaeea;">y_test</span> = np_utils.to_categorical(y_test, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">18: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22238;&#20659;&#34389;&#29702;&#23436;&#30340;&#36039;&#26009;</span>
<span class="linenr">19: </span>  <span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">20: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">21: </span>  np.set_printoptions(precision=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">22: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">print(x_train[0])</span>
</pre>
</div>

<pre class="example">
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
</pre>
</div>
</div>
</div>
<div id="outline-container-org93d7245" class="outline-3">
<h3 id="org93d7245"><span class="section-number-3">6.3.</span> 查看MNIST內容</h3>
<div class="outline-text-3" id="text-6-3">
</div>
<div id="outline-container-org013eef7" class="outline-4">
<h4 id="org013eef7"><span class="section-number-4">6.3.1.</span> 先把bunch存起來</h4>
<div class="outline-text-4" id="text-6-3-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr">2: </span><span style="color: #dcaeea;">mnist</span> = fetch_openml(<span style="color: #98be65;">'mnist_784'</span>, version=<span style="color: #da8548; font-weight: bold;">1</span>, as_frame=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">3: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#22240;&#28858;fetch_openml&#38928;&#35373;&#26371;&#20659;&#22238;pandas&#30340;dataframe&#65292;&#26371;&#21547;column&#30340;title&#65292;&#21487;&#20197;&#23559;as_frame&#35373;&#28858;false</span>
<span class="linenr">4: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr">5: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'wb'</span>) <span style="color: #51afef;">as</span> bunch:
<span class="linenr">6: </span>    pickle.dump(mnist, bunch, protocol=pickle.HIGHEST_PROTOCOL)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt;
</pre>
</div>
</div>
<div id="outline-container-org8797e43" class="outline-4">
<h4 id="org8797e43"><span class="section-number-4">6.3.2.</span> 再讀回pkl</h4>
<div class="outline-text-4" id="text-6-3-2">
<p>
此時讀回mnist無header, index，適合分析
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr"> 3: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> <span style="color: #dcaeea;">bunch</span>:
<span class="linenr"> 4: </span>    mnist = pickle.load(bunch)
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #dcaeea;">one_digit</span> = X[<span style="color: #da8548; font-weight: bold;">9527</span>]
<span class="linenr">11: </span><span style="color: #dcaeea;">one_digit_image</span> = one_digit.reshape(<span style="color: #da8548; font-weight: bold;">28</span>, <span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20197;&#22294;&#29255;&#21576;&#29694;</span>
<span class="linenr">14: </span>plt.imshow(one_digit_image)
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">'images/Mnist9527.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">16: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(y[<span style="color: #da8548; font-weight: bold;">9527</span>]))
<span class="linenr">17: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">18: </span>y = y.astype(np.uint8)
<span class="linenr">19: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(y[<span style="color: #da8548; font-weight: bold;">9527</span>]))
</pre>
</div>

<pre class="example">
&lt;class 'str'&gt;
&lt;class 'numpy.uint8'&gt;
</pre>


<div id="org2030daf" class="figure">
<p><img src="images/MNIST9527.png" alt="MNIST9527.png" width="300" />
</p>
<p><span class="figure-number">Figure 10: </span>Caption</p>
</div>
<ul class="org-ul">
<li>多數的演算法label均期望為數字，故應改為int (np.unit8())</li>
<li><p>
分為測試組與訓練組最好是label 0~9平均分佈，MNIST已事先安排好(前60000張為訓練組)
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30001;&#36889;&#20491;&#23531;&#27861;&#21487;&#20197;&#29702;&#35299;&#28858;&#20160;&#40636;index&#30340;&#35486;&#27861;&#35201;&#36889;&#27171;&#35373;&#35336;</span>
<span class="linenr">2: </span>  <span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
</pre>
</div></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc268dbd" class="outline-3">
<h3 id="orgc268dbd"><span class="section-number-3">6.4.</span> 訓練二元分類器</h3>
<div class="outline-text-3" id="text-6-4">
<p>
先簡化分類工作: 每次辨識是否為某一數字(如2)
</p>
</div>
<div id="outline-container-orgbcb7557" class="outline-4">
<h4 id="orgbcb7557"><span class="section-number-4">6.4.1.</span> 先建立目標向量</h4>
<div class="outline-text-4" id="text-6-4-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">y_train_is2</span> = (y_train == <span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">2: </span>y_test_is2 = (y_test ==<span style="color: #da8548; font-weight: bold;">2</span>)
</pre>
</div>

<p>
Scikit-Learn的SDGClassifier可高效處理大量資料庫，也十分適合線上學習系統。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35712;&#20837;data set</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr"> 4: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> <span style="color: #dcaeea;">bunch</span>:
<span class="linenr"> 5: </span>    mnist = pickle.load(bunch)
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr"> 8: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 9: </span><span style="color: #dcaeea;">y</span> = y.astype(np.uint8)
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#28858;&#28204;&#35430;&#32068;&#33287;&#35347;&#32244;&#32068;</span>
<span class="linenr">12: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20108;&#20803;&#20998;&#39006;&#30446;&#27161;&#20989;&#24335;</span>
<span class="linenr">14: </span><span style="color: #dcaeea;">y_train_is2</span> = (y_train == <span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">15: </span>y_test_is2 = (y_test ==<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">16: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;model</span>
<span class="linenr">17: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> SGDClassifier
<span class="linenr">18: </span>sgd_clf = SGDClassifier(max_iter=<span style="color: #da8548; font-weight: bold;">1000</span>, tol=1e-<span style="color: #da8548; font-weight: bold;">3</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">19: </span>sgd_clf.fit(X_train, y_train_is2)
<span class="linenr">20: </span><span style="color: #c678dd;">print</span>(sgd_clf)
<span class="linenr">21: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29992;&#20358;&#38928;&#28204;&#31532;9527&#34399;&#22294;&#29255;(labe&#28858;2)</span>
<span class="linenr">22: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(X[<span style="color: #da8548; font-weight: bold;">9527</span>])) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">ndarray</span>
<span class="linenr">23: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>([X[<span style="color: #da8548; font-weight: bold;">9527</span>]])) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">list</span>
<span class="linenr">24: </span>result = sgd_clf.predict([X[<span style="color: #da8548; font-weight: bold;">9527</span>]]) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#28858;&#20160;&#40636;&#21482;&#33021;&#19999;list&#36914;&#21435;?</span>
<span class="linenr">25: </span><span style="color: #c678dd;">print</span>(result, <span style="color: #98be65;">'label: '</span>, y[<span style="color: #da8548; font-weight: bold;">9527</span>])
<span class="linenr">26: </span>result = sgd_clf.predict([X[<span style="color: #da8548; font-weight: bold;">9528</span>]])
<span class="linenr">27: </span><span style="color: #c678dd;">print</span>(result, <span style="color: #98be65;">'label: '</span>,y[<span style="color: #da8548; font-weight: bold;">9528</span>])
<span class="linenr">28: </span>
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; SGDClassifier(random_state=42)
&lt;class 'numpy.ndarray'&gt;
&lt;class 'list'&gt;
[ True] label:  2
[False] label:  8
</pre>
</div>
</div>
<div id="outline-container-orgae62b12" class="outline-4">
<h4 id="orgae62b12"><span class="section-number-4">6.4.2.</span> 效能評估</h4>
<div class="outline-text-4" id="text-6-4-2">
</div>
<ol class="org-ol">
<li><a id="orga8507a1"></a>K-folder 交叉驗證: 把訓練集拆成K個fold<br />
<div class="outline-text-5" id="text-6-4-2-1">

<div id="orgeafcdaf" class="figure">
<p><img src="images/20200312143156767.png" alt="20200312143156767.png" width="500" />
</p>
<p><span class="figure-number">Figure 11: </span>Cross Validation</p>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_score <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30475;&#24471;&#20998;</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">scores</span> = cross_val_score(sgd_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(scores)
</pre>
</div>

<pre class="example">
[0.96645 0.95895 0.904  ]
</pre>
</div>
</li>
<li><a id="org534e1f7"></a>測試一下其他數字的效能<br />
<div class="outline-text-5" id="text-6-4-2-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24314;&#31435;&#19968;&#20491;&#21028;&#26039;&#26159;&#21542;&#28858;&#25976;&#23383;7&#30340;&#30446;&#27161;&#20989;&#24335;</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">y_train_is7</span> = (y_train == <span style="color: #da8548; font-weight: bold;">7</span>)
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35347;&#32244;</span>
<span class="linenr">5: </span>sgd_clf.fit(X_train, y_train_is7)
<span class="linenr">6: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35413;&#20998;</span>
<span class="linenr">7: </span>scores = cross_val_score(sgd_clf, X_train, y_train_is7, cv=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(scores)
</pre>
</div>
<pre class="example">
[0.98033333 0.9825     0.97333333 0.97725    0.97633333]
</pre>
</div>
</li>
<li><a id="orgb7bdd72"></a>混淆矩陣<br />
<div class="outline-text-5" id="text-6-4-2-3">
<p>
評估分類器的較佳工具為confusion matrx，其原理為查看類別A被判定為類別B的次數
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr">2: </span><span style="color: #dcaeea;">y_train_pred</span> = cross_val_predict(sgd_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> confusion_matrix
<span class="linenr">5: </span>result = confusion_matrix(y_train_is7, y_train_pred)
<span class="linenr">6: </span>
<span class="linenr">7: </span><span style="color: #c678dd;">print</span>(y_train_pred)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(result)
</pre>
</div>

<pre class="example">
[False False False ... False False False]
[[46293  7442]
 [ 6153   112]]
</pre>


<p>
cross_val_predict傳回對各個測試fold進行的預測，confusion matrix傳回的矩陣值如下
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">實際為7</th>
<th scope="col" class="org-left">實際不是7</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">預測為7</td>
<td class="org-left">TP(True Positive)</td>
<td class="org-left">FP(False Positive)</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Type I Error</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">預測不是7</td>
<td class="org-left">FN(False Negative)</td>
<td class="org-left">TN(True Negative)</td>
</tr>

<tr>
<td class="org-left">Type II Error</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>
<p>
結果表示：60000張圖片中有46293被model <b>正確預測</b> 為7、有112張被model <b>正確預測</b> 不是7。
</p>

<div id="org1a2abea" class="figure">
<p><img src="images/2022-05-05_15-30-09.jpg" alt="2022-05-05_15-30-09.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 12: </span>Caption</p>
</div>
</div>
</li>
<li><a id="org97cd20f"></a>幾種不同的precision指標<br />
<ol class="org-ol">
<li><a id="orgf215052"></a>Precision<br />
<div class="outline-text-6" id="text-6-4-2-4-1">
<p>
\[precision=\frac{TP}{TP+FP}\]
這種評估方式的問題在於只做陽性預測的準確率，忽略了positive之外的問題。就是只對 <b>預測出為7</b> 的那些case感興趣
</p>
</div>
</li>
<li><a id="org53be6b3"></a>Recall<br />
<div class="outline-text-6" id="text-6-4-2-4-2">
<p>
\[ recall=\frac{TP}{TP+FN} \]
也叫sensitivity，這是分類器正確認出positve實例的比例，就是只對 <b>實際為7</b> 的那些例子感興趣，
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr">2: </span><span style="color: #dcaeea;">y_train_pred</span> = cross_val_predict(sgd_clf, X_train, y_train_is7, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> precision_score, recall_score
<span class="linenr">5: </span>
<span class="linenr">6: </span>preScore = precision_score(y_train_is7, y_train_pred)
<span class="linenr">7: </span>recScore = recall_score(y_train_is7, y_train_pred)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Precision Score: </span>{preScore}<span style="color: #98be65;">'</span>)
<span class="linenr">9: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Rescore Score: </span>{recScore}<span style="color: #98be65;">'</span>)
</pre>
</div>
<pre class="example">
Precision Score: 0.8285544495617293
Rescore Score: 0.8901835594573024
</pre>
</div>
</li>
<li><a id="org92521a1"></a>Precision與Recall的取捨<br />
<div class="outline-text-6" id="text-6-4-2-4-3">
<ul class="org-ul">
<li>兒童影片分類: 寧可錯殺(low recall)，希望能多找出兒童不宜的影片(高precision)，可以犧牲recall</li>
<li>監控小偷的影片分類：希望recall多一點，只要實際有小偷，就一定要判斷出來，可以犧牲precision</li>
<li>地震：recall要高，情願發出1000次警報，把10次地震都預測正確了；也不要預測100次對了8次漏了兩次。</li>
<li>嫌疑人定罪:基於不錯怪一個好人的原則，對於嫌疑人的定罪我們希望是非常準確的。及時有時候放過了一些罪犯（recall低），但也是值得的。</li>
<li>森林大火呢</li>
</ul>
</div>
</li>
<li><a id="org578964d"></a>\[F_1\]<br />
<div class="outline-text-6" id="text-6-4-2-4-4">
<p>
另一種整合precision與recall的評量標準
\[F_1=\frac{2}{\frac{1}{precision}+\frac{1}{recall}}\]
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> f1_score
<span class="linenr">2: </span><span style="color: #dcaeea;">f1Score</span> = f1_score(y_train_is7, y_train_pred)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'F1 score: </span>{f1Score}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
F1 score: 0.8582640812557709
</pre>
</div>
</li>
</ol>
</li>
<li><a id="org9a22f53"></a>Precision, Recall, Threhold<br />
<div class="outline-text-5" id="text-6-4-2-5">
<p>
Scikit-Learn以決策函數來為每個instance算分數，若分數大於某個threshold(閥值)，就設為positive，否則就為negative。
</p>

<div id="org042301e" class="figure">
<p><img src="images/2022-05-05_15-31-03.png" alt="2022-05-05_15-31-03.png" width="500" />
</p>
<p><span class="figure-number">Figure 13: </span>Caption</p>
</div>


<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #dcaeea;">sgd_clf</span> = SGDClassifier(max_iter=<span style="color: #da8548; font-weight: bold;">1000</span>, tol=1e-<span style="color: #da8548; font-weight: bold;">3</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr"> 2: </span>sgd_clf.fit(X_train, y_train_is2)
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span>y_scores = sgd_clf.decision_function([X[<span style="color: #da8548; font-weight: bold;">9527</span>]])
<span class="linenr"> 5: </span><span style="color: #c678dd;">print</span>(y_scores)
<span class="linenr"> 6: </span>threshold = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr"> 7: </span>y_scores = cross_val_predict(sgd_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>, method=<span style="color: #98be65;">"decision_function"</span>)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> precision_recall_curve
<span class="linenr">10: </span>precisions, recalls, thresholds = precision_recall_curve(y_train_is2, y_scores)
<span class="linenr">11: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'precision: </span>{precisions}<span style="color: #98be65;">'</span>)
<span class="linenr">12: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'recalls: </span>{recalls}<span style="color: #98be65;">'</span>)
<span class="linenr">13: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'thresholds: </span>{thresholds}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
[6878.3086925]
precision: [0.10072015 0.10070495 0.10070665 ... 1.         1.         1.        ]
recalls: [1.00000000e+00 9.99832158e-01 9.99832158e-01 ... 3.35683115e-04
 1.67841558e-04 0.00000000e+00]
thresholds: [-69733.7356162  -69719.34570155 -69711.85512195 ...  56894.63040719
  59479.43254173  59763.44817006]
</pre>

<p>
二者間的關係
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 2: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_precision_recall_vs_threshold</span>(precisions, recalls, thresholds):
<span class="linenr"> 3: </span>    plt.plot(thresholds, precisions[:-<span style="color: #da8548; font-weight: bold;">1</span>], <span style="color: #98be65;">"b--"</span>, label=<span style="color: #98be65;">"Precision"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr"> 4: </span>    plt.plot(thresholds, recalls[:-<span style="color: #da8548; font-weight: bold;">1</span>], <span style="color: #98be65;">"g-"</span>, label=<span style="color: #98be65;">"Recall"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr"> 5: </span>    plt.legend(loc=<span style="color: #98be65;">"center right"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 6: </span>    plt.xlabel(<span style="color: #98be65;">"Threshold"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 7: </span>    plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr"> 8: </span>    plt.axis([-<span style="color: #da8548; font-weight: bold;">50000</span>, <span style="color: #da8548; font-weight: bold;">50000</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>])             <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Not shown</span>
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>recall_90_precision = recalls[np.argmax(precisions &gt;= <span style="color: #da8548; font-weight: bold;">0.90</span>)]
<span class="linenr">11: </span>threshold_90_precision = thresholds[np.argmax(precisions &gt;= <span style="color: #da8548; font-weight: bold;">0.90</span>)]
<span class="linenr">12: </span>
<span class="linenr">13: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">4</span>))
<span class="linenr">14: </span>plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
<span class="linenr">15: </span>plt.plot([threshold_90_precision, threshold_90_precision], [<span style="color: #da8548; font-weight: bold;">0</span>., <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">16: </span>plt.plot([-<span style="color: #da8548; font-weight: bold;">50000</span>, threshold_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>, <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">17: </span>plt.plot([-<span style="color: #da8548; font-weight: bold;">50000</span>, threshold_90_precision], [recall_90_precision, recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">18: </span>plt.plot([threshold_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">19: </span>plt.plot([threshold_90_precision], [recall_90_precision], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">20: </span>plt.savefig(<span style="color: #98be65;">"images/precision_recall_vs_threshold_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">21: </span>plt.show()
<span class="linenr">22: </span>
</pre>
</div>

<p width="500">
<img src="images/precision_recall_vs_threshold_plot.png" alt="precision_recall_vs_threshold_plot.png" width="500" />
要做出precision與recall的取捨，另一種方式是畫出二者的關係圖
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_precision_vs_recall</span>(precisions, recalls):
<span class="linenr"> 2: </span>    plt.plot(recalls, precisions, <span style="color: #98be65;">"b-"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>)&#65292;
<span class="linenr"> 3: </span>    plt.xlabel(<span style="color: #98be65;">"Recall"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 4: </span>    plt.ylabel(<span style="color: #98be65;">"Precision"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 5: </span>    plt.axis([<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr"> 6: </span>    plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr"> 9: </span>plot_precision_vs_recall(precisions, recalls)
<span class="linenr">10: </span>plt.plot([recall_90_precision, recall_90_precision], [<span style="color: #da8548; font-weight: bold;">0</span>., <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">11: </span>plt.plot([<span style="color: #da8548; font-weight: bold;">0.0</span>, recall_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>, <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">12: </span>plt.plot([recall_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">13: </span>plt.savefig(<span style="color: #98be65;">"images/precision_vs_recall_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">14: </span>plt.show()
</pre>
</div>

<p width="500">
<img src="images/precision_vs_recall_plot.png" alt="precision_vs_recall_plot.png" width="500" />
若目標為90%的precision(如圖<a href="#org7fb1d3f">14</a>)，其threshold大約在8000，若要求較精確的值，可以透過np.argmax()
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">threshold_90_precision</span> = thresholds[np.argmax(precisions &gt;= <span style="color: #da8548; font-weight: bold;">0.90</span>)]
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(threshold_90_precision)
<span class="linenr">3: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#20197;&#36889;&#20491;threshold&#20358;&#21462;&#20195;&#20998;&#39006;&#22120;&#20013;&#30340;predict()</span>
<span class="linenr">4: </span><span style="color: #dcaeea;">y_train_pred_90</span> = (y_scores &gt;= threshold_90_precision)
<span class="linenr">5: </span><span style="color: #dcaeea;">nPreSco</span> = precision_score(y_train_is2, y_train_pred_90)
<span class="linenr">6: </span><span style="color: #dcaeea;">nRecSco</span> = recall_score(y_train_is2, y_train_pred_90)
<span class="linenr">7: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'New precision score: </span>{nPreSco}<span style="color: #98be65;">'</span>)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'New recall score: </span>{nRecSco}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
5585.140261597363
New precision score: 0.9000641985876311
New recall score: 0.7059415911379657
</pre>

<p>
現在precision就有90%了&#x2026;.
</p>
</div>
</li>
<li><a id="orgfb02bb7"></a>ROC曲線<br />
<div class="outline-text-5" id="text-6-4-2-6">
<p>
接收者業特徵(receiver operating characteristic, ROC)曲線也常和二元分類一起使用，主要是畫出true positive率(recall) v.s. false positive率。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> roc_curve
<span class="linenr"> 2: </span><span style="color: #dcaeea;">fpr</span>, <span style="color: #dcaeea;">tpr</span>, <span style="color: #dcaeea;">thresholds</span> = roc_curve(y_train_is2, y_scores)
<span class="linenr"> 3: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_roc_curve</span>(fpr, tpr, label=<span style="color: #a9a1e1;">None</span>):
<span class="linenr"> 4: </span>    plt.plot(fpr, tpr, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>, label=label)
<span class="linenr"> 5: </span>    plt.plot([<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>], [<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>], <span style="color: #98be65;">'k--'</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">dashed diagonal</span>
<span class="linenr"> 6: </span>    plt.axis([<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr"> 7: </span>    plt.xlabel(<span style="color: #98be65;">'False Positive Rate (Fall-Out)'</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 8: </span>    plt.ylabel(<span style="color: #98be65;">'True Positive Rate (Recall)'</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 9: </span>    plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr">10: </span>
<span class="linenr">11: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr">12: </span>plot_roc_curve(fpr, tpr)
<span class="linenr">13: </span>fpr_90 = fpr[np.argmax(tpr &gt;= recall_90_precision)]
<span class="linenr">14: </span>plt.plot([fpr_90, fpr_90], [<span style="color: #da8548; font-weight: bold;">0</span>., recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">15: </span>plt.plot([<span style="color: #da8548; font-weight: bold;">0.0</span>, fpr_90], [recall_90_precision, recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">16: </span>plt.plot([fpr_90], [recall_90_precision], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">17: </span>plt.savefig(<span style="color: #98be65;">"images/roc_curve_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">18: </span>plt.show()
</pre>
</div>

<div id="org8e911fa" class="figure">
<p><img src="images/roc_curve_plot.png" alt="roc_curve_plot.png" width="500" />
</p>
<p><span class="figure-number">Figure 14: </span>所有可能的threshold的false positive率與true positive率</p>
</div>

<p>
這個曲線意味著效能還有改善的空間，即，曲線應該還以再往左上方成長
</p>
</div>
<ol class="org-ol">
<li><a id="org75c6aee"></a>比較不同分類器的效能<br />
<div class="outline-text-6" id="text-6-4-2-6-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> sklearn.ensemble <span style="color: #51afef;">import</span> RandomForestClassifier
<span class="linenr"> 2: </span><span style="color: #dcaeea;">forest_clf</span> = RandomForestClassifier(n_estimators=<span style="color: #da8548; font-weight: bold;">100</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr"> 3: </span>y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>,
<span class="linenr"> 4: </span>                                    method=<span style="color: #98be65;">"predict_proba"</span>)
<span class="linenr"> 5: </span>y_scores_forest = y_probas_forest[:, <span style="color: #da8548; font-weight: bold;">1</span>] <span style="color: #5B6268;"># </span><span style="color: #5B6268;">score = positive&#39006;&#21029;&#30340;&#27231;&#29575;</span>
<span class="linenr"> 6: </span>fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_is2,y_scores_forest)
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span>recall_for_forest = tpr_forest[np.argmax(fpr_forest &gt;= fpr_90)]
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr">11: </span>plt.plot(fpr, tpr, <span style="color: #98be65;">"b:"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>, label=<span style="color: #98be65;">"SGD"</span>)
<span class="linenr">12: </span>plot_roc_curve(fpr_forest, tpr_forest, <span style="color: #98be65;">"Random Forest"</span>)
<span class="linenr">13: </span>plt.plot([fpr_90, fpr_90], [<span style="color: #da8548; font-weight: bold;">0</span>., recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">14: </span>plt.plot([<span style="color: #da8548; font-weight: bold;">0.0</span>, fpr_90], [recall_90_precision, recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">15: </span>plt.plot([fpr_90], [recall_90_precision], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">16: </span>plt.plot([fpr_90, fpr_90], [<span style="color: #da8548; font-weight: bold;">0</span>., recall_for_forest], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">17: </span>plt.plot([fpr_90], [recall_for_forest], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">18: </span>plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr">19: </span>plt.legend(loc=<span style="color: #98be65;">"lower right"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr">20: </span>plt.savefig(<span style="color: #98be65;">"images/roc_curve_comparison_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">21: </span>plt.show()
</pre>
</div>


<div id="orge426aef" class="figure">
<p><img src="images/roc_curve_comparison_plot.png" alt="roc_curve_comparison_plot.png" width="500" />
</p>
<p><span class="figure-number">Figure 15: </span>隨機森林分類器 v.s. SGD分類器</p>
</div>
</div>
</li>
</ol>
</li>
</ol>
</div>
</div>
<div id="outline-container-orgd080977" class="outline-3">
<h3 id="orgd080977"><span class="section-number-3">6.5.</span> 多類別分類器</h3>
<div class="outline-text-3" id="text-6-5">
<ul class="org-ul">
<li>同時可以處理多類別與二元分類的分類器: SGD classifiers, Random Forest classifiers, and naive Bayes classifiers</li>
<li>只能做二元分類: Logistic Regression or Support Vector Machine classifiers</li>
</ul>
</div>
<div id="outline-container-org7e5aade" class="outline-4">
<h4 id="org7e5aade"><span class="section-number-4">6.5.1.</span> SVM</h4>
<div class="outline-text-4" id="text-6-5-1">
<p>
當然也可以拿二元類器(如SVM)來實作多類別分類，例如：
</p>
<ul class="org-ul">
<li>訓練10個二元分類器，每個分類器負責一個數字，這種做法叫one-versus-the-rest(OvR)策略，也叫one-versus-all</li>
<li>另一種做法是幫每一對數字訓練一個二元分類器(0:1, 0:2, 0:3, &#x2026; 1:2, 1:3,&#x2026;..)，這種做法叫one-versus-one(OvO)，麻煩的地方是要建立太多分類器(此例中要訓練出45組)，優點是訓練時只要比較兩個類別</li>
</ul>
</div>
</div>
<div id="outline-container-orgab89ad5" class="outline-4">
<h4 id="orgab89ad5"><span class="section-number-4">6.5.2.</span> OvO</h4>
<div class="outline-text-4" id="text-6-5-2">
<p>
這段程式用訓練組(X_train)和目標類別(y_train) 來訓練45個SVM二元分類器，取得對於圖片的研判分數，選擇最後在互相競爭中勝出的類別。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> sklearn.svm <span style="color: #51afef;">import</span> SVC
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #dcaeea;">svm_clf</span> = SVC(gamma=<span style="color: #98be65;">"auto"</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">4: </span>svm_clf.fit(X_train[:<span style="color: #da8548; font-weight: bold;">10000</span>], y_train[:<span style="color: #da8548; font-weight: bold;">10000</span>]) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">y_train, not y_train_2</span>
<span class="linenr">5: </span>svmResult = svm_clf.predict([X[<span style="color: #da8548; font-weight: bold;">9527</span>]])
<span class="linenr">6: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'OvO prediction: </span>{svmResult}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
SVM prediction: [2]
</pre>

<p>
其實上述程式共做了10次預測:
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(svm_clf.decision_function([X[<span style="color: #da8548; font-weight: bold;">9527</span>]]))
</pre>
</div>

<pre class="example">
[[ 3.83583746  8.03753281  9.29908463  5.86497842  2.82087068 -0.22917658
   4.84708487  6.91484871  0.80125693  1.81963445]]
</pre>

<p>
其中第三個(9.299&#x2026; 代表2)得分最高
</p>
</div>
</div>
<div id="outline-container-org0edc474" class="outline-4">
<h4 id="org0edc474"><span class="section-number-4">6.5.3.</span> OvR</h4>
<div class="outline-text-4" id="text-6-5-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr"> 3: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> <span style="color: #dcaeea;">bunch</span>:
<span class="linenr"> 4: </span>    mnist = pickle.load(bunch)
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr"> 7: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 8: </span><span style="color: #dcaeea;">y</span> = y.astype(np.uint8)
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#28858;&#28204;&#35430;&#32068;&#33287;&#35347;&#32244;&#32068;</span>
<span class="linenr">11: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #51afef;">from</span> sklearn.svm <span style="color: #51afef;">import</span> SVC
<span class="linenr">14: </span><span style="color: #51afef;">from</span> sklearn.multiclass <span style="color: #51afef;">import</span> OneVsRestClassifier
<span class="linenr">15: </span><span style="color: #dcaeea;">ovr_clf</span> = OneVsRestClassifier(SVC(gamma=<span style="color: #98be65;">"auto"</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>))
<span class="linenr">16: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25343;&#21069;10000&#31558;&#36039;&#35338;&#36914;&#21435;&#35347;&#32244;&#30340;&#35441;&#26371;&#36305;&#24456;&#20037;.....</span>
<span class="linenr">17: </span>ovr_clf.fit(X_train[:<span style="color: #da8548; font-weight: bold;">1000</span>], y_train[:<span style="color: #da8548; font-weight: bold;">1000</span>])
<span class="linenr">18: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38928;&#28204;</span>
<span class="linenr">19: </span><span style="color: #c678dd;">print</span>(y[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">20: </span>ovrResult = ovr_clf.predict([X[<span style="color: #da8548; font-weight: bold;">0</span>]])
<span class="linenr">21: </span>
<span class="linenr">22: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'OvR prediction: </span>{ovrResult}<span style="color: #98be65;">'</span>)
<span class="linenr">23: </span>
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; 5
OvR prediction: [5]
</pre>
</div>
</div>
<div id="outline-container-orga6764a8" class="outline-4">
<h4 id="orga6764a8"><span class="section-number-4">6.5.4.</span> 誤差分析</h4>
<div class="outline-text-4" id="text-6-5-4">
<p>
匯入library
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Python &#8805;3.5 is required</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> sys
<span class="linenr"> 3: </span><span style="color: #51afef;">assert</span> sys.version_info &gt;= (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Is this notebook running on Colab or Kaggle?</span>
<span class="linenr"> 6: </span><span style="color: #dcaeea;">IS_COLAB</span> = <span style="color: #98be65;">"google.colab"</span> <span style="color: #51afef;">in</span> sys.modules
<span class="linenr"> 7: </span><span style="color: #dcaeea;">IS_KAGGLE</span> = <span style="color: #98be65;">"kaggle_secrets"</span> <span style="color: #51afef;">in</span> sys.modules
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Scikit-Learn &#8805;0.20 is required</span>
<span class="linenr">10: </span><span style="color: #51afef;">import</span> sklearn
<span class="linenr">11: </span><span style="color: #51afef;">assert</span> sklearn.__version__ &gt;= <span style="color: #98be65;">"0.20"</span>
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Common imports</span>
<span class="linenr">14: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">15: </span><span style="color: #51afef;">import</span> os
<span class="linenr">16: </span>
<span class="linenr">17: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">to make this notebook's output stable across runs</span>
<span class="linenr">18: </span>np.random.seed(<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">19: </span>
<span class="linenr">20: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">To plot pretty figures</span>
<span class="linenr">21: </span>
<span class="linenr">22: </span><span style="color: #51afef;">import</span> matplotlib <span style="color: #51afef;">as</span> mpl
<span class="linenr">23: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">24: </span>mpl.rc(<span style="color: #98be65;">'axes'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">14</span>)
<span class="linenr">25: </span>mpl.rc(<span style="color: #98be65;">'xtick'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">12</span>)
<span class="linenr">26: </span>mpl.rc(<span style="color: #98be65;">'ytick'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">12</span>)
<span class="linenr">27: </span>
<span class="linenr">28: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Where to save the figures</span>
<span class="linenr">29: </span>PROJECT_ROOT_DIR = <span style="color: #98be65;">"."</span>
<span class="linenr">30: </span>CHAPTER_ID = <span style="color: #98be65;">"classification"</span>
<span class="linenr">31: </span>IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, <span style="color: #98be65;">"images"</span>, CHAPTER_ID)
<span class="linenr">32: </span>os.makedirs(IMAGES_PATH, exist_ok=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">33: </span>
<span class="linenr">34: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">save_fig</span>(fig_id, tight_layout=<span style="color: #a9a1e1;">True</span>, fig_extension=<span style="color: #98be65;">"png"</span>, resolution=<span style="color: #da8548; font-weight: bold;">300</span>):
<span class="linenr">35: </span>    path = os.path.join(IMAGES_PATH, fig_id + <span style="color: #98be65;">"."</span> + fig_extension)
<span class="linenr">36: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Saving figure"</span>, fig_id)
<span class="linenr">37: </span>    <span style="color: #51afef;">if</span> tight_layout:
<span class="linenr">38: </span>        plt.tight_layout()
<span class="linenr">39: </span>    plt.savefig(path, <span style="color: #c678dd;">format</span>=fig_extension, dpi=resolution)
</pre>
</div>

<pre class="example">
Python 3.7.13 (default, Mar 28 2022, 07:24:34)
[Clang 12.0.0 ] :: Anaconda, Inc. on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt;
</pre>


<p>
輸出confusion matrix
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> matplotlib <span style="color: #51afef;">as</span> mpl
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 4: </span><span style="color: #51afef;">import</span> pickle5 <span style="color: #51afef;">as</span> pickle
<span class="linenr"> 5: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> <span style="color: #dcaeea;">bunch</span>:
<span class="linenr"> 6: </span>    mnist = pickle.load(bunch)
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr"> 9: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">10: </span><span style="color: #dcaeea;">y</span> = y.astype(np.uint8)
<span class="linenr">11: </span>
<span class="linenr">12: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#28858;&#28204;&#35430;&#32068;&#33287;&#35347;&#32244;&#32068;</span>
<span class="linenr">13: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
<span class="linenr">14: </span>
<span class="linenr">15: </span><span style="color: #51afef;">from</span> sklearn.preprocessing <span style="color: #51afef;">import</span> StandardScaler
<span class="linenr">16: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> SGDClassifier
<span class="linenr">17: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25226;&#35347;&#32244;&#36039;&#26009;&#27161;&#21270;</span>
<span class="linenr">18: </span><span style="color: #dcaeea;">scaler</span> = StandardScaler()
<span class="linenr">19: </span><span style="color: #dcaeea;">X_train_scaled</span> = scaler.fit_transform(X_train.astype(np.float64))
<span class="linenr">20: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;&#20998;&#39006;</span>
<span class="linenr">21: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">max_iter&#35373;&#28858;1000&#26371;&#36305;&#24456;&#20037;&#24456;&#20037;....</span>
<span class="linenr">22: </span><span style="color: #dcaeea;">sgd_clf</span> = SGDClassifier(max_iter=<span style="color: #da8548; font-weight: bold;">10</span>, tol=1e-<span style="color: #da8548; font-weight: bold;">3</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">23: </span>
<span class="linenr">24: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_score <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30475;&#24471;&#20998;</span>
<span class="linenr">25: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20132;&#21449;&#39511;&#35657;</span>
<span class="linenr">26: </span>cross_val_score(sgd_clf, X_train_scaled, y_train, cv=<span style="color: #da8548; font-weight: bold;">3</span>, scoring=<span style="color: #98be65;">"accuracy"</span>)
<span class="linenr">27: </span>
<span class="linenr">28: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> confusion_matrix
<span class="linenr">29: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr">30: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21462;&#24471;&#38928;&#28204;&#32080;&#26524;</span>
<span class="linenr">31: </span>y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">32: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27714;&#20986;confusion matrix</span>
<span class="linenr">33: </span>conf_mx = confusion_matrix(y_train, y_train_pred)
<span class="linenr">34: </span><span style="color: #c678dd;">print</span>(conf_mx)
<span class="linenr">35: </span>plt.xticks(<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">10</span>))
<span class="linenr">36: </span>plt.matshow(conf_mx, cmap=plt.cm.gray)
<span class="linenr">37: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#28151;&#28102;&#30697;&#38499;&#30340;&#20540;&#38500;&#20197;&#27599;&#19968;&#39006;&#21029;&#30340;&#22294;&#29255;&#25976;&#37327;&#65292;&#21487;&#20197;&#24471;&#21040;&#37679;&#35492;&#29575;</span>
<span class="linenr">38: </span>plt.savefig(<span style="color: #98be65;">'images/MNIST-confusion-matrix.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">39: </span>row_sums = conf_mx.<span style="color: #c678dd;">sum</span>(axis=<span style="color: #da8548; font-weight: bold;">1</span>, keepdims=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">40: </span>norm_conf_mx = conf_mx / row_sums
<span class="linenr">41: </span>np.fill_diagonal(norm_conf_mx, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">42: </span>plt.matshow(norm_conf_mx, cmap=plt.cm.gray)
<span class="linenr">43: </span>plt.savefig(<span style="color: #98be65;">"images/confusion_matrix_errors_plot.png"</span>, tight_layout=<span style="color: #a9a1e1;">False</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<pre class="example" id="org8378f48">
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
[[5715    2   29    9   12   47   46    8   52    3]
 [   1 6461   37   29    7   41    9   10  133   14]
 [  52   36 5314  107   79   29   92   55  179   15]
 [  44   39  140 5340    3  239   33   51  143   99]
 [  18   21   37   10 5338    9   59   27  110  213]
 [  70   37   40  193   75 4598  101   25  185   97]
 [  32   22   45    2   42   95 5629    3   48    0]
 [  23   23   68   32   56   11    4 5771   22  255]
 [  47  130   66  147   10  155   49   26 5093  128]
 [  37   29   26   88  150   34    2  201  104 5278]]
__main__:43: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument "tight_layout" which is no longer supported as of 3.3 and will become an error in 3.6
</pre>

<div id="org2456ad8" class="figure">
<p><img src="images/MNIST-confusion-matrix.png" alt="MNIST-confusion-matrix.png" width="300" />
</p>
<p><span class="figure-number">Figure 16: </span>Caption</p>
</div>

<p>
5的顏色比較深，可能代表圖片5在資料庫中較少，也可能代表分類器處理5的能力較低。
將混淆矩陣的值除以每一類別的圖片數量，可以得到錯誤率,
</p>

<div id="orgb0b2ed3" class="figure">
<p><img src="images/confusion_matrix_errors_plot.png" alt="confusion_matrix_errors_plot.png" width="300" />
</p>
<p><span class="figure-number">Figure 17: </span>Caption</p>
</div>

<p>
圖<a href="#orgb0b2ed3">17</a>中的列代表真正的類型、行代表模型所預測出的類型。圖中的8這一直欄特別亮，代表有很多圖被錯誤的歸類為8；然而真正的8這一橫列並沒有特別亮，表示真正的8會被歸類為8。這個混淆矩陣並未對稱，可以看出很多的3和5常被搞混。
</p>

<p>
從這樣的圖看來，我們應該能搜集更多看起來像(但不是)8的訓練資料，加強分類器的學習。
</p>

<p>
分析個別的錯誤也有助於瞭解分類器在做什麼以及它為什麼失敗：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">EXTRA</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_digits</span>(instances, images_per_row=<span style="color: #da8548; font-weight: bold;">10</span>, **options):
<span class="linenr"> 3: </span>    size = <span style="color: #da8548; font-weight: bold;">28</span>
<span class="linenr"> 4: </span>    images_per_row = <span style="color: #c678dd;">min</span>(<span style="color: #c678dd;">len</span>(instances), images_per_row)
<span class="linenr"> 5: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">This is equivalent to n_rows = ceil(len(instances) / images_per_row):</span>
<span class="linenr"> 6: </span>    n_rows = (<span style="color: #c678dd;">len</span>(instances) - <span style="color: #da8548; font-weight: bold;">1</span>) // images_per_row + <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Append empty images to fill the end of the grid, if needed:</span>
<span class="linenr"> 9: </span>    n_empty = n_rows * images_per_row - <span style="color: #c678dd;">len</span>(instances)
<span class="linenr">10: </span>    padded_instances = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">11: </span>
<span class="linenr">12: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Reshape the array so it's organized as a grid containing 28&#215;28 images:</span>
<span class="linenr">13: </span>    image_grid = padded_instances.reshape((n_rows, images_per_row, size, size))
<span class="linenr">14: </span>
<span class="linenr">15: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Combine axes 0 and 2 (vertical image grid axis, and vertical image axis),</span>
<span class="linenr">16: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">and axes 1 and 3 (horizontal axes). We first need to move the axes that we</span>
<span class="linenr">17: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">want to combine next to each other, using transpose(), and only then we</span>
<span class="linenr">18: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">can reshape:</span>
<span class="linenr">19: </span>    big_image = image_grid.transpose(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">3</span>).reshape(n_rows * size,
<span class="linenr">20: </span>                                                         images_per_row * size)
<span class="linenr">21: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Now that we have a big image, we just need to show it:</span>
<span class="linenr">22: </span>    plt.imshow(big_image, cmap = mpl.cm.binary, **options)
<span class="linenr">23: </span>    plt.axis(<span style="color: #98be65;">"off"</span>)
<span class="linenr">24: </span>
<span class="linenr">25: </span>cl_a, cl_b = <span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">5</span>
<span class="linenr">26: </span>X_aa = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_a)]
<span class="linenr">27: </span>X_ab = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_b)]
<span class="linenr">28: </span>X_ba = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_a)]
<span class="linenr">29: </span>X_bb = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_b)]
<span class="linenr">30: </span>plt.cla()
<span class="linenr">31: </span>plt.tight_layout()
<span class="linenr">32: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>,<span style="color: #da8548; font-weight: bold;">8</span>))
<span class="linenr">33: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">221</span>); plot_digits(X_aa[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">34: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">222</span>); plot_digits(X_ab[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">35: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">223</span>); plot_digits(X_ba[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">36: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">224</span>); plot_digits(X_bb[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">37: </span>plt.savefig(<span style="color: #98be65;">"images/error_analysis_digits_plot1.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">38: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
</pre>
</div>

<p>
圖<a href="#org75c459e">18</a>右上為真實類別為3但被預測為5的圖；左下為真實類別為5但被預測為3的圖。SGDClassifier為線性模型、其做法是幫每個像素設定各個類別的權重，當他看到新圖時，它只是把加權的像素強度總和起來，得到每個類別的分數。所以當3和5這兩個只有部份像素有差異的圖，SDGClassifier就很難分辨。
</p>

<div id="org75c459e" class="figure">
<p><img src="images/error_analysis_digits_plot.png" alt="error_analysis_digits_plot.png" width="500" />
</p>
<p><span class="figure-number">Figure 18: </span>Caption</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgcd52da0" class="outline-3">
<h3 id="orgcd52da0"><span class="section-number-3">6.6.</span> 多標籤分類</h3>
<div class="outline-text-3" id="text-6-6">
<p>
把MNIST改為多類別：「大於等於7」、「奇數」，以y_multilabel陣列儲存多類別標籤，以KNN進行分類
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> sklearn.neighbors <span style="color: #51afef;">import</span> KNeighborsClassifier
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">y_train_large</span> = (y_train &gt;= <span style="color: #da8548; font-weight: bold;">7</span>)
<span class="linenr"> 4: </span><span style="color: #dcaeea;">y_train_odd</span> = (y_train % <span style="color: #da8548; font-weight: bold;">2</span> == <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 5: </span><span style="color: #dcaeea;">y_multilabel</span> = np.c_[y_train_large, y_train_odd]
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">knn_clf</span> = KNeighborsClassifier()
<span class="linenr"> 8: </span>knn_clf.fit(X_train, y_multilabel)
<span class="linenr"> 9: </span><span style="color: #dcaeea;">some_digit</span> = X[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(y[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">11: </span><span style="color: #c678dd;">print</span>(knn_clf.predict([some_digit]))
</pre>
</div>

<pre class="example">
5
[[False  True]]
</pre>

<p>
這樣會傳回兩個boolean值，表示這個數字沒有「大於等於7」、是奇數。
評估多類別標籤分類器可以為各個單獨的標籤計算$F_1$分數，再計算平均數。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> f1_score
<span class="linenr">3: </span><span style="color: #dcaeea;">y_train_knn_pred</span> = cross_val_predict(knn_clf, X_train, y_multilabel, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(f1_score(y_multilabel, y_train_knn_pred, average=<span style="color: #98be65;">"macro"</span>))
</pre>
</div>

<pre class="example">
0.976410265560605
</pre>
</div>
</div>
</div>

<div id="outline-container-orgacdc2f2" class="outline-2">
<h2 id="orgacdc2f2"><span class="section-number-2">7.</span> 分類實作: MNIST(CNN)</h2>
<div class="outline-text-2" id="text-7">
<p>
準備資料是訓練模型的第一步，基礎資料可以是網上公開的資料集，也可以是自己的資料集。視覺、語音、語言等各種型別的資料在網上都能找到相應的資料集。
</p>
</div>
<div id="outline-container-org637a136" class="outline-3">
<h3 id="org637a136"><span class="section-number-3">7.1.</span> 準備 MNIST 資料</h3>
<div class="outline-text-3" id="text-7-1">
<p>
MNIST 數據集來自美國國家標準與技術研究所, National Institute of Standards and Technology (NIST). 訓練集 (training set) 由來自 250 個不同人手寫的數字構成, 其中 50% 是高中學生, 50% 來自人口普查局 (the Census Bureau) 的工作人員. 測試集(test set) 也是同樣比例的手寫數字數據。MNIST 數據集可在 <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> 獲取, 它包含了四個部分:
</p>
<ol class="org-ol">
<li>Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解壓後 47 MB, 包含 60,000 個樣本)</li>
<li>Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解壓後 60 KB, 包含 60,000 個標籤)</li>
<li>Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解壓後 7.8 MB, 包含 10,000 個樣本)</li>
<li>Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解壓後 10 KB, 包含 10,000 個標籤)</li>
</ol>


<p>
MNIST 資料集是一個適合拿來當作 TensotFlow 的練習素材，在 Tensorflow 的現有套件中，也已經有內建好的 MNIST 資料集，我們只要在安裝好 TensorFlow 的 Python 環境中執行以下程式碼，即可將 MNIST 資料成功讀取進來。.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span id="coderef-get-keras-mnist" class="coderef-off">(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()</span>
</pre>
</div>
<p>
在訓練模型之前，需要將樣本資料劃分為訓練集、測試集，有些情況下還會劃分為訓練集、測試集、驗證集。由上述程式第<a href="#coderef-get-keras-mnist" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-get-keras-mnist');" onmouseout="CodeHighlightOff(this, 'coderef-get-keras-mnist');">3</a>行可知，下載後的 MNIST 資料分成訓練資料(training data)與測試資料(testing data)，其中 x 為圖片、y為所對應數字。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 2: </span><span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 3: </span>(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21028;&#26039;&#36039;&#26009;&#24418;&#29376;</span>
<span class="linenr"> 6: </span><span style="color: #c678dd;">print</span>(x_train.shape)
<span class="linenr"> 7: </span><span style="color: #c678dd;">print</span>(x_test.shape)
<span class="linenr"> 8: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31532;&#19968;&#20491;label&#30340;&#20839;&#23481;</span>
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034;&#24433;&#20687;&#20839;&#23481;</span>
<span class="linenr">11: </span><span style="color: #51afef;">import</span> matplotlib.pylab <span style="color: #51afef;">as</span> plt
<span class="linenr">12: </span><span style="color: #dcaeea;">img</span> = x_train[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">13: </span>plt.imshow(img)
<span class="linenr">14: </span>plt.savefig(<span style="color: #98be65;">"MNIST-Image.png"</span>)
</pre>
</div>
<pre class="example">
(60000, 28, 28)
(10000, 28, 28)
5
</pre>


<p>
由上述程式輸出結果可以看到載入的 x 為大小為 28*28 的圖片共 60000 張，每一筆 MNIST 資料的照片(x)由 784 個 pixels 組成（28*28），照片內容如圖<a href="#org2d23b75">8</a>，訓練集的標籤(y)則為其對應的數字(0～9)，此例為 5。
</p>

<div id="orge312428" class="figure">
<p><img src="images/MNIST-Image.png" alt="MNIST-Image.png" width="300" />
</p>
<p><span class="figure-number">Figure 19: </span>MNIST 影像示例</p>
</div>

<p>
x 的影像資料為灰階影像，每個像素的數值介於 0~255 之間，矩陣裡每一項的資料則是代表每個 pixel 顏色深淺的數值，如下圖<a href="#orgdd0513c">9</a>所示：
</p>

<div id="org5fbc1e8" class="figure">
<p><img src="images/MNIST-Matrix.png" alt="MNIST-Matrix.png" width="500" />
</p>
<p><span class="figure-number">Figure 20: </span>MNIST 資料矩陣</p>
</div>

<p>
載入的 y 為所對應的數字 0~9，在這我們要運用 keras 中的 np_utils.to_categorical 將 y 轉成 one-hot 的形式，將他轉為一個 10 維的 vector，例如：我們所拿到的資料為 y=3，經過 np_utils.to_categorical，會轉換為 y=[0,0,0,1,0,0,0,0,0,0]。這部份的轉換程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> mnist
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> keras.utils <span style="color: #51afef;">import</span> np_utils
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span>  <span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 5: </span>  <span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 6: </span>  (x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 7: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 8: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#22294;&#29255;&#36681;&#25563;&#28858;&#19968;&#20491;60000*784&#30340;&#21521;&#37327;&#65292;&#20006;&#19988;&#27161;&#28310;&#21270;</span>
<span class="linenr"> 9: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.reshape(x_train.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">10: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.reshape(x_test.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">11: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">12: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">13: </span>  <span style="color: #dcaeea;">x_train</span> = x_train/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">14: </span>  <span style="color: #dcaeea;">x_test</span> = x_test/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">15: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;y&#36681;&#25563;&#25104;one-hot encoding</span>
<span class="linenr">16: </span>  <span style="color: #dcaeea;">y_train</span> = np_utils.to_categorical(y_train, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">17: </span>  <span style="color: #dcaeea;">y_test</span> = np_utils.to_categorical(y_test, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">18: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22238;&#20659;&#34389;&#29702;&#23436;&#30340;&#36039;&#26009;</span>
<span class="linenr">19: </span>  <span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">20: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">21: </span>  np.set_printoptions(precision=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">22: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">print(x_train[0])</span>
</pre>
</div>

<pre class="example">
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
</pre>
</div>
</div>
<div id="outline-container-org2f0f1c7" class="outline-3">
<h3 id="org2f0f1c7"><span class="section-number-3">7.2.</span> MNIST 的推論處理</h3>
<div class="outline-text-3" id="text-7-2">
<p>
如圖<a href="#org3685af9">21</a>所示，MNIST 的推論神經網路最前端的輸入層有 784 (\(28*28=784\))個神經元，最後的輸出端有 10 個神經元(\(0~9\)個數字)，至於中間的隠藏層有兩個，第 1 個隱藏層有 50 個神經元，第 2 層有 100 個。此處的 50、100 可以設定為任意數（如，也可以是 128、64）。
</p>

<div id="org3685af9" class="figure">
<p><img src="images/MNIST-CNN.png" alt="MNIST-CNN.png" width="500" />
</p>
<p><span class="figure-number">Figure 21: </span>MNIST-NeuralNet</p>
</div>

<p>
為了完成上述推論，此處定義三個函數：get_data()、init_network()、predict()，其中 init_work()直接讀入作者已經訓練好的網絡權重。在以下這段程式碼中，權重與偏權值的參數會儲存成字典型態的變數。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">from</span> keras.datasets.mnist <span style="color: #51afef;">import</span> load_data
<span class="linenr"> 2: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span>  <span style="color: #51afef;">import</span> pickle
<span class="linenr"> 4: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">sigmoid</span>(x):
<span class="linenr"> 5: </span>    <span style="color: #51afef;">return</span> <span style="color: #da8548; font-weight: bold;">1</span> / (<span style="color: #da8548; font-weight: bold;">1</span> + np.exp(-x))
<span class="linenr"> 6: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38450;&#27490;&#28322;&#20986;&#22411;</span>
<span class="linenr"> 7: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">softmax</span>(x):
<span class="linenr"> 8: </span>    <span style="color: #dcaeea;">c</span> = np.<span style="color: #c678dd;">max</span>(x)
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">exp_x</span> = np.exp(x - c)
<span class="linenr">10: </span>    <span style="color: #dcaeea;">sum_exp_x</span> = np.<span style="color: #c678dd;">sum</span>(exp_x)
<span class="linenr">11: </span>    <span style="color: #51afef;">return</span> exp_x / sum_exp_x
<span class="linenr">12: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">get_data</span>():
<span class="linenr">13: </span>    (X_train, y_train), (<span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span>) = load_data()
<span class="linenr">14: </span>    <span style="color: #51afef;">return</span> X_test.reshape(<span style="color: #da8548; font-weight: bold;">10000</span>, <span style="color: #da8548; font-weight: bold;">784</span>), y_test
<span class="linenr">15: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">init_network</span>():
<span class="linenr">16: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">https://github.com/Bingyy/deep-learning-from-scratch/blob/master/ch03/sample_weight.pkl</span>
<span class="linenr">17: </span>    <span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'/Volumes/Vanessa/MNIST/data/mnist/sample_weight.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> <span style="color: #dcaeea;">f</span>:
<span class="linenr">18: </span>      network = pickle.load(f)
<span class="linenr">19: </span>      <span style="color: #51afef;">return</span> network
<span class="linenr">20: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23384;&#20786;&#30340;&#26159;&#32178;&#32097;&#21443;&#25976;&#23383;&#20856;</span>
<span class="linenr">21: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">22: </span>
<span class="linenr">23: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32068;&#21512;&#32178;&#32097;&#27969;&#31243;&#65292;&#29992;&#26044;&#38928;&#28204;</span>
<span id="coderef-MNIST-predict" class="coderef-off"><span class="linenr">24: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">predict</span>(network, x):</span>
<span class="linenr">25: </span>    <span style="color: #dcaeea;">W1</span>, <span style="color: #dcaeea;">W2</span>, <span style="color: #dcaeea;">W3</span> = network[<span style="color: #98be65;">'W1'</span>], network[<span style="color: #98be65;">'W2'</span>], network[<span style="color: #98be65;">'W3'</span>]
<span class="linenr">26: </span>    <span style="color: #dcaeea;">b1</span>, <span style="color: #dcaeea;">b2</span>, <span style="color: #dcaeea;">b3</span> = network[<span style="color: #98be65;">'b1'</span>], network[<span style="color: #98be65;">'b2'</span>], network[<span style="color: #98be65;">'b3'</span>]
<span class="linenr">27: </span>    <span style="color: #dcaeea;">a1</span> = np.dot(x,W1) + b1
<span class="linenr">28: </span>    <span style="color: #dcaeea;">z1</span> = sigmoid(a1)
<span class="linenr">29: </span>    <span style="color: #dcaeea;">a2</span> = np.dot(z1, W2) + b2
<span class="linenr">30: </span>    <span style="color: #dcaeea;">z2</span> = sigmoid(a2)
<span class="linenr">31: </span>    <span style="color: #dcaeea;">a3</span> = np.dot(z2, W3) + b3
<span class="linenr">32: </span>    <span style="color: #dcaeea;">y</span> = softmax(a3) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#39006;&#29992;&#30340;&#26368;&#24460;&#36664;&#20986;&#23652;&#30340;&#28608;&#27963;&#20989;&#25976;</span>
<span class="linenr">33: </span>    <span style="color: #51afef;">return</span> y
<span class="linenr">34: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992;&#32178;&#32097;&#38928;&#28204;</span>
<span class="linenr">35: </span>  <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span> = get_data() <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24471;&#21040;&#28204;&#35430;&#25976;&#25818;</span>
<span class="linenr">36: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">37: </span>
<span class="linenr">38: </span>  <span style="color: #dcaeea;">accuracy_cnt</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr">39: </span>  <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #c678dd;">len</span>(X_test)):
<span id="coderef-y-predict" class="coderef-off"><span class="linenr">40: </span>    <span style="color: #dcaeea;">y</span> = predict(network, X_test[i])</span>
<span id="coderef-np-argmax" class="coderef-off"><span class="linenr">41: </span>    <span style="color: #dcaeea;">p</span> = np.argmax(y)</span>
<span class="linenr">42: </span>    np.set_printoptions(precision=<span style="color: #da8548; font-weight: bold;">4</span>, suppress=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">43: </span>    <span style="color: #51afef;">if</span> p == y_test[i]:
<span class="linenr">44: </span>      accuracy_cnt += <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">45: </span>  <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;&#65306;'</span>, <span style="color: #c678dd;">str</span>(<span style="color: #c678dd;">float</span>(accuracy_cnt) / <span style="color: #c678dd;">len</span>(X_test)))
</pre>
</div>

<pre class="example">
準確率： 0.0002
</pre>


<p>
上述程式中，predict 程序(第<a href="#coderef-MNIST-predict" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-MNIST-predict');" onmouseout="CodeHighlightOff(this, 'coderef-MNIST-predict');">24</a>)透過矩陣相乘運算完成神經網路的參數傳遞，最後必須進行準確率的評估，程式碼第<a href="#coderef-y-predict" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-y-predict');" onmouseout="CodeHighlightOff(this, 'coderef-y-predict');">40</a>行為神經網路針對輸入圖片的預測結果，所傳回的值為各猜測值的機率陣列，如：[0.0004 0.0011 0.9859 0.0065 0.     0.0007 0.0051 0.     0.0003 0.    ]；而程式碼第<a href="#coderef-np-argmax" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-np-argmax');" onmouseout="CodeHighlightOff(this, 'coderef-np-argmax');">41</a>則是該圖片的應對標籤，np.argmax(y)會傳回 y 的最大值所在順序，若 y=[0,0,0,1,0,0,0,0,0,0]，則傳回 3，藉此計算預測正確的百分比。
</p>
</div>
</div>
<div id="outline-container-org248e404" class="outline-3">
<h3 id="org248e404"><span class="section-number-3">7.3.</span> Python 與神經網路運算的批次處理</h3>
<div class="outline-text-3" id="text-7-3">
<p>
前節程式碼中最後以 for 迴圈來逐一處理預測結果與比較，輸入(X)為單一圖片，其處理程序如圖<a href="#org64c3489">22</a>所示：
</p>

<div id="org64c3489" class="figure">
<p><img src="images/MNIST-single.png" alt="MNIST-single.png" width="500" />
</p>
<p><span class="figure-number">Figure 22: </span>MNIST-單一處理架構</p>
</div>

<p>
事實上，在使用批次處理（如一次處理 100 張圖）反而能大幅縮短每張圖片的處理時間，因為多數處理數值運算的函式庫都會針對大型陣列運算進行最佳化，尤其是透過 GPU 來處理時更是如此，這時，傳送單張圖片反而成為效能瓶頸，以批次處理則可減輕匯流排頻寛負擔。若以每次處理 100 張為例，其處理程序則如圖<a href="#org3cab1eb">23</a>所示。
</p>

<div id="org3cab1eb" class="figure">
<p><img src="images/MNIST-batch.png" alt="MNIST-batch.png" width="500" />
</p>
<p><span class="figure-number">Figure 23: </span>MNIST-批次處理架構</p>
</div>

<p>
至於批次運算的程式碼如下。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #51afef;">from</span> keras.datasets.mnist <span style="color: #51afef;">import</span> load_data
<span class="linenr"> 2: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span>  <span style="color: #51afef;">import</span> pickle
<span class="linenr"> 4: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">sigmoid</span>(x):
<span class="linenr"> 5: </span>    <span style="color: #51afef;">return</span> <span style="color: #da8548; font-weight: bold;">1</span> / (<span style="color: #da8548; font-weight: bold;">1</span> + np.exp(-x))
<span class="linenr"> 6: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38450;&#27490;&#28322;&#20986;&#22411;</span>
<span class="linenr"> 7: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">softmax</span>(x):
<span class="linenr"> 8: </span>    <span style="color: #dcaeea;">c</span> = np.<span style="color: #c678dd;">max</span>(x)
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">exp_x</span> = np.exp(x - c)
<span class="linenr">10: </span>    <span style="color: #dcaeea;">sum_exp_x</span> = np.<span style="color: #c678dd;">sum</span>(exp_x)
<span class="linenr">11: </span>    <span style="color: #51afef;">return</span> exp_x / sum_exp_x
<span class="linenr">12: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">get_data</span>():
<span class="linenr">13: </span>    (X_train, y_train), (<span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span>) = load_data()
<span class="linenr">14: </span>    <span style="color: #51afef;">return</span> X_test.reshape(<span style="color: #da8548; font-weight: bold;">10000</span>, <span style="color: #da8548; font-weight: bold;">784</span>), y_test
<span class="linenr">15: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">init_network</span>():
<span class="linenr">16: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">https://github.com/Bingyy/deep-learning-from-scratch/blob/master/ch03/sample_weight.pkl</span>
<span class="linenr">17: </span>    <span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'/Volumes/Vanessa/MNIST/sample_weight.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> <span style="color: #dcaeea;">f</span>:
<span class="linenr">18: </span>      network = pickle.load(f)
<span class="linenr">19: </span>      <span style="color: #51afef;">return</span> network
<span class="linenr">20: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23384;&#20786;&#30340;&#26159;&#32178;&#32097;&#21443;&#25976;&#23383;&#20856;</span>
<span class="linenr">21: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">22: </span>
<span class="linenr">23: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32068;&#21512;&#32178;&#32097;&#27969;&#31243;&#65292;&#29992;&#26044;&#38928;&#28204;</span>
<span class="linenr">24: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">predict</span>(network, x):
<span class="linenr">25: </span>    <span style="color: #dcaeea;">W1</span>, <span style="color: #dcaeea;">W2</span>, <span style="color: #dcaeea;">W3</span> = network[<span style="color: #98be65;">'W1'</span>], network[<span style="color: #98be65;">'W2'</span>], network[<span style="color: #98be65;">'W3'</span>]
<span class="linenr">26: </span>    <span style="color: #dcaeea;">b1</span>, <span style="color: #dcaeea;">b2</span>, <span style="color: #dcaeea;">b3</span> = network[<span style="color: #98be65;">'b1'</span>], network[<span style="color: #98be65;">'b2'</span>], network[<span style="color: #98be65;">'b3'</span>]
<span class="linenr">27: </span>    <span style="color: #dcaeea;">a1</span> = np.dot(x,W1) + b1
<span class="linenr">28: </span>    <span style="color: #dcaeea;">z1</span> = sigmoid(a1)
<span class="linenr">29: </span>    <span style="color: #dcaeea;">a2</span> = np.dot(z1, W2) + b2
<span class="linenr">30: </span>    <span style="color: #dcaeea;">z2</span> = sigmoid(a2)
<span class="linenr">31: </span>    <span style="color: #dcaeea;">a3</span> = np.dot(z2, W3) + b3
<span class="linenr">32: </span>    <span style="color: #dcaeea;">y</span> = softmax(a3) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#39006;&#29992;&#30340;&#26368;&#24460;&#36664;&#20986;&#23652;&#30340;&#28608;&#27963;&#20989;&#25976;</span>
<span class="linenr">33: </span>    <span style="color: #51afef;">return</span> y
<span class="linenr">34: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992;&#32178;&#32097;&#38928;&#28204;</span>
<span class="linenr">35: </span>  <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span> = get_data() <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24471;&#21040;&#28204;&#35430;&#25976;&#25818;</span>
<span class="linenr">36: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">37: </span>
<span class="linenr">38: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25209;&#27425;&#34389;&#29702;&#26550;&#27083;</span>
<span class="linenr">39: </span>  <span style="color: #dcaeea;">batch_size</span> = <span style="color: #da8548; font-weight: bold;">100</span>
<span class="linenr">40: </span>  <span style="color: #dcaeea;">accuracy_cnt</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr">41: </span>  <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #c678dd;">len</span>(X_test), batch_size):
<span id="coderef-b-mnist-x" class="coderef-off"><span class="linenr">42: </span>    <span style="color: #dcaeea;">x_batch</span> = X_test[i:i+batch_size]</span>
<span class="linenr">43: </span>    <span style="color: #dcaeea;">y_batch</span> = predict(network, x_batch)
<span id="coderef-b-mnist-p" class="coderef-off"><span class="linenr">44: </span>    <span style="color: #dcaeea;">p</span> = np.argmax(y_batch, axis=<span style="color: #da8548; font-weight: bold;">1</span>)</span>
<span class="linenr">45: </span>    accuracy_cnt += np.<span style="color: #c678dd;">sum</span>(p == y_test[i:i+batch_size])
<span class="linenr">46: </span>  <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;&#65306;'</span>, <span style="color: #c678dd;">str</span>(<span style="color: #c678dd;">float</span>(accuracy_cnt) / <span style="color: #c678dd;">len</span>(X_test)))
</pre>
</div>

<pre class="example">
準確率： 0.9207
</pre>


<p>
上述程式中，第<a href="#coderef-b-mnist-x" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-b-mnist-x');" onmouseout="CodeHighlightOff(this, 'coderef-b-mnist-x');">42</a>行每次取出 100 張圖形檔(X 陣列),第<a href="#coderef-b-mnist-p" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-b-mnist-p');" onmouseout="CodeHighlightOff(this, 'coderef-b-mnist-p');">44</a>行則取得這 100 筆資料中各筆資料最大值索引值，若以每次 4 筆資料為例，所得的估計值 p 可能為[7 2 1 0]，相對應的正確標籤值則儲存於 y_test[0:4]中，以此進行準確率的計算。
</p>
</div>
</div>
<div id="outline-container-orgb853e80" class="outline-3">
<h3 id="orgb853e80"><span class="section-number-3">7.4.</span> MNIST 資料集:以 DNN Sequential 模型為例&#xa0;&#xa0;&#xa0;<span class="tag"><span class="CNN">CNN</span></span></h3>
<div class="outline-text-3" id="text-7-4">
<p>
此處以最簡單的 DNN (deep neural network) 作為範例。以 Keras 的核心為模型，應用最常使用 Sequential 模型。藉由.add()我們可以一層一層的將神經網路疊起。在每一層之中我們只需要簡單的設定每層的大小(units)與激活函數(activation function)。需要特別記得的是：第一層要記得寫輸入的向量大小、最後一層的 units 要等於輸出的向量大小。在這邊我們最後一層使用的激活函數(activation function)為 softmax。
相對應程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36617;&#20837;&#36039;&#26009;</span>
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> mnist
<span class="linenr"> 3: </span>  <span style="color: #51afef;">from</span> keras.utils <span style="color: #51afef;">import</span> np_utils
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">load_data</span>():
<span class="linenr"> 6: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36617;&#20837;minst&#30340;&#36039;&#26009;</span>
<span class="linenr"> 7: </span>    (x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 8: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#22294;&#29255;&#36681;&#25563;&#28858;&#19968;&#20491;60000*784&#30340;&#21521;&#37327;&#65292;&#20006;&#19988;&#27161;&#28310;&#21270;</span>
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">x_train</span> = x_train.reshape(x_train.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">10: </span>    <span style="color: #dcaeea;">x_test</span> = x_test.reshape(x_test.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">11: </span>    <span style="color: #dcaeea;">x_train</span> = x_train.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">12: </span>    <span style="color: #dcaeea;">x_test</span> = x_test.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">13: </span>    <span style="color: #dcaeea;">x_train</span> = x_train/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">14: </span>    <span style="color: #dcaeea;">x_test</span> = x_test/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">15: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;y&#36681;&#25563;&#25104;one-hot encoding</span>
<span class="linenr">16: </span>    <span style="color: #dcaeea;">y_train</span> = np_utils.to_categorical(y_train, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">17: </span>    <span style="color: #dcaeea;">y_test</span> = np_utils.to_categorical(y_test, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">18: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22238;&#20659;&#34389;&#29702;&#23436;&#30340;&#36039;&#26009;</span>
<span class="linenr">19: </span>    <span style="color: #51afef;">return</span> (x_train, y_train), (x_test, y_test)
<span class="linenr">20: </span>
<span class="linenr">21: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">22: </span>  <span style="color: #51afef;">from</span> keras.models <span style="color: #51afef;">import</span> Sequential
<span class="linenr">23: </span>  <span style="color: #51afef;">from</span> keras.layers.core <span style="color: #51afef;">import</span> Dense,Activation
<span class="linenr">24: </span>  <span style="color: #51afef;">from</span> keras.optimizers <span style="color: #51afef;">import</span>  Adam
<span class="linenr">25: </span>
<span class="linenr">26: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">build_model</span>():<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#24314;&#31435;&#27169;&#22411;</span>
<span class="linenr">27: </span>    <span style="color: #dcaeea;">model</span> = Sequential()
<span class="linenr">28: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#23559;&#27169;&#22411;&#30090;&#36215;</span>
<span class="linenr">29: </span>    model.add(Dense(input_dim=<span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>,units=<span style="color: #da8548; font-weight: bold;">500</span>,activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">30: </span>    model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">500</span>,activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">31: </span>    model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">500</span>,activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">32: </span>    model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">10</span>,activation=<span style="color: #98be65;">'softmax'</span>))
<span class="linenr">33: </span>    model.summary()
<span class="linenr">34: </span>    <span style="color: #51afef;">return</span> model
<span class="linenr">35: </span>
<span class="linenr">36: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38283;&#22987;&#35347;&#32244;&#27169;&#22411;&#65292;&#27492;&#34389;&#20351;&#29992;&#20102;Adam&#20570;&#28858;&#25105;&#20497;&#30340;&#20778;&#21270;&#22120;&#65292;loss function&#36984;&#29992;&#20102;categorical_crossentropy&#12290;</span>
<span class="linenr">37: </span>  (x_train,y_train),(<span style="color: #dcaeea;">x_test</span>,<span style="color: #dcaeea;">y_test</span>)=load_data()
<span class="linenr">38: </span>  model = build_model()
<span class="linenr">39: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38283;&#22987;&#35347;&#32244;&#27169;&#22411;</span>
<span class="linenr">40: </span>  model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'categorical_crossentropy'</span>,optimizer=<span style="color: #98be65;">"adam"</span>,metrics=[<span style="color: #98be65;">'accuracy'</span>])
<span class="linenr">41: </span>  model.fit(x_train,y_train,batch_size=<span style="color: #da8548; font-weight: bold;">100</span>,epochs=<span style="color: #da8548; font-weight: bold;">20</span>)
<span class="linenr">42: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#39023;&#31034;&#35347;&#32244;&#32080;&#26524;</span>
<span class="linenr">43: </span>  score = model.evaluate(x_train,y_train)
<span class="linenr">44: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">'\nTrain Acc:'</span>, score[<span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr">45: </span>  score = model.evaluate(x_test,y_test)
<span class="linenr">46: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">'\nTest Acc:'</span>, score[<span style="color: #da8548; font-weight: bold;">1</span>])
</pre>
</div>

<pre class="example" id="org4e3cb72">
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_1 (Dense)              (None, 500)               392500
_________________________________________________________________
dense_2 (Dense)              (None, 500)               250500
_________________________________________________________________
dense_3 (Dense)              (None, 500)               250500
_________________________________________________________________
dense_4 (Dense)              (None, 10)                5010
=================================================================
Total params: 898,510
Trainable params: 898,510
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20

  100/60000 [..............................] - ETA: 2:55 - loss: 2.2917 - acc: 0.1300
  800/60000 [..............................] - ETA: 25s - loss: 1.6424 - ACM: 0.5362
.......
16300/60000 [=======&gt;......................] - ETA: 4s - loss: 0.3752 - acc: 0.8898
17000/60000 [=======&gt;......................] - ETA: 4s - loss: 0.3681 - acc: 0.8916
.......
50600/60000 [========================&gt;.....] - ETA: 0s - loss: 0.2232 - acc: 0.9335
51300/60000 [========================&gt;.....] - ETA: 0s - loss: 0.2220 - acc: 0.9338
.......
59700/60000 [============================&gt;.] - ETA: 0s - loss: 0.2078 - acc: 0.9377
60000/60000 [==============================] - 5s 81us/step - loss: 0.2074 - acc: 0.9379
Epoch 2/20

  100/60000 [..............................] - ETA: 5s - loss: 0.0702 - acc: 0.9800
......
60000/60000 [==============================] - 5s 77us/step - loss: 0.0832 - acc: 0.9740
Epoch 3/20
......
Epoch 29/20

   32/60000 [..............................] - ETA: 1:10
 1440/60000 [..............................] - ETA: 3s
......
58496/60000 [============================&gt;.] - ETA: 0s
60000/60000 [==============================] - 2s 34us/step

Train Acc: 0.9981666666666666

   32/10000 [..............................] - ETA: 0s
 1568/10000 [===&gt;..........................] - ETA: 0s
 3104/10000 [========&gt;.....................] - ETA: 0s
 4640/10000 [============&gt;.................] - ETA: 0s
 6176/10000 [=================&gt;............] - ETA: 0s
 7680/10000 [======================&gt;.......] - ETA: 0s
 9184/10000 [==========================&gt;...] - ETA: 0s
10000/10000 [==============================] - 0s 33us/step

Test Acc: 0.9823
</pre>
</div>
</div>
<div id="outline-container-org76585f5" class="outline-3">
<h3 id="org76585f5"><span class="section-number-3">7.5.</span> 其他MNIST教學檔</h3>
<div class="outline-text-3" id="text-7-5">
<ul class="org-ul">
<li><a href="file:///Users/letranger/Dropbox/DeepLearning/HiCNN.html">HICNN-TNFSH-作業</a></li>
<li><a href="file:///Users/letranger/Dropbox/DeepLearning/DeepLearning.html">hiDNN</a></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orge93a902" class="outline-2">
<h2 id="orge93a902"><span class="section-number-2">8.</span> 推薦系統: 受限波爾茲曼機 on MovieLens</h2>
<div class="outline-text-2" id="text-8">
<p>
MovieLens 是一個推薦系統和虛擬社區網站，於1997年建立。其主要功能為應用協同過濾技術和用戶對電影的喜好，向用戶推薦電影。該網站是GroupLens研究所旗下一個項目，該研究所隸屬於美國明尼蘇達大學雙城分校計算機科學與工程系。MovieLens 20M資料集包含20,000,263筆關於27,278部電影的評價，評價者共138,493人。
</p>
</div>
<div id="outline-container-orgf4566fe" class="outline-3">
<h3 id="orgf4566fe"><span class="section-number-3">8.1.</span> 資料準備</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<div id="outline-container-orgb052230" class="outline-4">
<h4 id="orgb052230"><span class="section-number-4">8.1.1.</span> Setup</h4>
<div class="outline-text-4" id="text-8-1-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #83898d;">'''Main'''</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 4: </span><span style="color: #51afef;">import</span> os, time, re
<span class="linenr"> 5: </span><span style="color: #51afef;">import</span> pickle, gzip, datetime
<span class="linenr"> 6: </span><span style="color: #51afef;">from</span> datetime <span style="color: #51afef;">import</span> datetime
<span class="linenr"> 7: </span><span style="color: #51afef;">from</span> zipfile <span style="color: #51afef;">import</span> ZipFile
<span class="linenr"> 8: </span><span style="color: #51afef;">from</span> urllib.request <span style="color: #51afef;">import</span> urlretrieve
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #98be65;">'''Data Viz'''</span>
<span class="linenr">11: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">12: </span><span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span class="linenr">13: </span><span style="color: #dcaeea;">color</span> = sns.color_palette()
<span class="linenr">14: </span><span style="color: #51afef;">import</span> matplotlib <span style="color: #51afef;">as</span> mpl
<span class="linenr">15: </span>
<span class="linenr">16: </span><span style="color: #98be65;">'''Data Prep and Model Evaluation'''</span>
<span class="linenr">17: </span><span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> preprocessing <span style="color: #51afef;">as</span> pp
<span class="linenr">18: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span class="linenr">19: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> StratifiedKFold
<span class="linenr">20: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> log_loss
<span class="linenr">21: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> precision_recall_curve, average_precision_score
<span class="linenr">22: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> roc_curve, auc, roc_auc_score, mean_squared_error
<span class="linenr">23: </span>
<span class="linenr">24: </span><span style="color: #98be65;">'''Algos'''</span>
<span class="linenr">25: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">import lightgbm as lgb</span>
<span class="linenr">26: </span>
<span class="linenr">27: </span><span style="color: #98be65;">'''TensorFlow and Keras'''</span>
<span class="linenr">28: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr">29: </span><span style="color: #51afef;">from</span> tensorflow <span style="color: #51afef;">import</span> keras
<span class="linenr">30: </span><span style="color: #dcaeea;">K</span> = keras.backend
<span class="linenr">31: </span>
<span class="linenr">32: </span><span style="color: #51afef;">from</span> tensorflow.keras.models <span style="color: #51afef;">import</span> Sequential, Model
<span class="linenr">33: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> Activation, Dense, Dropout
<span class="linenr">34: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> BatchNormalization, Input, Lambda
<span class="linenr">35: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> Embedding, Flatten, dot
<span class="linenr">36: </span><span style="color: #51afef;">from</span> tensorflow.keras <span style="color: #51afef;">import</span> regularizers
<span class="linenr">37: </span><span style="color: #51afef;">from</span> tensorflow.keras.losses <span style="color: #51afef;">import</span> mse, binary_crossentropy
</pre>
</div>
</div>
</div>
<div id="outline-container-org97af3d0" class="outline-4">
<h4 id="org97af3d0"><span class="section-number-4">8.1.2.</span> Check library version</h4>
<div class="outline-text-4" id="text-8-1-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> sys, sklearn
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'sklearn    </span>{sklearn.__version__}<span style="color: #98be65;">'</span>)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'tensorflow </span>{tf.__version__}<span style="color: #98be65;">'</span>)
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'keras      </span>{keras.__version__}<span style="color: #98be65;">'</span>)
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'numpy      </span>{np.__version__}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
sklearn    1.0.1
tensorflow 2.7.0
keras      2.7.0
numpy      1.19.5
</pre>
</div>
</div>

<div id="outline-container-org3f2c29b" class="outline-4">
<h4 id="org3f2c29b"><span class="section-number-4">8.1.3.</span> Download and unzip the Data</h4>
<div class="outline-text-4" id="text-8-1-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Download and read into Pandas DataFrame</span>
<span class="linenr">2: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">import os</span>
<span class="linenr">3: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">from urllib.request import urlretrieve</span>
<span class="linenr">4: </span><span style="color: #dcaeea;">current_path</span> = os.getcwd()
<span class="linenr">5: </span>urlretrieve(<span style="color: #98be65;">"http://files.grouplens.org/datasets/movielens/ml-20m.zip"</span>, \
<span class="linenr">6: </span>            current_path+<span style="color: #98be65;">"/dataset/movielens.zip"</span>)
<span class="linenr">7: </span>ZipFile(current_path+<span style="color: #98be65;">"/dataset/movielens.zip"</span>, <span style="color: #98be65;">"r"</span>).extractall(current_path+<span style="color: #98be65;">"/dataset/"</span>)
<span class="linenr">8: </span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgc4592ca" class="outline-4">
<h4 id="orgc4592ca"><span class="section-number-4">8.1.4.</span> Load data</h4>
<div class="outline-text-4" id="text-8-1-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">ratingDF</span> = pd.read_csv(<span style="color: #98be65;">"./dataset/ml-20m/ratings.csv"</span>)
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(ratingDF)
</pre>
</div>

<pre class="example" id="org02034d6">
          userId  movieId  rating   timestamp
0              1        2     3.5  1112486027
1              1       29     3.5  1112484676
2              1       32     3.5  1112484819
3              1       47     3.5  1112484727
4              1       50     3.5  1112484580
...          ...      ...     ...         ...
20000258  138493    68954     4.5  1258126920
20000259  138493    69526     4.5  1259865108
20000260  138493    69644     3.0  1260209457
20000261  138493    70286     5.0  1258126944
20000262  138493    71619     2.5  1255811136

[20000263 rows x 4 columns]
</pre>
</div>
</div>

<div id="outline-container-org02a0e92" class="outline-4">
<h4 id="org02a0e92"><span class="section-number-4">8.1.5.</span> 轉換資料</h4>
<div class="outline-text-4" id="text-8-1-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Convert fields into appropriate data types</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> datetime <span style="color: #51afef;">import</span> datetime
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 4: </span><span style="color: #dcaeea;">ratingDF</span> = pd.read_csv(<span style="color: #98be65;">"./dataset/ml-20m/ratings.csv"</span>)
<span class="linenr"> 5: </span>ratingDF.<span style="color: #dcaeea;">userId</span> = ratingDF.userId.astype(<span style="color: #c678dd;">str</span>).astype(<span style="color: #c678dd;">int</span>)
<span class="linenr"> 6: </span>ratingDF.<span style="color: #dcaeea;">movieId</span> = ratingDF.movieId.astype(<span style="color: #c678dd;">str</span>).astype(<span style="color: #c678dd;">int</span>)
<span class="linenr"> 7: </span>ratingDF.<span style="color: #dcaeea;">rating</span> = ratingDF.rating.astype(<span style="color: #c678dd;">str</span>).astype(<span style="color: #c678dd;">float</span>)
<span class="linenr"> 8: </span>ratingDF.<span style="color: #dcaeea;">timestamp</span> = ratingDF.timestamp.<span style="color: #c678dd;">apply</span>(<span style="color: #51afef;">lambda</span> x: \
<span class="linenr"> 9: </span>                        datetime.utcfromtimestamp(x).strftime(<span style="color: #98be65;">'%Y-%m-%d %H:%M:%S'</span>))
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Store DataFrame as pickle for faster loading in the future</span>
<span class="linenr">11: </span>ratingDF.to_pickle(<span style="color: #98be65;">"./dataset/ml-20m/ratingPickle"</span>)
<span class="linenr">12: </span><span style="color: #dcaeea;">ratingDF</span> = pd.read_pickle(<span style="color: #98be65;">"./dataset/ml-20m/ratingPickle"</span>)
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Preview data</span>
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(ratingDF.head())
</pre>
</div>

<pre class="example">
   userId  movieId  rating            timestamp
0       1        2     3.5  2005-04-02 23:53:47
1       1       29     3.5  2005-04-02 23:31:16
2       1       32     3.5  2005-04-02 23:33:39
3       1       47     3.5  2005-04-02 23:32:07
4       1       50     3.5  2005-04-02 23:29:40
</pre>
</div>
</div>

<div id="outline-container-org7c22142" class="outline-4">
<h4 id="org7c22142"><span class="section-number-4">8.1.6.</span> 確認使用者、評價數量</h4>
<div class="outline-text-4" id="text-8-1-6">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Calculate summary statistics on full dataset</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">n_users</span> = ratingDF.userId.unique().shape[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr"> 3: </span><span style="color: #dcaeea;">n_movies</span> = ratingDF.movieId.unique().shape[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr"> 4: </span><span style="color: #dcaeea;">n_ratings</span> = <span style="color: #c678dd;">len</span>(ratingDF)
<span class="linenr"> 5: </span><span style="color: #dcaeea;">avg_ratings_per_user</span> = n_ratings/n_users
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Number of unique users: </span>{n_users}<span style="color: #98be65;">'</span>)
<span class="linenr"> 8: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Number of unique movies: </span>{n_movies}<span style="color: #98be65;">'</span>)
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Number of total ratings: </span>{n_ratings}<span style="color: #98be65;">'</span>)
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Average number of ratings per user: </span>{<span style="color: #c678dd;">round</span>(avg_ratings_per_user,1)}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
Number of unique users: 138493
Number of unique movies: 26744
Number of total ratings: 20000263
Average number of ratings per user: 144.4
</pre>
</div>
</div>


<div id="outline-container-orge2d592c" class="outline-4">
<h4 id="orge2d592c"><span class="section-number-4">8.1.7.</span> 只取前1000筆記錄</h4>
<div class="outline-text-4" id="text-8-1-7">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Reduce size of dataset by taking top 1000 movies</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">movieIndex</span> = ratingDF.groupby(<span style="color: #98be65;">"movieId"</span>).count().sort_values(by=
<span class="linenr">3: </span>                <span style="color: #98be65;">"rating"</span>,ascending=<span style="color: #a9a1e1;">False</span>)[<span style="color: #da8548; font-weight: bold;">0</span>:<span style="color: #da8548; font-weight: bold;">1000</span>].index
<span class="linenr">4: </span>ratingDFX2 = ratingDF[ratingDF.movieId.isin(movieIndex)]
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(ratingDFX2.count())
</pre>
</div>

<pre class="example">
userId       12840344
movieId      12840344
rating       12840344
timestamp    12840344
dtype: int64
</pre>



<p>
隨機抽1000位使用者，以這1000位使用者來過濾資料集，如此可以將庫筆數由12840344縮至90213
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Reduce size of dataset by sampling 1000 users</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">userIndex</span> = ratingDFX2.groupby(<span style="color: #98be65;">"userId"</span>).count().sort_values(by=
<span class="linenr">3: </span>    <span style="color: #98be65;">"rating"</span>,ascending=<span style="color: #a9a1e1;">False</span>).sample(n=<span style="color: #da8548; font-weight: bold;">1000</span>, random_state=<span style="color: #da8548; font-weight: bold;">2018</span>).index
<span class="linenr">4: </span>ratingDFX3 = ratingDFX2[ratingDFX2.userId.isin(userIndex)]
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(ratingDFX3.count())
</pre>
</div>

<pre class="example">
userId       90213
movieId      90213
rating       90213
timestamp    90213
dtype: int64
</pre>
</div>
</div>

<div id="outline-container-orgce23b2b" class="outline-4">
<h4 id="orgce23b2b"><span class="section-number-4">8.1.8.</span> 針對已縮減的資料集重建index(movieID, userID)</h4>
<div class="outline-text-4" id="text-8-1-8">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Reindex movie ID</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">movies</span> = ratingDFX3.movieId.unique()
<span class="linenr"> 3: </span><span style="color: #dcaeea;">moviesDF</span> = pd.DataFrame(data=movies,columns=[<span style="color: #98be65;">'originalMovieId'</span>])
<span class="linenr"> 4: </span>moviesDF[<span style="color: #98be65;">'newMovieId'</span>] = moviesDF.index+<span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr"> 5: </span><span style="color: #c678dd;">print</span>(moviesDF.head())
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Reindex user ID</span>
<span class="linenr"> 7: </span>users = ratingDFX3.userId.unique()
<span class="linenr"> 8: </span>usersDF = pd.DataFrame(data=users,columns=[<span style="color: #98be65;">'originalUserId'</span>])
<span class="linenr"> 9: </span>usersDF[<span style="color: #98be65;">'newUserId'</span>] = usersDF.index+<span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(usersDF.head())
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Generate newly merged DataFrame</span>
<span class="linenr">12: </span>ratingDFX3 = ratingDFX3.merge(moviesDF,left_on=<span style="color: #98be65;">'movieId'</span>,
<span class="linenr">13: </span>                              right_on=<span style="color: #98be65;">'originalMovieId'</span>)
<span class="linenr">14: </span>ratingDFX3.drop(labels=<span style="color: #98be65;">'originalMovieId'</span>, axis=<span style="color: #da8548; font-weight: bold;">1</span>, inplace=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">15: </span>ratingDFX3 = ratingDFX3.merge(usersDF,left_on=<span style="color: #98be65;">'userId'</span>,
<span class="linenr">16: </span>                              right_on=<span style="color: #98be65;">'originalUserId'</span>)
<span class="linenr">17: </span>ratingDFX3.drop(labels=<span style="color: #98be65;">'originalUserId'</span>, axis=<span style="color: #da8548; font-weight: bold;">1</span>, inplace=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">18: </span><span style="color: #c678dd;">print</span>(ratingDFX3.head(<span style="color: #da8548; font-weight: bold;">3</span>))
</pre>
</div>

<pre class="example" id="orgf6ee837">
   originalMovieId  newMovieId
0               50           1
1              163           2
2              216           3
3              296           4
4              333           5
   originalUserId  newUserId
0              49          1
1             260          2
2             311          3
3             319          4
4             499          5
   userId  movieId  rating            timestamp  newMovieId  newUserId
0      49       50     5.0  2013-05-03 02:50:26           1          1
1      49      163     3.5  2013-05-03 02:43:37           2          1
2      49      216     3.0  2013-05-03 02:45:58           3          1
</pre>
</div>
</div>


<div id="outline-container-orgae4edc2" class="outline-4">
<h4 id="orgae4edc2"><span class="section-number-4">8.1.9.</span> 計算縮減資料庫大小</h4>
<div class="outline-text-4" id="text-8-1-9">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Calculate summary statistics on reduced dataset</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">n_users</span> = ratingDFX3.userId.unique().shape[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr"> 3: </span><span style="color: #dcaeea;">n_movies</span> = ratingDFX3.movieId.unique().shape[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr"> 4: </span><span style="color: #dcaeea;">n_ratings</span> = <span style="color: #c678dd;">len</span>(ratingDFX3)
<span class="linenr"> 5: </span><span style="color: #dcaeea;">avg_ratings_per_user</span> = n_ratings/n_users
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Number of unique users: </span>{n_users}<span style="color: #98be65;">'</span>)
<span class="linenr"> 8: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Number of unique movies: </span>{n_movies}<span style="color: #98be65;">'</span>)
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Number of total ratings: </span>{n_ratings}<span style="color: #98be65;">'</span>)
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Average number of ratings per user: </span>{<span style="color: #c678dd;">round</span>(avg_ratings_per_user,1)}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
Number of unique users: 1000
Number of unique movies: 1000
Number of total ratings: 90213
Average number of ratings per user: 90.2
</pre>
</div>
</div>

<div id="outline-container-org6a2b44b" class="outline-4">
<h4 id="org6a2b44b"><span class="section-number-4">8.1.10.</span> 產生訓練集、測試集和驗證集</h4>
<div class="outline-text-4" id="text-8-1-10">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Split into validation and test, such that each is 5% of the dataset</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span> = train_test_split(ratingDFX3, test_size=<span style="color: #da8548; font-weight: bold;">0.10</span>, \
<span class="linenr"> 3: </span>                                   shuffle=<span style="color: #a9a1e1;">True</span>, random_state=<span style="color: #da8548; font-weight: bold;">2018</span>)
<span class="linenr"> 4: </span>X_valid, X_test = train_test_split(X_test,     test_size=<span style="color: #da8548; font-weight: bold;">0.50</span>, \
<span class="linenr"> 5: </span>                                   shuffle=<span style="color: #a9a1e1;">True</span>, random_state=<span style="color: #da8548; font-weight: bold;">2018</span>)
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Confirm size of train, validation, and test datasets</span>
<span class="linenr"> 7: </span><span style="color: #51afef;">for</span> (l,x) <span style="color: #51afef;">in</span> [(<span style="color: #98be65;">'train'</span>,X_train),(<span style="color: #98be65;">'validation'</span>,X_valid),(<span style="color: #98be65;">'test'</span>,X_test)]:
<span class="linenr"> 8: </span>    <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Size of </span>{l}<span style="color: #98be65;"> set: </span>{<span style="color: #c678dd;">len</span>(x)}<span style="color: #98be65;">'</span>)
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(X_train.shape)
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(X_test.shape)
<span class="linenr">11: </span><span style="color: #c678dd;">print</span>(X_valid.shape)
</pre>
</div>

<pre class="example">
Size of train set: 81191
Size of validation set: 4511
Size of test set: 4511
(81191, 6)
(4511, 6)
(4511, 6)
</pre>
</div>
</div>
</div>
<div id="outline-container-org2b4a867" class="outline-3">
<h3 id="org2b4a867"><span class="section-number-3">8.2.</span> 定義loss function</h3>
<div class="outline-text-3" id="text-8-2">
<p>
先建一個 \(m\times n\) 的矩陣，\(m\) 為使用者、\(n\) 為電影。此為稀疏矩陣，因為一位使用者不會對所有電影評價。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Generate ratings matrix for train, validation and test</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">ratings_train</span> = np.zeros((n_users, n_movies))
<span class="linenr">3: </span><span style="color: #dcaeea;">ratings_valid</span> = np.zeros((n_users, n_movies))
<span class="linenr">4: </span><span style="color: #dcaeea;">ratings_test</span>  = np.zeros((n_users, n_movies))
<span class="linenr">5: </span><span style="color: #51afef;">for</span> (X,ratings) <span style="color: #51afef;">in</span> [(X_train,ratings_train),(X_valid,ratings_valid),(X_test,ratings_test)]:
<span class="linenr">6: </span>    <span style="color: #51afef;">for</span> row <span style="color: #51afef;">in</span> X.itertuples():
<span class="linenr">7: </span>        ratings[row[<span style="color: #da8548; font-weight: bold;">6</span>]-<span style="color: #da8548; font-weight: bold;">1</span>, row[<span style="color: #da8548; font-weight: bold;">5</span>]-<span style="color: #da8548; font-weight: bold;">1</span>] = row[<span style="color: #da8548; font-weight: bold;">3</span>]
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(ratings_train.shape, ratings_valid.shape, ratings_test.shape)
</pre>
</div>

<pre class="example">
(1000, 1000) (1000, 1000) (1000, 1000)
</pre>


<p>
使用MSE評估預測值與實際值間的均方差，故需要兩個大小為 <i>[n,1]</i> 的矩陣，一個放實際評價、一個放預估評價
</p>
</div>
<div id="outline-container-org5b0f571" class="outline-4">
<h4 id="org5b0f571"><span class="section-number-4">8.2.1.</span> 先將稀疏矩陣展開</h4>
<div class="outline-text-4" id="text-8-2-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Flatten the sprace matrix with the rations for the validation set. This will be the vector of actual ratings</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">actual_valid</span> = ratings_valid[ratings_valid.nonzero()].flatten()
</pre>
</div>
</div>
</div>

<div id="outline-container-org575d7cc" class="outline-4">
<h4 id="org575d7cc"><span class="section-number-4">8.2.2.</span> 以電影平均評價(3.5)做為驗證集的評價預測，計算MSE，得到基準值1.06</h4>
<div class="outline-text-4" id="text-8-2-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">pred_valid</span> = np.zeros((<span style="color: #c678dd;">len</span>(X_valid),<span style="color: #da8548; font-weight: bold;">1</span>))
<span class="linenr">2: </span><span style="color: #dcaeea;">pred_valid</span>[pred_valid==<span style="color: #da8548; font-weight: bold;">0</span>] = <span style="color: #da8548; font-weight: bold;">3.5</span>
<span class="linenr">3: </span><span style="color: #dcaeea;">naive_prediction</span> = mean_squared_error(pred_valid, actual_valid)
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Mean squared error using naive prediction: </span>{<span style="color: #c678dd;">round</span>(naive_prediction,2)}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
Mean squared error using naive prediction: 1.06
</pre>
</div>
</div>

<div id="outline-container-org94f963c" class="outline-4">
<h4 id="org94f963c"><span class="section-number-4">8.2.3.</span> 以使用者對所有其他影片的平均評價來預測一部未評價的電影評價</h4>
<div class="outline-text-4" id="text-8-2-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">ratings_valid_pred</span> = np.zeros((n_users, n_movies))
<span class="linenr">2: </span><span style="color: #dcaeea;">i</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr">3: </span><span style="color: #51afef;">for</span> row <span style="color: #51afef;">in</span> ratings_train:
<span class="linenr">4: </span>    ratings_valid_pred[i][ratings_valid_pred[i]==<span style="color: #da8548; font-weight: bold;">0</span>] = np.mean(row[row&gt;<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">5: </span>    i += <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">6: </span>
<span class="linenr">7: </span>pred_valid = ratings_valid_pred[ratings_valid.nonzero()].flatten()
<span class="linenr">8: </span>user_average = mean_squared_error(pred_valid, actual_valid)
<span class="linenr">9: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Mean squared error using user average: </span>{<span style="color: #c678dd;">round</span>(user_average,3)}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
Mean squared error using user average: 0.909
</pre>


<p>
MSE改善至0.9
</p>
</div>
</div>
<div id="outline-container-orge9c91ae" class="outline-4">
<h4 id="orge9c91ae"><span class="section-number-4">8.2.4.</span> 以所有其他使用者對於某電影的評價來預估某使用者的評價</h4>
<div class="outline-text-4" id="text-8-2-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #dcaeea;">ratings_valid_pred</span> = np.zeros((n_users, n_movies)).T
<span class="linenr"> 2: </span><span style="color: #dcaeea;">i</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr"> 3: </span><span style="color: #51afef;">for</span> row <span style="color: #51afef;">in</span> ratings_train.T:
<span class="linenr"> 4: </span>    ratings_valid_pred[i][ratings_valid_pred[i]==<span style="color: #da8548; font-weight: bold;">0</span>] = np.mean(row[row&gt;<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr"> 5: </span>    i += <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span>ratings_valid_pred = ratings_valid_pred.T
<span class="linenr"> 8: </span>pred_valid = ratings_valid_pred[ratings_valid.nonzero()].flatten()
<span class="linenr"> 9: </span>movie_average = mean_squared_error(pred_valid, actual_valid)
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Mean squared error using movie average: </span>{<span style="color: #c678dd;">round</span>(movie_average,3)}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
Mean squared error using movie average: 0.914
</pre>
</div>
</div>
</div>
<div id="outline-container-orgab8f3a4" class="outline-3">
<h3 id="orgab8f3a4"><span class="section-number-3">8.3.</span> 矩陣分解</h3>
<div class="outline-text-3" id="text-8-3">
<p>
矩陣分解(Matrix Factorization)為目前最成功且最受歡迎的協同過濾演算法之一，它將使用者-物品矩陣分解成兩個較低維度矩陣的乘積，使用者與物品各自在較低維的潛在空間內被表示。
假設使用者-物品矩陣為R，有m個使用者和n個物品，矩陣分解會建立兩個低維矩陣:H和W，
</p>
<ul class="org-ul">
<li>H為「m個使用者」X「k個潛在因子」矩陣</li>
<li>W為「k個潛在因子」X「m個使用者」矩陣</li>
</ul>
<p>
潛在因子（latent factor）k的數量決定了模型的容量，k越高模型容量越大，但當k過高則易出現過擬合現象。
</p>
</div>
<div id="outline-container-org3b6a852" class="outline-4">
<h4 id="org3b6a852"><span class="section-number-4">8.3.1.</span> 單個潛在因子</h4>
<div class="outline-text-4" id="text-8-3-1">
<p>
從最簡單的形式（只有一個潛在因子）開始，使用Keras進行矩陣分解
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>plt.clf()
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> BatchNormalization, Input, Lambda
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> Embedding, Flatten, dot
<span class="linenr"> 4: </span><span style="color: #dcaeea;">n_latent_factors</span> = <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #dcaeea;">user_input</span> = Input(shape=[<span style="color: #da8548; font-weight: bold;">1</span>], name=<span style="color: #98be65;">'user'</span>)
<span class="linenr"> 7: </span>user_embedding = Embedding(input_dim=n_users + <span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr"> 8: </span>                           output_dim=n_latent_factors,
<span class="linenr"> 9: </span>                           name=<span style="color: #98be65;">'user_embedding'</span>)(user_input)
<span class="linenr">10: </span>user_vec = Flatten(name=<span style="color: #98be65;">'flatten_users'</span>)(user_embedding)
<span class="linenr">11: </span>
<span class="linenr">12: </span>movie_input = Input(shape=[<span style="color: #da8548; font-weight: bold;">1</span>], name=<span style="color: #98be65;">'movie'</span>)
<span class="linenr">13: </span>movie_embedding = Embedding(input_dim=n_movies + <span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr">14: </span>                            output_dim=n_latent_factors,
<span class="linenr">15: </span>                            name=<span style="color: #98be65;">'movie_embedding'</span>)(movie_input)
<span class="linenr">16: </span>movie_vec = Flatten(name=<span style="color: #98be65;">'flatten_movies'</span>)(movie_embedding)
<span class="linenr">17: </span>
<span class="linenr">18: </span>product = dot([movie_vec, user_vec], axes=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">19: </span>model = Model(inputs=[user_input, movie_input], outputs=product)
<span class="linenr">20: </span>model.<span style="color: #c678dd;">compile</span>(<span style="color: #98be65;">'adam'</span>, <span style="color: #98be65;">'mean_squared_error'</span>)
<span class="linenr">21: </span>
<span class="linenr">22: </span>history = model.fit(x=[X_train.newUserId, X_train.newMovieId],
<span class="linenr">23: </span>                    y=X_train.rating, epochs=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr">24: </span>                    validation_data=([X_valid.newUserId, X_valid.newMovieId], X_valid.rating),
<span class="linenr">25: </span>                    verbose=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">26: </span>
<span class="linenr">27: </span>pd.Series(history.history[<span style="color: #98be65;">'val_loss'</span>][<span style="color: #da8548; font-weight: bold;">10</span>:]).plot(logy=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">28: </span>plt.xlabel(<span style="color: #98be65;">"Epoch"</span>)
<span class="linenr">29: </span>plt.ylabel(<span style="color: #98be65;">"Validation Error"</span>)
<span class="linenr">30: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">"Minimum MSE: </span>{<span style="color: #c678dd;">round</span>(<span style="color: #c678dd;">min</span>(history.history['val_loss']),3)}<span style="color: #98be65;">"</span>)
<span class="linenr">31: </span>plt.savefig(<span style="color: #98be65;">'images/ML-1LF.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<p>
Minimum MSE: 0.796
</p>


<div id="orge0422b7" class="figure">
<p><img src="images/ML-1LF.png" alt="ML-1LF.png" width="500" />
</p>
<p><span class="figure-number">Figure 24: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-org2e5ce48" class="outline-4">
<h4 id="org2e5ce48"><span class="section-number-4">8.3.2.</span> 三個潛在因子</h4>
<div class="outline-text-4" id="text-8-3-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>plt.clf()
<span class="linenr"> 2: </span>plt.cla()
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> BatchNormalization, Input, Lambda
<span class="linenr"> 4: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> Embedding, Flatten, dot
<span class="linenr"> 5: </span><span style="color: #dcaeea;">n_latent_factors</span> = <span style="color: #da8548; font-weight: bold;">3</span>
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">user_input</span> = Input(shape=[<span style="color: #da8548; font-weight: bold;">1</span>], name=<span style="color: #98be65;">'user'</span>)
<span class="linenr"> 8: </span>user_embedding = Embedding(input_dim=n_users + <span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr"> 9: </span>                           output_dim=n_latent_factors,
<span class="linenr">10: </span>                           name=<span style="color: #98be65;">'user_embedding'</span>)(user_input)
<span class="linenr">11: </span>user_vec = Flatten(name=<span style="color: #98be65;">'flatten_users'</span>)(user_embedding)
<span class="linenr">12: </span>
<span class="linenr">13: </span>movie_input = Input(shape=[<span style="color: #da8548; font-weight: bold;">1</span>], name=<span style="color: #98be65;">'movie'</span>)
<span class="linenr">14: </span>movie_embedding = Embedding(input_dim=n_movies + <span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr">15: </span>                            output_dim=n_latent_factors,
<span class="linenr">16: </span>                            name=<span style="color: #98be65;">'movie_embedding'</span>)(movie_input)
<span class="linenr">17: </span>movie_vec = Flatten(name=<span style="color: #98be65;">'flatten_movies'</span>)(movie_embedding)
<span class="linenr">18: </span>
<span class="linenr">19: </span>product = dot([movie_vec, user_vec], axes=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">20: </span>model = Model(inputs=[user_input, movie_input], outputs=product)
<span class="linenr">21: </span>model.<span style="color: #c678dd;">compile</span>(<span style="color: #98be65;">'adam'</span>, <span style="color: #98be65;">'mean_squared_error'</span>)
<span class="linenr">22: </span>
<span class="linenr">23: </span>history = model.fit(x=[X_train.newUserId, X_train.newMovieId],
<span class="linenr">24: </span>                    y=X_train.rating, epochs=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr">25: </span>                    validation_data=([X_valid.newUserId, X_valid.newMovieId], X_valid.rating),
<span class="linenr">26: </span>                    verbose=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">27: </span>
<span class="linenr">28: </span>pd.Series(history.history[<span style="color: #98be65;">'val_loss'</span>][<span style="color: #da8548; font-weight: bold;">10</span>:]).plot(logy=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">29: </span>plt.xlabel(<span style="color: #98be65;">"Epoch"</span>)
<span class="linenr">30: </span>plt.ylabel(<span style="color: #98be65;">"Validation Error"</span>)
<span class="linenr">31: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">"\n\nMinimum MSE: </span>{<span style="color: #c678dd;">round</span>(<span style="color: #c678dd;">min</span>(history.history['val_loss']),3)}<span style="color: #98be65;">"</span>)
<span class="linenr">32: </span>plt.savefig(<span style="color: #98be65;">'images/ML-3LF.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>
<p>
Minimum MSE: 0.76
</p>

<div id="orga385ebe" class="figure">
<p><img src="images/ML-3LF.png" alt="ML-3LF.png" width="500" />
</p>
<p><span class="figure-number">Figure 25: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-orge909c57" class="outline-4">
<h4 id="orge909c57"><span class="section-number-4">8.3.3.</span> 五個潛在因子</h4>
<div class="outline-text-4" id="text-8-3-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>plt.clf()
<span class="linenr"> 2: </span>plt.cla()
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> BatchNormalization, Input, Lambda
<span class="linenr"> 4: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> Embedding, Flatten, dot
<span class="linenr"> 5: </span><span style="color: #dcaeea;">n_latent_factors</span> = <span style="color: #da8548; font-weight: bold;">5</span>
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">user_input</span> = Input(shape=[<span style="color: #da8548; font-weight: bold;">1</span>], name=<span style="color: #98be65;">'user'</span>)
<span class="linenr"> 8: </span>user_embedding = Embedding(input_dim=n_users + <span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr"> 9: </span>                           output_dim=n_latent_factors,
<span class="linenr">10: </span>                           name=<span style="color: #98be65;">'user_embedding'</span>)(user_input)
<span class="linenr">11: </span>user_vec = Flatten(name=<span style="color: #98be65;">'flatten_users'</span>)(user_embedding)
<span class="linenr">12: </span>
<span class="linenr">13: </span>movie_input = Input(shape=[<span style="color: #da8548; font-weight: bold;">1</span>], name=<span style="color: #98be65;">'movie'</span>)
<span class="linenr">14: </span>movie_embedding = Embedding(input_dim=n_movies + <span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr">15: </span>                            output_dim=n_latent_factors,
<span class="linenr">16: </span>                            name=<span style="color: #98be65;">'movie_embedding'</span>)(movie_input)
<span class="linenr">17: </span>movie_vec = Flatten(name=<span style="color: #98be65;">'flatten_movies'</span>)(movie_embedding)
<span class="linenr">18: </span>
<span class="linenr">19: </span>product = dot([movie_vec, user_vec], axes=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">20: </span>model = Model(inputs=[user_input, movie_input], outputs=product)
<span class="linenr">21: </span>model.<span style="color: #c678dd;">compile</span>(<span style="color: #98be65;">'adam'</span>, <span style="color: #98be65;">'mean_squared_error'</span>)
<span class="linenr">22: </span>
<span class="linenr">23: </span>history = model.fit(x=[X_train.newUserId, X_train.newMovieId],
<span class="linenr">24: </span>                    y=X_train.rating, epochs=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr">25: </span>                    validation_data=([X_valid.newUserId, X_valid.newMovieId], X_valid.rating),
<span class="linenr">26: </span>                    verbose=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">27: </span>
<span class="linenr">28: </span>pd.Series(history.history[<span style="color: #98be65;">'val_loss'</span>][<span style="color: #da8548; font-weight: bold;">10</span>:]).plot(logy=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">29: </span>plt.xlabel(<span style="color: #98be65;">"Epoch"</span>)
<span class="linenr">30: </span>plt.ylabel(<span style="color: #98be65;">"Validation Error"</span>)
<span class="linenr">31: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">"\n\nMinimum MSE: </span>{<span style="color: #c678dd;">round</span>(<span style="color: #c678dd;">min</span>(history.history['val_loss']),3)}<span style="color: #98be65;">"</span>)
<span class="linenr">32: </span>plt.savefig(<span style="color: #98be65;">'images/ML-5LF.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>
<p>
Minimum MSE: 0.749
</p>
<p width="500">
<img src="images/ML-5LF.png" alt="ML-5LF.png" width="500" />
在前25回合後，有明顯的過擬合現象。
</p>
</div>
</div>
</div>
<div id="outline-container-orgc1d72c0" class="outline-3">
<h3 id="orgc1d72c0"><span class="section-number-3">8.4.</span> 使用RBMs的協同過濾</h3>
<div class="outline-text-3" id="text-8-4">
<p>
受限玻爾茲曼機（RBM，Restricted Boltzmann machine）由多倫多大學的 Geoff Hinton 等人提出，它是一種可以用於降維、分類、回歸、協同過濾、特徵學習以及主題建模的算法。
</p>

<p>
RBMs有兩層：輸入/可視層(input layer/visible layer)和和隱藏層(hidden layer)，每一層的神經元會與其他層的神經元溝通，但不會與同層內的神經元有所連接，這是RBMs的限制。
</p>

<p>
RBMs的另一重要特徵是：層之間的溝通是雙向而非單向。
</p>

<p>
RBMs中的可視層神經元會與隱藏層的神經元溝通，然後隱藏層神經元會回傳資訊給可視層，如此來回數次。RBMs進行這種形式的溝通來發展生成模型，使隱藏層的輸出經過重新建構、近似於原先的輸入。
</p>

<p>
換言之，RMBs試圖建立一個生成模型，這個模型基於以下兩個相似度來協助預測使用者是否喜歡某部電影：
</p>
<ul class="org-ul">
<li>某部電影與使用者作過評價的其他電影間的相似度</li>
<li>使用者與為某部電影作過評價的其他使用者間的相似度</li>
</ul>

<p>
可視層中會有X個神經元，X為電影數量。每一個神經元有一個介於0~1的評價(經過歸一化)。可視層的神經元會與隱藏層的神經元溝通，隱藏層的神經元會試著學習資料內部的潛在特徵。
</p>

<p>
RBMs也被稱為對稱二分雙向圖，對稱是因為每個可視的節點都被連接到每個隱藏層的結點，二分是因為有兩層節點，雙向是因為資訊的交流。
</p>
</div>
</div>
<div id="outline-container-org100a22e" class="outline-3">
<h3 id="org100a22e"><span class="section-number-3">8.5.</span> RBM神經網路架構</h3>
<div class="outline-text-3" id="text-8-5">
<p>
參考網路教學&#x2026;.這裡寫的太抽象(這本書竟然想用文字來把它說完，太不負責任)
</p>
<ul class="org-ul">
<li>有m個使用者和n部電影，有一個$m&times; n$的矩陣</li>
<li>訓練RBM時批次傳入k個使用者與其對n部電影的評價，進行特定回合的訓練</li>
<li>每個被傳入神經網路的x代表一個使用者對n部電影的評價，可視層有n個節點</li>
<li>可以指定隱藏層的節點數量(通常會少於可視層，以便有效率的學習特徵)</li>
<li>每個輸入$v0$與其相對應的權重$w$相乘，這個權重是透過可視層到隱藏層的資訊交流而學習到的。最後加上一個隱藏層的偏差值向量\(hb\)，這個偏差值是為了確保至少有些神經元會觸發，然後將函數$W &times; v0+hb$的結果傳入一個激活函數裡。</li>
<li>接下來對這個流程的輸出結果進行採樣(稝為 <i>Gibbs</i> 採樣)，也就是從隱藏層的激活函數的輸出最終是被隨機挑選，這種隨機方式有助於強化模型的效能與強韌性。</li>
<li>在 <i>Gibbs</i> 採樣後的輸出$h0$透過神經網路以相反的方向被回傳，這個過程稱為backward pass。在backward pass中，那些在forward pass中經由 <i>Gibbs</i> 採樣後的激活函數計算結果被傳入隱藏層，並與之前相同的權重W相乘，然後再加上可視層的新偏差向量vb。</li>
</ul>
</div>
</div>
<div id="outline-container-org223be6e" class="outline-3">
<h3 id="org223be6e"><span class="section-number-3">8.6.</span> 重建RBM元件</h3>
<div class="outline-text-3" id="text-8-6">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Make code compatible with v1 of TF</span>
<span class="linenr"> 2: </span>tf.compat.v1.disable_eager_execution()
<span class="linenr"> 3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Define RBM class</span>
<span class="linenr"> 4: </span><span style="color: #51afef;">class</span> <span style="color: #ECBE7B;">RBM</span>(<span style="color: #c678dd;">object</span>):
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">__init__</span>(<span style="color: #51afef;">self</span>, input_size, output_size,
<span class="linenr"> 7: </span>                 learning_rate, epochs, batchsize):
<span class="linenr"> 8: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23450;&#32681;&#36229;&#21443;&#25976;</span>
<span class="linenr"> 9: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">_input_size</span> = input_size
<span class="linenr">10: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">_output_size</span> = output_size
<span class="linenr">11: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">learning_rate</span> = learning_rate
<span class="linenr">12: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">epochs</span> = epochs
<span class="linenr">13: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">batchsize</span> = batchsize
<span class="linenr">14: </span>
<span class="linenr">15: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21033;&#29992;&#38646;&#30697;&#38499;&#21021;&#22987;&#21270;&#27402;&#37325;&#30697;&#38499;&#33287;&#20559;&#24046;&#30697;&#38499;</span>
<span class="linenr">16: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">w</span> = np.zeros([input_size, output_size], dtype=np.float32)
<span class="linenr">17: </span>        <span style="color: #51afef;">self</span>.hb = np.zeros([output_size], dtype=np.float32)
<span class="linenr">18: </span>        <span style="color: #51afef;">self</span>.vb = np.zeros([input_size], dtype=np.float32)
<span class="linenr">19: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#27491;&#21521;&#20659;&#36958;&#20989;&#24335;&#65292;h&#28858;&#38577;&#34255;&#23652;&#65292;v&#28858;&#21487;&#35222;&#23652;</span>
<span class="linenr">20: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">prob_h_given_v</span>(<span style="color: #51afef;">self</span>, visible, w, hb):
<span class="linenr">21: </span>        <span style="color: #51afef;">return</span> tf.nn.sigmoid(tf.matmul(visible, w) + hb)
<span class="linenr">22: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#21453;&#21521;&#20659;&#36958;&#20989;&#24335;</span>
<span class="linenr">23: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">prob_v_given_h</span>(<span style="color: #51afef;">self</span>, hidden, w, vb):
<span class="linenr">24: </span>        <span style="color: #51afef;">return</span> tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)
<span class="linenr">25: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25505;&#27171;&#20989;&#24335;</span>
<span class="linenr">26: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">sample_prob</span>(<span style="color: #51afef;">self</span>, probs):
<span class="linenr">27: </span>        <span style="color: #51afef;">return</span> tf.nn.relu(tf.sign(probs - tf.random.uniform(tf.shape(probs))))
<span class="linenr">28: </span>
<span class="linenr">29: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">train</span>(<span style="color: #51afef;">self</span>, X):
<span class="linenr">30: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#20197;tensorflow&#24314;&#31435;&#19977;&#20491;placeholder: &#27402;&#37325;&#30697;&#38499;&#12289;&#38577;&#34255;&#23652;&#30340;&#20559;&#24046;&#20540;&#21521;&#37327;&#12289;&#21487;&#35222;&#23652;&#30340;&#20559;&#24046;&#20540;&#21521;&#37327;</span>
<span class="linenr">31: </span>        _w = tf.compat.v1.placeholder(tf.float32, [<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size])
<span class="linenr">32: </span>        _hb = tf.compat.v1.placeholder(tf.float32, [<span style="color: #51afef;">self</span>._output_size])
<span class="linenr">33: </span>        _vb = tf.compat.v1.placeholder(tf.float32, [<span style="color: #51afef;">self</span>._input_size])
<span class="linenr">34: </span>
<span class="linenr">35: </span>        prv_w = np.zeros([<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr">36: </span>        prv_hb = np.zeros([<span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr">37: </span>        prv_vb = np.zeros([<span style="color: #51afef;">self</span>._input_size], dtype=np.float32)
<span class="linenr">38: </span>
<span class="linenr">39: </span>        cur_w = np.zeros([<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr">40: </span>        cur_hb = np.zeros([<span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr">41: </span>        cur_vb = np.zeros([<span style="color: #51afef;">self</span>._input_size], dtype=np.float32)
<span class="linenr">42: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#32102;&#21487;&#35222;&#23652;&#30340;placehold</span>
<span class="linenr">43: </span>        v0 = tf.compat.v1.placeholder(tf.float32, [<span style="color: #a9a1e1;">None</span>, <span style="color: #51afef;">self</span>._input_size])
<span class="linenr">44: </span>        h0 = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_h_given_v(v0, _w, _hb))
<span class="linenr">45: </span>        v1 = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_v_given_h(h0, _w, _vb))
<span class="linenr">46: </span>        h1 = <span style="color: #51afef;">self</span>.prob_h_given_v(v1, _w, _hb)
<span class="linenr">47: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23450;&#32681;&#35492;&#24046; MSE</span>
<span class="linenr">48: </span>        positive_grad = tf.matmul(tf.transpose(v0), h0)
<span class="linenr">49: </span>        negative_grad = tf.matmul(tf.transpose(v1), h1)
<span class="linenr">50: </span>
<span class="linenr">51: </span>        update_w = _w + <span style="color: #51afef;">self</span>.learning_rate * \
<span class="linenr">52: </span>            (positive_grad - negative_grad) / tf.cast(tf.shape(v0)[<span style="color: #da8548; font-weight: bold;">0</span>], tf.float32)
<span class="linenr">53: </span>        update_vb = _vb +  <span style="color: #51afef;">self</span>.learning_rate * tf.reduce_mean(v0 - v1, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">54: </span>        update_hb = _hb +  <span style="color: #51afef;">self</span>.learning_rate * tf.reduce_mean(h0 - h1, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">55: </span>
<span class="linenr">56: </span>        err = tf.reduce_mean(tf.square(v0 - v1))
<span class="linenr">57: </span>
<span class="linenr">58: </span>        error_list = []
<span class="linenr">59: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#21021;&#22987;&#21270;TensorFlow&#24037;&#20316;&#38542;&#27573;</span>
<span class="linenr">60: </span>        <span style="color: #51afef;">with</span> tf.compat.v1.Session() <span style="color: #51afef;">as</span> sess:
<span class="linenr">61: </span>            <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25209;&#27425;&#23559;&#36039;&#26009;&#20659;&#20837;&#36914;&#34892;&#35347;&#32244;</span>
<span class="linenr">62: </span>            sess.run(tf.compat.v1.global_variables_initializer())
<span class="linenr">63: </span>
<span class="linenr">64: </span>            <span style="color: #51afef;">for</span> epoch <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #51afef;">self</span>.epochs):
<span class="linenr">65: </span>                <span style="color: #51afef;">for</span> start, end <span style="color: #51afef;">in</span> <span style="color: #c678dd;">zip</span>(<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #c678dd;">len</span>(X), \
<span class="linenr">66: </span>                        <span style="color: #51afef;">self</span>.batchsize),<span style="color: #c678dd;">range</span>(<span style="color: #51afef;">self</span>.batchsize,<span style="color: #c678dd;">len</span>(X), \
<span class="linenr">67: </span>                                              <span style="color: #51afef;">self</span>.batchsize)):
<span class="linenr">68: </span>                    batch = X[start:end]
<span class="linenr">69: </span>                    cur_w = sess.run(update_w, feed_dict={v0: batch, \
<span class="linenr">70: </span>                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr">71: </span>                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, \
<span class="linenr">72: </span>                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr">73: </span>                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, \
<span class="linenr">74: </span>                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr">75: </span>                    prv_w = cur_w
<span class="linenr">76: </span>                    prv_hb = cur_hb
<span class="linenr">77: </span>                    prv_vb = cur_vb
<span class="linenr">78: </span>                error = sess.run(err, feed_dict={v0: X, \
<span class="linenr">79: </span>                                _w: cur_w, _vb: cur_vb, _hb: cur_hb})
<span class="linenr">80: </span>                <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">'Epoch: %d'</span> % epoch,<span style="color: #98be65;">'reconstruction error: %f'</span> % error)
<span class="linenr">81: </span>                error_list.append(error)
<span class="linenr">82: </span>            <span style="color: #51afef;">self</span>.w = prv_w
<span class="linenr">83: </span>            <span style="color: #51afef;">self</span>.hb = prv_hb
<span class="linenr">84: </span>            <span style="color: #51afef;">self</span>.vb = prv_vb
<span class="linenr">85: </span>            <span style="color: #51afef;">return</span> error_list
<span class="linenr">86: </span>
<span class="linenr">87: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">rbm_output</span>(<span style="color: #51afef;">self</span>, X):
<span class="linenr">88: </span>
<span class="linenr">89: </span>        input_X = tf.constant(X)
<span class="linenr">90: </span>        _w = tf.constant(<span style="color: #51afef;">self</span>.w)
<span class="linenr">91: </span>        _hb = tf.constant(<span style="color: #51afef;">self</span>.hb)
<span class="linenr">92: </span>        _vb = tf.constant(<span style="color: #51afef;">self</span>.vb)
<span class="linenr">93: </span>        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)
<span class="linenr">94: </span>        hiddenGen = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_h_given_v(input_X, _w, _hb))
<span class="linenr">95: </span>        visibleGen = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_v_given_h(hiddenGen, _w, _vb))
<span class="linenr">96: </span>        <span style="color: #51afef;">with</span> tf.compat.v1.Session() <span style="color: #51afef;">as</span> sess:
<span class="linenr">97: </span>            sess.run(tf.compat.v1.global_variables_initializer())
<span class="linenr">98: </span>            <span style="color: #51afef;">return</span> sess.run(out), sess.run(visibleGen), sess.run(hiddenGen)
</pre>
</div>
</div>
</div>
<div id="outline-container-org3d2b5f6" class="outline-3">
<h3 id="org3d2b5f6"><span class="section-number-3">8.7.</span> 訓練</h3>
<div class="outline-text-3" id="text-8-7">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Convert inputX into float32</span>
<span class="linenr"> 2: </span>plt.clf()
<span class="linenr"> 3: </span><span style="color: #dcaeea;">inputX</span> = ratings_train
<span class="linenr"> 4: </span><span style="color: #dcaeea;">inputX</span> = inputX.astype(np.float32)
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Define the parameters of the RBMs we will train</span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">rbm</span>=RBM(<span style="color: #da8548; font-weight: bold;">1000</span>,<span style="color: #da8548; font-weight: bold;">1000</span>,<span style="color: #da8548; font-weight: bold;">1</span>,<span style="color: #da8548; font-weight: bold;">1000</span>,<span style="color: #da8548; font-weight: bold;">200</span>)
<span class="linenr"> 8: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Train RBM model</span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">err</span> = rbm.train(inputX)
<span class="linenr">10: </span><span style="color: #dcaeea;">outputX</span>, <span style="color: #dcaeea;">reconstructedX</span>, <span style="color: #dcaeea;">hiddenX</span> = rbm.rbm_output(inputX)
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Plot reconstruction errors</span>
<span class="linenr">12: </span>pd.Series(err).plot(logy=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">13: </span>plt.xlabel(<span style="color: #98be65;">"Epoch"</span>)
<span class="linenr">14: </span>plt.ylabel(<span style="color: #98be65;">"Reconstruction Error"</span>);
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">'images/ML-RBM.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">16: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Predict ratings for validation set</span>
<span class="linenr">17: </span>inputValid = ratings_valid
<span class="linenr">18: </span>inputValid = inputValid.astype(np.float32)
<span class="linenr">19: </span>
<span class="linenr">20: </span><span style="color: #dcaeea;">_</span>, <span style="color: #dcaeea;">reconstructedOutput_valid</span>, <span style="color: #dcaeea;">_</span> = rbm.rbm_output(inputValid)
<span class="linenr">21: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Calculate MSE on validation set</span>
<span class="linenr">22: </span>predictionsArray = reconstructedOutput_valid
<span class="linenr">23: </span>pred_valid = predictionsArray[ratings_valid.nonzero()].flatten()
<span class="linenr">24: </span>actual_valid = ratings_valid[ratings_valid.nonzero()].flatten()
<span class="linenr">25: </span>
<span class="linenr">26: </span>rbm_prediction = mean_squared_error(pred_valid, actual_valid)
<span class="linenr">27: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Mean squared error using RBM prediction: </span>{<span style="color: #c678dd;">round</span>(rbm_prediction,2)}<span style="color: #98be65;">'</span>)
</pre>
</div>

<p>
Epoch: 0 reconstruction error: 1.106261
Epoch: 1 reconstruction error: 1.079569
Epoch: 2 reconstruction error: 1.086965
&#x2026;
Epoch: 998 reconstruction error: 1.072312
Epoch: 999 reconstruction error: 1.072114
Mean squared error using RBM prediction: 9.34
</p>

<div id="org5c1e314" class="figure">
<p><img src="images/ML-RBM.png" alt="ML-RBM.png" width="500" />
</p>
<p><span class="figure-number">Figure 26: </span>Caption</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org2c41972" class="outline-2">
<h2 id="org2c41972"><span class="section-number-2">9.</span> 深度信念網路(DBNs)</h2>
<div class="outline-text-2" id="text-9">
<p>
DBNs在2006年由Geoffrey Hinton在多倫多大學提出。RBMs只有兩層，DBNs由多個RBMs組成，一個RBMs的隱藏層是下一個RBMs的可視層。DBNs可以用來辨識、分群圖片、聲音、文字、影片。
在DBN中，一次只有一層被訓練，從最前面緊鄰輸入層的隱藏層開始，建構第一個RBM，當第一個RBM被訓練完後，第一個RBM的隱藏層就會被當做下一個RBM的可視層，用來訓練第二個RBM的隱藏層。
</p>
</div>
<div id="outline-container-org3b1389d" class="outline-3">
<h3 id="org3b1389d"><span class="section-number-3">9.1.</span> MNIST分類</h3>
<div class="outline-text-3" id="text-9-1">
</div>
<div id="outline-container-org0b432e1" class="outline-4">
<h4 id="org0b432e1"><span class="section-number-4">9.1.1.</span> 載入函式庫</h4>
<div class="outline-text-4" id="text-9-1-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #83898d;">'''Main'''</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 4: </span><span style="color: #51afef;">import</span> os, time, re
<span class="linenr"> 5: </span><span style="color: #51afef;">import</span> pickle, gzip, datetime
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #98be65;">'''Data Viz'''</span>
<span class="linenr"> 8: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 9: </span><span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span class="linenr">10: </span><span style="color: #dcaeea;">color</span> = sns.color_palette()
<span class="linenr">11: </span><span style="color: #51afef;">import</span> matplotlib <span style="color: #51afef;">as</span> mpl
<span class="linenr">12: </span><span style="color: #51afef;">from</span> mpl_toolkits.axes_grid1 <span style="color: #51afef;">import</span> Grid
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #98be65;">'''Data Prep and Model Evaluation'''</span>
<span class="linenr">15: </span><span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> preprocessing <span style="color: #51afef;">as</span> pp
<span class="linenr">16: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span class="linenr">17: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> StratifiedKFold
<span class="linenr">18: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> log_loss, accuracy_score
<span class="linenr">19: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> precision_recall_curve, average_precision_score
<span class="linenr">20: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> roc_curve, auc, roc_auc_score, mean_squared_error
<span class="linenr">21: </span>
<span class="linenr">22: </span><span style="color: #98be65;">'''Algos'''</span>
<span class="linenr">23: </span><span style="color: #51afef;">import</span> lightgbm <span style="color: #51afef;">as</span> lgb
<span class="linenr">24: </span>
<span class="linenr">25: </span><span style="color: #98be65;">'''TensorFlow and Keras'''</span>
<span class="linenr">26: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr">27: </span><span style="color: #51afef;">from</span> tensorflow <span style="color: #51afef;">import</span> keras
<span class="linenr">28: </span><span style="color: #dcaeea;">K</span> = keras.backend
<span class="linenr">29: </span>
<span class="linenr">30: </span><span style="color: #51afef;">from</span> tensorflow.keras.models <span style="color: #51afef;">import</span> Sequential, Model
<span class="linenr">31: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> Activation, Dense, Dropout
<span class="linenr">32: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> BatchNormalization, Input, Lambda
<span class="linenr">33: </span><span style="color: #51afef;">from</span> tensorflow.keras.layers <span style="color: #51afef;">import</span> Embedding, Flatten, dot
<span class="linenr">34: </span><span style="color: #51afef;">from</span> tensorflow.keras <span style="color: #51afef;">import</span> regularizers
<span class="linenr">35: </span><span style="color: #51afef;">from</span> tensorflow.keras.losses <span style="color: #51afef;">import</span> mse, binary_crossentropy
<span class="linenr">36: </span><span style="color: #51afef;">import</span> sys, sklearn
<span class="linenr">37: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'sklearn    </span>{sklearn.__version__}<span style="color: #98be65;">'</span>)
<span class="linenr">38: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'tensorflow </span>{tf.__version__}<span style="color: #98be65;">'</span>)
<span class="linenr">39: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'keras      </span>{keras.__version__}<span style="color: #98be65;">'</span>)
<span class="linenr">40: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'numpy      </span>{np.__version__}<span style="color: #98be65;">'</span>)
<span class="linenr">41: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">To make the output stable across runs</span>
<span class="linenr">42: </span>tf.random.set_seed(<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">43: </span>np.random.seed(<span style="color: #da8548; font-weight: bold;">42</span>)
</pre>
</div>

<pre class="example">
Python 3.7.13 (default, Mar 28 2022, 07:24:34)
[Clang 12.0.0 ] :: Anaconda, Inc. on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; sklearn    1.0.2
tensorflow 2.0.0
keras      2.2.4-tf
numpy      1.21.5
</pre>
</div>
</div>

<div id="outline-container-org8e7232e" class="outline-4">
<h4 id="org8e7232e"><span class="section-number-4">9.1.2.</span> 資料準備</h4>
<div class="outline-text-4" id="text-9-1-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Load the datasets</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">current_path</span> = os.getcwd()
<span class="linenr"> 3: </span><span style="color: #c678dd;">file</span> = os.path.sep.join([<span style="color: #98be65;">''</span>, <span style="color: #98be65;">'dataset'</span>, <span style="color: #98be65;">'mnist.pkl.gz'</span>])
<span class="linenr"> 4: </span><span style="color: #dcaeea;">f</span> = gzip.<span style="color: #c678dd;">open</span>(current_path+<span style="color: #c678dd;">file</span>, <span style="color: #98be65;">'rb'</span>)
<span class="linenr"> 5: </span><span style="color: #dcaeea;">train_set</span>, <span style="color: #dcaeea;">validation_set</span>, <span style="color: #dcaeea;">test_set</span> = pickle.load(f, encoding=<span style="color: #98be65;">'latin1'</span>)
<span class="linenr"> 6: </span>f.close()
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span>X_train, y_train = train_set[<span style="color: #da8548; font-weight: bold;">0</span>], train_set[<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 9: </span>X_validation, y_validation = validation_set[<span style="color: #da8548; font-weight: bold;">0</span>], validation_set[<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr">10: </span>X_test, y_test = test_set[<span style="color: #da8548; font-weight: bold;">0</span>], test_set[<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Verify shape of datasets</span>
<span class="linenr">12: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Shape of X_train: "</span>, X_train.shape)
<span class="linenr">13: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Shape of y_train: "</span>, y_train.shape)
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Shape of X_validation: "</span>, X_validation.shape)
<span class="linenr">15: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Shape of y_validation: "</span>, y_validation.shape)
<span class="linenr">16: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Shape of X_test: "</span>, X_test.shape)
<span class="linenr">17: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Shape of y_test: "</span>, y_test.shape)
</pre>
</div>

<pre class="example">
Shape of X_train:  (50000, 784)
Shape of y_train:  (50000,)
Shape of X_validation:  (10000, 784)
Shape of y_validation:  (10000,)
Shape of X_test:  (10000, 784)
Shape of y_test:  (10000,)
</pre>
</div>
</div>

<div id="outline-container-org9041ad6" class="outline-4">
<h4 id="org9041ad6"><span class="section-number-4">9.1.3.</span> 建立資料集</h4>
<div class="outline-text-4" id="text-9-1-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create Pandas DataFrames from the datasets</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">train_index</span> = <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #c678dd;">len</span>(X_train))
<span class="linenr"> 3: </span><span style="color: #dcaeea;">validation_index</span> = <span style="color: #c678dd;">range</span>(<span style="color: #c678dd;">len</span>(X_train),<span style="color: #c678dd;">len</span>(X_train)+<span style="color: #c678dd;">len</span>(X_validation))
<span class="linenr"> 4: </span><span style="color: #dcaeea;">test_index</span> = <span style="color: #c678dd;">range</span>(<span style="color: #c678dd;">len</span>(X_train)+<span style="color: #c678dd;">len</span>(X_validation), \
<span class="linenr"> 5: </span>                   <span style="color: #c678dd;">len</span>(X_train)+<span style="color: #c678dd;">len</span>(X_validation)+<span style="color: #c678dd;">len</span>(X_test))
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">X_train</span> = pd.DataFrame(data=X_train,index=train_index)
<span class="linenr"> 8: </span>y_train = pd.Series(data=y_train,index=train_index)
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>X_validation = pd.DataFrame(data=X_validation,index=validation_index)
<span class="linenr">11: </span>y_validation = pd.Series(data=y_validation,index=validation_index)
<span class="linenr">12: </span>
<span class="linenr">13: </span>X_test = pd.DataFrame(data=X_test,index=test_index)
<span class="linenr">14: </span>y_test = pd.Series(data=y_test,index=test_index)
<span class="linenr">15: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Describe the training matrix</span>
<span class="linenr">16: </span><span style="color: #c678dd;">print</span>(X_train.describe())
</pre>
</div>

<pre class="example" id="orgcadbdaa">
           0        1        2        3        4        5        6    ...           777           778           779      780      781      782      783
count  50000.0  50000.0  50000.0  50000.0  50000.0  50000.0  50000.0  ...  50000.000000  50000.000000  50000.000000  50000.0  50000.0  50000.0  50000.0
mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000090      0.000071      0.000009      0.0      0.0      0.0      0.0
std        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.007217      0.007181      0.001483      0.0      0.0      0.0      0.0
min        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
max        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.988281      0.992188      0.242188      0.0      0.0      0.0      0.0

[8 rows x 784 columns]
</pre>
</div>
</div>


<div id="outline-container-org11b7899" class="outline-4">
<h4 id="org11b7899"><span class="section-number-4">9.1.4.</span> View the digit image</h4>
<div class="outline-text-4" id="text-9-1-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">view_digit</span>(X, y, example, fn):
<span class="linenr"> 2: </span>    plt.cla()
<span class="linenr"> 3: </span>    <span style="color: #dcaeea;">label</span> = y.loc[example]
<span class="linenr"> 4: </span>    <span style="color: #dcaeea;">image</span> = X.loc[example,:].values.reshape([<span style="color: #da8548; font-weight: bold;">28</span>,<span style="color: #da8548; font-weight: bold;">28</span>])
<span class="linenr"> 5: </span>    plt.title(<span style="color: #98be65;">'Example: %d  Label: %d'</span> % (example, label))
<span class="linenr"> 6: </span>    plt.imshow(image, cmap=plt.get_cmap(<span style="color: #98be65;">'gray'</span>))
<span class="linenr"> 7: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr"> 8: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35201;&#23384;&#27284;&#30340;&#35441;&#23601;&#19981;&#35201;&#29992;show()?</span>
<span class="linenr"> 9: </span>    plt.tight_layout()
<span class="linenr">10: </span>    plt.savefig(fn, dpi=<span style="color: #da8548; font-weight: bold;">300</span>, bbox_inches = <span style="color: #98be65;">'tight'</span>)
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">View the first digit</span>
<span class="linenr">12: </span>view_digit(X_train, y_train, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #98be65;">'images/firsttest.png'</span>)
</pre>
</div>


<div id="orgf19048e" class="figure">
<p><img src="images/firsttest.png" alt="firsttest.png" width="500" />
</p>
<p><span class="figure-number">Figure 27: </span>Caption</p>
</div>
</div>
</div>

<div id="outline-container-org4fb17c2" class="outline-4">
<h4 id="org4fb17c2"><span class="section-number-4">9.1.5.</span> 將label以one-hot encoding編碼</h4>
<div class="outline-text-4" id="text-9-1-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">one_hot</span>(series):
<span class="linenr"> 2: </span>    <span style="color: #dcaeea;">label_binarizer</span> = pp.LabelBinarizer()
<span class="linenr"> 3: </span>    label_binarizer.fit(<span style="color: #c678dd;">range</span>(<span style="color: #c678dd;">max</span>(series)+<span style="color: #da8548; font-weight: bold;">1</span>))
<span class="linenr"> 4: </span>    <span style="color: #51afef;">return</span> label_binarizer.transform(series)
<span class="linenr"> 5: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">reverse_one_hot</span>(originalSeries, newSeries):
<span class="linenr"> 6: </span>    <span style="color: #dcaeea;">label_binarizer</span> = pp.LabelBinarizer()
<span class="linenr"> 7: </span>    label_binarizer.fit(<span style="color: #c678dd;">range</span>(<span style="color: #c678dd;">max</span>(originalSeries)+<span style="color: #da8548; font-weight: bold;">1</span>))
<span class="linenr"> 8: </span>    <span style="color: #51afef;">return</span> label_binarizer.inverse_transform(newSeries)
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create one-hot vectors for the labels</span>
<span class="linenr">10: </span><span style="color: #dcaeea;">y_train_oneHot</span> = one_hot(y_train)
<span class="linenr">11: </span><span style="color: #dcaeea;">y_validation_oneHot</span> = one_hot(y_validation)
<span class="linenr">12: </span><span style="color: #dcaeea;">y_test_oneHot</span> = one_hot(y_test)
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Show one-hot vector for example 0, which is the number 5</span>
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">15: </span><span style="color: #c678dd;">print</span>(y_train_oneHot[<span style="color: #da8548; font-weight: bold;">0</span>])
</pre>
</div>

<pre class="example">
5
[0 0 0 0 0 1 0 0 0 0]
</pre>

<p>
圖<a href="#orgf19048e">27</a>的label和相對應的one-hot encoding如下:
</p>
<pre class="example">
5
[0 0 0 0 0 1 0 0 0 0]
</pre>
</div>
</div>
</div>

<div id="outline-container-org168ddcd" class="outline-3">
<h3 id="org168ddcd"><span class="section-number-3">9.2.</span> Restricted Boltzmann Machines (RBMs)</h3>
<div class="outline-text-3" id="text-9-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">  1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Make code compatible with v1 of TF</span>
<span class="linenr">  2: </span>tf.compat.v1.disable_eager_execution()
<span class="linenr">  3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Define RBM class</span>
<span class="linenr">  4: </span><span style="color: #51afef;">class</span> <span style="color: #ECBE7B;">RBM</span>(<span style="color: #c678dd;">object</span>):
<span class="linenr">  5: </span>
<span class="linenr">  6: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">__init__</span>(<span style="color: #51afef;">self</span>, input_size, output_size,
<span class="linenr">  7: </span>                 learning_rate, epochs, batchsize):
<span class="linenr">  8: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Define hyperparameters</span>
<span class="linenr">  9: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">_input_size</span> = input_size
<span class="linenr"> 10: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">_output_size</span> = output_size
<span class="linenr"> 11: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">learning_rate</span> = learning_rate
<span class="linenr"> 12: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">epochs</span> = epochs
<span class="linenr"> 13: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">batchsize</span> = batchsize
<span class="linenr"> 14: </span>
<span class="linenr"> 15: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Initialize weights and biases using zero matrices</span>
<span class="linenr"> 16: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">w</span> = np.zeros([input_size, output_size], dtype=np.float32)
<span class="linenr"> 17: </span>        <span style="color: #51afef;">self</span>.hb = np.zeros([output_size], dtype=np.float32)
<span class="linenr"> 18: </span>        <span style="color: #51afef;">self</span>.vb = np.zeros([input_size], dtype=np.float32)
<span class="linenr"> 19: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27491;&#21521;&#20659;&#36958;</span>
<span class="linenr"> 20: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">prob_h_given_v</span>(<span style="color: #51afef;">self</span>, visible, w, hb):
<span class="linenr"> 21: </span>        <span style="color: #51afef;">return</span> tf.nn.sigmoid(tf.matmul(visible, w) + hb)
<span class="linenr"> 22: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21453;&#21521;&#20659;&#36958;</span>
<span class="linenr"> 23: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">prob_v_given_h</span>(<span style="color: #51afef;">self</span>, hidden, w, vb):
<span class="linenr"> 24: </span>        <span style="color: #51afef;">return</span> tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)
<span class="linenr"> 25: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25506;&#27171;</span>
<span class="linenr"> 26: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">sample_prob</span>(<span style="color: #51afef;">self</span>, probs):
<span class="linenr"> 27: </span>        <span style="color: #51afef;">return</span> tf.nn.relu(tf.sign(probs - tf.compat.v1.random_uniform(tf.shape(probs))))
<span class="linenr"> 28: </span>
<span class="linenr"> 29: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">train</span>(<span style="color: #51afef;">self</span>, X):
<span class="linenr"> 30: </span>        _w = tf.compat.v1.placeholder(tf.float32, [<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size])
<span class="linenr"> 31: </span>        _hb = tf.compat.v1.placeholder(tf.float32, [<span style="color: #51afef;">self</span>._output_size])
<span class="linenr"> 32: </span>        _vb = tf.compat.v1.placeholder(tf.float32, [<span style="color: #51afef;">self</span>._input_size])
<span class="linenr"> 33: </span>
<span class="linenr"> 34: </span>        prv_w = np.zeros([<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr"> 35: </span>        prv_hb = np.zeros([<span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr"> 36: </span>        prv_vb = np.zeros([<span style="color: #51afef;">self</span>._input_size], dtype=np.float32)
<span class="linenr"> 37: </span>
<span class="linenr"> 38: </span>        cur_w = np.zeros([<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr"> 39: </span>        cur_hb = np.zeros([<span style="color: #51afef;">self</span>._output_size], dtype=np.float32)
<span class="linenr"> 40: </span>        cur_vb = np.zeros([<span style="color: #51afef;">self</span>._input_size], dtype=np.float32)
<span class="linenr"> 41: </span>
<span class="linenr"> 42: </span>        v0 = tf.compat.v1.placeholder(tf.float32, [<span style="color: #a9a1e1;">None</span>, <span style="color: #51afef;">self</span>._input_size])
<span class="linenr"> 43: </span>        h0 = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_h_given_v(v0, _w, _hb))
<span class="linenr"> 44: </span>        v1 = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_v_given_h(h0, _w, _vb))
<span class="linenr"> 45: </span>        h1 = <span style="color: #51afef;">self</span>.prob_h_given_v(v1, _w, _hb)
<span class="linenr"> 46: </span>
<span class="linenr"> 47: </span>        positive_grad = tf.matmul(tf.transpose(v0), h0)
<span class="linenr"> 48: </span>        negative_grad = tf.matmul(tf.transpose(v1), h1)
<span class="linenr"> 49: </span>
<span class="linenr"> 50: </span>        update_w = _w + <span style="color: #51afef;">self</span>.learning_rate * \
<span class="linenr"> 51: </span>            (positive_grad - negative_grad) / tf.cast(tf.shape(v0)[<span style="color: #da8548; font-weight: bold;">0</span>], tf.float32)
<span class="linenr"> 52: </span>        update_vb = _vb +  <span style="color: #51afef;">self</span>.learning_rate * tf.reduce_mean(v0 - v1, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr"> 53: </span>        update_hb = _hb +  <span style="color: #51afef;">self</span>.learning_rate * tf.reduce_mean(h0 - h1, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr"> 54: </span>
<span class="linenr"> 55: </span>        err = tf.reduce_mean(tf.square(v0 - v1))
<span class="linenr"> 56: </span>
<span class="linenr"> 57: </span>        error_list = []
<span class="linenr"> 58: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25209;&#27425;&#20659;&#20837;&#36039;&#26009;&#20006;&#38283;&#22987;&#35347;&#32244;</span>
<span class="linenr"> 59: </span>        <span style="color: #51afef;">with</span> tf.compat.v1.Session() <span style="color: #51afef;">as</span> sess:
<span class="linenr"> 60: </span>            sess.run(tf.compat.v1.global_variables_initializer())
<span class="linenr"> 61: </span>
<span class="linenr"> 62: </span>            <span style="color: #51afef;">for</span> epoch <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #51afef;">self</span>.epochs):
<span class="linenr"> 63: </span>                <span style="color: #51afef;">for</span> start, end <span style="color: #51afef;">in</span> <span style="color: #c678dd;">zip</span>(<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #c678dd;">len</span>(X), \
<span class="linenr"> 64: </span>                        <span style="color: #51afef;">self</span>.batchsize),<span style="color: #c678dd;">range</span>(<span style="color: #51afef;">self</span>.batchsize,<span style="color: #c678dd;">len</span>(X), \
<span class="linenr"> 65: </span>                                              <span style="color: #51afef;">self</span>.batchsize)):
<span class="linenr"> 66: </span>                    batch = X[start:end]
<span class="linenr"> 67: </span>                    cur_w = sess.run(update_w, feed_dict={v0: batch, \
<span class="linenr"> 68: </span>                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr"> 69: </span>                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, \
<span class="linenr"> 70: </span>                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr"> 71: </span>                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, \
<span class="linenr"> 72: </span>                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr"> 73: </span>                    prv_w = cur_w
<span class="linenr"> 74: </span>                    prv_hb = cur_hb
<span class="linenr"> 75: </span>                    prv_vb = cur_vb
<span class="linenr"> 76: </span>                error = sess.run(err, feed_dict={v0: X, \
<span class="linenr"> 77: </span>                                _w: cur_w, _vb: cur_vb, _hb: cur_hb})
<span class="linenr"> 78: </span>                <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">'Epoch: %d'</span> % epoch,<span style="color: #98be65;">'reconstruction error: %f'</span> % error)
<span class="linenr"> 79: </span>                error_list.append(error)
<span class="linenr"> 80: </span>            <span style="color: #51afef;">self</span>.w = prv_w
<span class="linenr"> 81: </span>            <span style="color: #51afef;">self</span>.hb = prv_hb
<span class="linenr"> 82: </span>            <span style="color: #51afef;">self</span>.vb = prv_vb
<span class="linenr"> 83: </span>            <span style="color: #51afef;">return</span> error_list
<span class="linenr"> 84: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992;RBM&#27169;&#22411;&#29986;&#29983;&#24433;&#20687;</span>
<span class="linenr"> 85: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">rbm_output</span>(<span style="color: #51afef;">self</span>, X):
<span class="linenr"> 86: </span>
<span class="linenr"> 87: </span>        input_X = tf.constant(X)
<span class="linenr"> 88: </span>        _w = tf.constant(<span style="color: #51afef;">self</span>.w)
<span class="linenr"> 89: </span>        _hb = tf.constant(<span style="color: #51afef;">self</span>.hb)
<span class="linenr"> 90: </span>        _vb = tf.constant(<span style="color: #51afef;">self</span>.vb)
<span class="linenr"> 91: </span>        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)
<span class="linenr"> 92: </span>        hiddenGen = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_h_given_v(input_X, _w, _hb))
<span class="linenr"> 93: </span>        visibleGen = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_v_given_h(hiddenGen, _w, _vb))
<span class="linenr"> 94: </span>        <span style="color: #51afef;">with</span> tf.compat.v1.Session() <span style="color: #51afef;">as</span> sess:
<span class="linenr"> 95: </span>            sess.run(tf.compat.v1.global_variables_initializer())
<span class="linenr"> 96: </span>            <span style="color: #51afef;">return</span> sess.run(out), sess.run(visibleGen), sess.run(hiddenGen)
<span class="linenr"> 97: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26597;&#30475;&#38577;&#34255;&#23652;&#30340;&#29305;&#24501;</span>
<span class="linenr"> 98: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">show_features</span>(<span style="color: #51afef;">self</span>, shape, suptitle, count=-<span style="color: #da8548; font-weight: bold;">1</span>, fn=<span style="color: #98be65;">''</span>):
<span class="linenr"> 99: </span>        maxw = np.amax(<span style="color: #51afef;">self</span>.w.T)
<span class="linenr">100: </span>        minw = np.amin(<span style="color: #51afef;">self</span>.w.T)
<span class="linenr">101: </span>        count = <span style="color: #51afef;">self</span>._output_size <span style="color: #51afef;">if</span> count == -<span style="color: #da8548; font-weight: bold;">1</span> <span style="color: #51afef;">or</span> count &gt; \
<span class="linenr">102: </span>                <span style="color: #51afef;">self</span>._output_size <span style="color: #51afef;">else</span> count
<span class="linenr">103: </span>        ncols = count <span style="color: #51afef;">if</span> count &lt; <span style="color: #da8548; font-weight: bold;">14</span> <span style="color: #51afef;">else</span> <span style="color: #da8548; font-weight: bold;">14</span>
<span class="linenr">104: </span>        nrows = count//ncols
<span class="linenr">105: </span>        nrows = nrows <span style="color: #51afef;">if</span> nrows &gt; <span style="color: #da8548; font-weight: bold;">2</span> <span style="color: #51afef;">else</span> <span style="color: #da8548; font-weight: bold;">3</span>
<span class="linenr">106: </span>        fig = plt.figure(figsize=(ncols, nrows), dpi=<span style="color: #da8548; font-weight: bold;">100</span>)
<span class="linenr">107: </span>        grid = Grid(fig, rect=<span style="color: #da8548; font-weight: bold;">111</span>, nrows_ncols=(nrows, ncols), axes_pad=<span style="color: #da8548; font-weight: bold;">0.01</span>)
<span class="linenr">108: </span>
<span class="linenr">109: </span>        <span style="color: #51afef;">for</span> i, ax <span style="color: #51afef;">in</span> <span style="color: #c678dd;">enumerate</span>(grid):
<span class="linenr">110: </span>            x = <span style="color: #51afef;">self</span>.w.T[i] <span style="color: #51afef;">if</span> i&lt;<span style="color: #51afef;">self</span>._input_size <span style="color: #51afef;">else</span> np.zeros(shape)
<span class="linenr">111: </span>            x = (x.reshape(<span style="color: #da8548; font-weight: bold;">1</span>, -<span style="color: #da8548; font-weight: bold;">1</span>) - minw)/maxw
<span class="linenr">112: </span>            ax.imshow(x.reshape(*shape), cmap=mpl.cm.Greys)
<span class="linenr">113: </span>            ax.set_axis_off()
<span class="linenr">114: </span>
<span class="linenr">115: </span>        fig.text(<span style="color: #da8548; font-weight: bold;">0.5</span>,<span style="color: #da8548; font-weight: bold;">1</span>, suptitle, fontsize=<span style="color: #da8548; font-weight: bold;">20</span>, horizontalalignment=<span style="color: #98be65;">'center'</span>)
<span class="linenr">116: </span>        fig.tight_layout()
<span class="linenr">117: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show() #&#22914;&#20309;&#20659;&#22238;fig</span>
<span class="linenr">118: </span>        plt.savefig(fn, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">119: </span>        <span style="color: #51afef;">return</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgf8f5ea7" class="outline-3">
<h3 id="orgf8f5ea7"><span class="section-number-3">9.3.</span> 為DBN訓練三個RBMs</h3>
<div class="outline-text-3" id="text-9-3">
<ol class="org-ol">
<li>先將訓練資料存成Numpy陣列</li>
<li>建立一個陣列(rbm_list)來保存所訓練的RMBs</li>
<li>定義三個RBM的超參數(輸入值數量、輸出值數量、學習率、訓練回合數、批次大小)</li>
</ol>
<p>
此模型中：
</p>
<ul class="org-ul">
<li>第一個RBM接收784維的輸入、輸出700維的矩陣</li>
<li>下一個RBM使用前一個RBM輸出的700維矩陣為輸入，輸出一個600維的矩陣</li>
<li>最後一個RBM使用這600維的矩陣當成輸入、輸出一個500維的矩陣</li>
<li>學習率設為1.0</li>
<li>訓練100回合</li>
<li>批次大小設為200</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Since we are training, set input as training data</span>
<span class="linenr"> 2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25343;&#35347;&#32244;&#38598;&#30070;&#25104;&#36664;&#20837;</span>
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 4: </span><span style="color: #dcaeea;">inputX</span> = np.array(X_train)
<span class="linenr"> 5: </span><span style="color: #dcaeea;">inputX</span> = inputX.astype(np.float32)
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create list to hold our RBMs</span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">rbm_list</span> = []
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Define the parameters of the RBMs we will train</span>
<span class="linenr">11: </span>rbm_list.append(RBM(<span style="color: #da8548; font-weight: bold;">784</span>,<span style="color: #da8548; font-weight: bold;">700</span>,<span style="color: #da8548; font-weight: bold;">1.0</span>,<span style="color: #da8548; font-weight: bold;">100</span>,<span style="color: #da8548; font-weight: bold;">200</span>))
<span class="linenr">12: </span>rbm_list.append(RBM(<span style="color: #da8548; font-weight: bold;">700</span>,<span style="color: #da8548; font-weight: bold;">600</span>,<span style="color: #da8548; font-weight: bold;">1.0</span>,<span style="color: #da8548; font-weight: bold;">100</span>,<span style="color: #da8548; font-weight: bold;">200</span>))
<span class="linenr">13: </span>rbm_list.append(RBM(<span style="color: #da8548; font-weight: bold;">600</span>,<span style="color: #da8548; font-weight: bold;">500</span>,<span style="color: #da8548; font-weight: bold;">1.0</span>,<span style="color: #da8548; font-weight: bold;">100</span>,<span style="color: #da8548; font-weight: bold;">200</span>))
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#35347;&#32244;&#36942;&#30340;RBM&#23384;&#22312;outputList</span>
<span class="linenr">15: </span><span style="color: #dcaeea;">outputList</span> = []
<span class="linenr">16: </span><span style="color: #dcaeea;">error_list</span> = []
<span class="linenr">17: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">For each RBM in our list</span>
<span class="linenr">18: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #c678dd;">len</span>(rbm_list)):
<span class="linenr">19: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'RBM'</span>, i+<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">20: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">Train a new one</span>
<span class="linenr">21: </span>    <span style="color: #dcaeea;">rbm</span> = rbm_list[i]
<span class="linenr">22: </span>    <span style="color: #dcaeea;">err</span> = rbm.train(inputX)
<span class="linenr">23: </span>    error_list.append(err)
<span class="linenr">24: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">Return the output layer</span>
<span class="linenr">25: </span>    <span style="color: #dcaeea;">outputX</span>, <span style="color: #dcaeea;">reconstructedX</span>, <span style="color: #dcaeea;">hiddenX</span> = rbm.rbm_output(inputX)
<span class="linenr">26: </span>    outputList.append(outputX)
<span class="linenr">27: </span>    <span style="color: #dcaeea;">inputX</span> = hiddenX
</pre>
</div>

<pre class="example" id="org4848352">
RBM 1
2022-05-14 23:52:49.162587: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-14 23:52:49.164433: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
Epoch: 0 reconstruction error: 0.074801
...
Epoch: 99 reconstruction error: 0.038867
RBM 2
Epoch: 0 reconstruction error: 0.050241
...
Epoch: 99 reconstruction error: 0.018937
RBM 3
Epoch: 0 reconstruction error: 0.038833
...
Epoch: 99 reconstruction error: 0.017987
</pre>
</div>
</div>
<div id="outline-container-orga454f7a" class="outline-3">
<h3 id="orga454f7a"><span class="section-number-3">9.4.</span> 查看RBM誤差</h3>
<div class="outline-text-3" id="text-9-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Plot reconstruction errors</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">i</span> = <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr"> 3: </span><span style="color: #51afef;">for</span> err <span style="color: #51afef;">in</span> error_list:
<span class="linenr"> 4: </span>    plt.clf()
<span class="linenr"> 5: </span>    plt.cla()
<span class="linenr"> 6: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"RBM"</span>,i)
<span class="linenr"> 7: </span>    pd.Series(err).plot(logy=<span style="color: #a9a1e1;">False</span>)
<span class="linenr"> 8: </span>    plt.xlabel(<span style="color: #98be65;">"Epoch"</span>)
<span class="linenr"> 9: </span>    plt.ylabel(<span style="color: #98be65;">"Reconstruction Error"</span>)
<span class="linenr">10: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.ylim(0,1)</span>
<span class="linenr">11: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">12: </span>    plt.savefig(f<span style="color: #98be65;">'images/DBN-DMB-</span>{i}<span style="color: #98be65;">.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">13: </span>    i += <span style="color: #da8548; font-weight: bold;">1</span>
</pre>
</div>

<pre class="example">
RBM 1
RBM 2
RBM 3
</pre>



<div id="org2c6bfd9" class="figure">
<p><img src="images/DBN-DMB-1.png" alt="DBN-DMB-1.png" width="500" />
</p>
<p><span class="figure-number">Figure 28: </span>Caption</p>
</div>

<div id="orgb2d16ed" class="figure">
<p><img src="images/DBN-DMB-2.png" alt="DBN-DMB-2.png" width="500" />
</p>
<p><span class="figure-number">Figure 29: </span>Caption</p>
</div>

<div id="org5666587" class="figure">
<p><img src="images/DBN-DMB-3.png" alt="DBN-DMB-3.png" width="500" />
</p>
<p><span class="figure-number">Figure 30: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-orge685a00" class="outline-3">
<h3 id="orge685a00"><span class="section-number-3">9.5.</span> 檢視特徵偵測器</h3>
<div class="outline-text-3" id="text-9-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Examine Feature Detectors</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">rbm_shapes</span> = [(<span style="color: #da8548; font-weight: bold;">28</span>,<span style="color: #da8548; font-weight: bold;">28</span>),(<span style="color: #da8548; font-weight: bold;">35</span>,<span style="color: #da8548; font-weight: bold;">20</span>),(<span style="color: #da8548; font-weight: bold;">30</span>,<span style="color: #da8548; font-weight: bold;">20</span>)]
<span class="linenr"> 3: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #c678dd;">len</span>(rbm_list)):
<span class="linenr"> 4: </span>    <span style="color: #dcaeea;">rbm</span> = rbm_list[i]
<span class="linenr"> 5: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"RBM"</span>,i)
<span class="linenr"> 6: </span>    <span style="color: #dcaeea;">fn</span> = f<span style="color: #98be65;">'images/DBN-Detect-</span>{i}<span style="color: #98be65;">.png'</span>
<span class="linenr"> 7: </span>    <span style="color: #c678dd;">print</span>(rbm.show_features(rbm_shapes[i], <span style="color: #98be65;">"RBM learned features from MNIST"</span>, <span style="color: #da8548; font-weight: bold;">56</span>, fn))
<span class="linenr"> 8: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">fig = rbm.show_features(rbm_shapes[i])</span>
<span class="linenr"> 9: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.savefig(f'images/DBN-Detect-{i}.png', fig,  dpi=300)</span>
<span class="linenr">10: </span>
</pre>
</div>

<pre class="example">
RBM 0
None
RBM 1
None
RBM 2
None
</pre>



<div id="orgeebb51c" class="figure">
<p><img src="images/DBN-Detect-0.png" alt="DBN-Detect-0.png" width="500" />
</p>
<p><span class="figure-number">Figure 31: </span>Caption</p>
</div>

<div id="orgd8efd67" class="figure">
<p><img src="images/DBN-Detect-1.png" alt="DBN-Detect-1.png" width="500" />
</p>
<p><span class="figure-number">Figure 32: </span>Caption</p>
</div>

<div id="org6b0b03a" class="figure">
<p><img src="images/DBN-Detect-2.png" alt="DBN-Detect-2.png" width="500" />
</p>
<p><span class="figure-number">Figure 33: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-orgf91ea74" class="outline-3">
<h3 id="orgf91ea74"><span class="section-number-3">9.6.</span> 查看RBM生成的影像</h3>
<div class="outline-text-3" id="text-9-6">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">View generated images from the first RBM</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">inputX</span> = np.array(X_train)
<span class="linenr"> 3: </span><span style="color: #dcaeea;">rbmOne</span> = rbm_list[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'RBM 1'</span>)
<span class="linenr"> 6: </span><span style="color: #dcaeea;">outputX_rbmOne</span>, <span style="color: #dcaeea;">reconstructedX_rbmOne</span>, <span style="color: #dcaeea;">hiddenX_rbmOne</span> = \
<span class="linenr"> 7: </span>                            rbmOne.rbm_output(inputX)
<span class="linenr"> 8: </span><span style="color: #dcaeea;">reconstructedX_rbmOne</span> = pd.DataFrame(data=reconstructedX_rbmOne, \
<span class="linenr"> 9: </span>                                     index=X_train.index)
<span class="linenr">10: </span><span style="color: #51afef;">for</span> j <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">10</span>):
<span class="linenr">11: </span>    plt.cla()
<span class="linenr">12: </span>    plt.clf()
<span class="linenr">13: </span>    example = j
<span class="linenr">14: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Image generated by RBM"</span>)
<span class="linenr">15: </span>    fn = f<span style="color: #98be65;">'images/DBN-RBMGenerated-</span>{j}<span style="color: #98be65;">.png'</span>
<span class="linenr">16: </span>    view_digit(reconstructedX_rbmOne, y_train, example, fn)
<span class="linenr">17: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Original image"</span>)
<span class="linenr">18: </span>    fn = f<span style="color: #98be65;">'images/DBN-Original-</span>{j}<span style="color: #98be65;">.png'</span>
<span class="linenr">19: </span>    view_digit(X_train, y_train, example, fn)
</pre>
</div>

<pre class="example" id="org0c9b2b2">
RBM 1
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
</pre>

<div id="org3c9f9f3" class="figure">
<p><img src="images/DBN-Original-9.png" alt="DBN-Original-9.png" width="500" />
</p>
<p><span class="figure-number">Figure 34: </span>Caption</p>
</div>
<p width="300">
<img src="images/DBN-RBMGenerated-9.png" alt="DBN-RBMGenerated-9.png" width="300" />
<img src="images/DBN-Original-8.png" alt="DBN-Original-8.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-8.png" alt="DBN-RBMGenerated-8.png" width="300" />
<img src="images/DBN-Original-7.png" alt="DBN-Original-7.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-7.png" alt="DBN-RBMGenerated-7.png" width="300" />
<img src="images/DBN-Original-6.png" alt="DBN-Original-6.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-6.png" alt="DBN-RBMGenerated-6.png" width="300" />
<img src="images/DBN-Original-5.png" alt="DBN-Original-5.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-5.png" alt="DBN-RBMGenerated-5.png" width="300" />
<img src="images/DBN-Original-4.png" alt="DBN-Original-4.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-4.png" alt="DBN-RBMGenerated-4.png" width="300" />
<img src="images/DBN-Original-3.png" alt="DBN-Original-3.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-3.png" alt="DBN-RBMGenerated-3.png" width="300" />
<img src="images/DBN-Original-2.png" alt="DBN-Original-2.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-2.png" alt="DBN-RBMGenerated-2.png" width="300" />
<img src="images/DBN-Original-1.png" alt="DBN-Original-1.png" />
</p>
<p width="300">
<img src="images/DBN-RBMGenerated-1.png" alt="DBN-RBMGenerated-1.png" width="300" />
<img src="images/DBN-Original-0.png" alt="DBN-Original-0.png" />
</p>

<div id="org965d9ae" class="figure">
<p><img src="images/DBN-RBMGenerated-0.png" alt="DBN-RBMGenerated-0.png" width="300" />
</p>
</div>
</div>
</div>
<div id="outline-container-orgf5f59e5" class="outline-3">
<h3 id="orgf5f59e5"><span class="section-number-3">9.7.</span> 完整的DBN</h3>
<div class="outline-text-3" id="text-9-7">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">  1: </span><span style="color: #51afef;">class</span> <span style="color: #ECBE7B;">DBN</span>(<span style="color: #c678dd;">object</span>):
<span class="linenr">  2: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">__init__</span>(<span style="color: #51afef;">self</span>, original_input_size, input_size, output_size,
<span class="linenr">  3: </span>                 learning_rate, epochs, batchsize, rbmOne, rbmTwo, rbmThree):
<span class="linenr">  4: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Define hyperparameters</span>
<span class="linenr">  5: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">_original_input_size</span> = original_input_size
<span class="linenr">  6: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">_input_size</span> = input_size
<span class="linenr">  7: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">_output_size</span> = output_size
<span class="linenr">  8: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">learning_rate</span> = learning_rate
<span class="linenr">  9: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">epochs</span> = epochs
<span class="linenr"> 10: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">batchsize</span> = batchsize
<span class="linenr"> 11: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">rbmOne</span> = rbmOne
<span class="linenr"> 12: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">rbmTwo</span> = rbmTwo
<span class="linenr"> 13: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">rbmThree</span> = rbmThree
<span class="linenr"> 14: </span>
<span class="linenr"> 15: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">w</span> = np.zeros([input_size, output_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 16: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">hb</span> = np.zeros([output_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 17: </span>        <span style="color: #51afef;">self</span>.<span style="color: #dcaeea;">vb</span> = np.zeros([input_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 18: </span>
<span class="linenr"> 19: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">prob_h_given_v</span>(<span style="color: #51afef;">self</span>, visible, w, hb):
<span class="linenr"> 20: </span>        <span style="color: #51afef;">return</span> tf.nn.sigmoid(tf.matmul(visible, w) + hb)
<span class="linenr"> 21: </span>
<span class="linenr"> 22: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">prob_v_given_h</span>(<span style="color: #51afef;">self</span>, hidden, w, vb):
<span class="linenr"> 23: </span>        <span style="color: #51afef;">return</span> tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)
<span class="linenr"> 24: </span>
<span class="linenr"> 25: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">sample_prob</span>(<span style="color: #51afef;">self</span>, probs):
<span class="linenr"> 26: </span>        <span style="color: #51afef;">return</span> tf.nn.relu(tf.sign(probs - tf.compat.v1.random_uniform(tf.shape(probs))))
<span class="linenr"> 27: </span>
<span class="linenr"> 28: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">train</span>(<span style="color: #51afef;">self</span>, X):
<span class="linenr"> 29: </span>        <span style="color: #dcaeea;">_w</span> = tf.compat.v1.placeholder(<span style="color: #98be65;">"float"</span>, [<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size])
<span class="linenr"> 30: </span>        <span style="color: #dcaeea;">_hb</span> = tf.compat.v1.placeholder(<span style="color: #98be65;">"float"</span>, [<span style="color: #51afef;">self</span>._output_size])
<span class="linenr"> 31: </span>        <span style="color: #dcaeea;">_vb</span> = tf.compat.v1.placeholder(<span style="color: #98be65;">"float"</span>, [<span style="color: #51afef;">self</span>._input_size])
<span class="linenr"> 32: </span>
<span class="linenr"> 33: </span>        <span style="color: #dcaeea;">prv_w</span> = np.zeros([<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 34: </span>        <span style="color: #dcaeea;">prv_hb</span> = np.zeros([<span style="color: #51afef;">self</span>._output_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 35: </span>        <span style="color: #dcaeea;">prv_vb</span> = np.zeros([<span style="color: #51afef;">self</span>._input_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 36: </span>
<span class="linenr"> 37: </span>        <span style="color: #dcaeea;">cur_w</span> = np.zeros([<span style="color: #51afef;">self</span>._input_size, <span style="color: #51afef;">self</span>._output_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 38: </span>        <span style="color: #dcaeea;">cur_hb</span> = np.zeros([<span style="color: #51afef;">self</span>._output_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 39: </span>        <span style="color: #dcaeea;">cur_vb</span> = np.zeros([<span style="color: #51afef;">self</span>._input_size], <span style="color: #98be65;">"float"</span>)
<span class="linenr"> 40: </span>
<span class="linenr"> 41: </span>        <span style="color: #dcaeea;">v0</span> = tf.compat.v1.placeholder(<span style="color: #98be65;">"float"</span>, [<span style="color: #a9a1e1;">None</span>, <span style="color: #51afef;">self</span>._original_input_size])
<span class="linenr"> 42: </span>
<span class="linenr"> 43: </span>        <span style="color: #dcaeea;">forwardOne</span> = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(v0, \
<span class="linenr"> 44: </span>                        <span style="color: #51afef;">self</span>.rbmOne.w) + <span style="color: #51afef;">self</span>.rbmOne.hb) - tf.compat.v1.random_uniform( \
<span class="linenr"> 45: </span>                        tf.shape(tf.nn.sigmoid(tf.matmul(v0, <span style="color: #51afef;">self</span>.rbmOne.w) + \
<span class="linenr"> 46: </span>                        <span style="color: #51afef;">self</span>.rbmOne.hb)))))
<span class="linenr"> 47: </span>        <span style="color: #dcaeea;">forwardTwo</span> = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(forwardOne, \
<span class="linenr"> 48: </span>                        <span style="color: #51afef;">self</span>.rbmTwo.w) + <span style="color: #51afef;">self</span>.rbmTwo.hb) - tf.compat.v1.random_uniform( \
<span class="linenr"> 49: </span>                        tf.shape(tf.nn.sigmoid(tf.matmul(forwardOne, \
<span class="linenr"> 50: </span>                        <span style="color: #51afef;">self</span>.rbmTwo.w) + <span style="color: #51afef;">self</span>.rbmTwo.hb)))))
<span class="linenr"> 51: </span>        <span style="color: #dcaeea;">forward</span> = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(forwardTwo, \
<span class="linenr"> 52: </span>                        <span style="color: #51afef;">self</span>.rbmThree.w) + <span style="color: #51afef;">self</span>.rbmThree.hb) - \
<span class="linenr"> 53: </span>                        tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid(tf.matmul( \
<span class="linenr"> 54: </span>                        forwardTwo, <span style="color: #51afef;">self</span>.rbmThree.w) + <span style="color: #51afef;">self</span>.rbmThree.hb)))))
<span class="linenr"> 55: </span>        <span style="color: #dcaeea;">h0</span> = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_h_given_v(forward, _w, _hb))
<span class="linenr"> 56: </span>        <span style="color: #dcaeea;">v1</span> = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_v_given_h(h0, _w, _vb))
<span class="linenr"> 57: </span>        <span style="color: #dcaeea;">h1</span> = <span style="color: #51afef;">self</span>.prob_h_given_v(v1, _w, _hb)
<span class="linenr"> 58: </span>
<span class="linenr"> 59: </span>        <span style="color: #dcaeea;">positive_grad</span> = tf.matmul(tf.transpose(forward), h0)
<span class="linenr"> 60: </span>        <span style="color: #dcaeea;">negative_grad</span> = tf.matmul(tf.transpose(v1), h1)
<span class="linenr"> 61: </span>
<span class="linenr"> 62: </span>        <span style="color: #dcaeea;">update_w</span> = _w + <span style="color: #51afef;">self</span>.learning_rate * (positive_grad - negative_grad) / \
<span class="linenr"> 63: </span>                        tf.cast(tf.shape(forward)[<span style="color: #da8548; font-weight: bold;">0</span>], tf.float32)
<span class="linenr"> 64: </span>        <span style="color: #dcaeea;">update_vb</span> = _vb +  <span style="color: #51afef;">self</span>.learning_rate * tf.reduce_mean(forward - v1, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr"> 65: </span>        <span style="color: #dcaeea;">update_hb</span> = _hb +  <span style="color: #51afef;">self</span>.learning_rate * tf.reduce_mean(h0 - h1, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr"> 66: </span>
<span class="linenr"> 67: </span>        <span style="color: #dcaeea;">backwardOne</span> = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(v1, \
<span class="linenr"> 68: </span>                            <span style="color: #51afef;">self</span>.rbmThree.w.T) + <span style="color: #51afef;">self</span>.rbmThree.vb) - \
<span class="linenr"> 69: </span>                            tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid( \
<span class="linenr"> 70: </span>                            tf.matmul(v1, <span style="color: #51afef;">self</span>.rbmThree.w.T) + \
<span class="linenr"> 71: </span>                            <span style="color: #51afef;">self</span>.rbmThree.vb)))))
<span class="linenr"> 72: </span>        <span style="color: #dcaeea;">backwardTwo</span> = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(backwardOne, \
<span class="linenr"> 73: </span>                            <span style="color: #51afef;">self</span>.rbmTwo.w.T) + <span style="color: #51afef;">self</span>.rbmTwo.vb) - \
<span class="linenr"> 74: </span>                            tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid( \
<span class="linenr"> 75: </span>                            tf.matmul(backwardOne, <span style="color: #51afef;">self</span>.rbmTwo.w.T) + \
<span class="linenr"> 76: </span>                            <span style="color: #51afef;">self</span>.rbmTwo.vb)))))
<span class="linenr"> 77: </span>        <span style="color: #dcaeea;">backward</span> = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(backwardTwo, \
<span class="linenr"> 78: </span>                            <span style="color: #51afef;">self</span>.rbmOne.w.T) + <span style="color: #51afef;">self</span>.rbmOne.vb) - \
<span class="linenr"> 79: </span>                            tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid( \
<span class="linenr"> 80: </span>                            tf.matmul(backwardTwo, <span style="color: #51afef;">self</span>.rbmOne.w.T) + \
<span class="linenr"> 81: </span>                            <span style="color: #51afef;">self</span>.rbmOne.vb)))))
<span class="linenr"> 82: </span>
<span class="linenr"> 83: </span>        <span style="color: #dcaeea;">err</span> = tf.reduce_mean(tf.square(v0 - backward))
<span class="linenr"> 84: </span>        <span style="color: #dcaeea;">error_list</span> = []
<span class="linenr"> 85: </span>
<span class="linenr"> 86: </span>        <span style="color: #51afef;">with</span> tf.compat.v1.Session() <span style="color: #51afef;">as</span> <span style="color: #dcaeea;">sess</span>:
<span class="linenr"> 87: </span>            sess.run(tf.compat.v1.global_variables_initializer())
<span class="linenr"> 88: </span>
<span class="linenr"> 89: </span>            <span style="color: #51afef;">for</span> epoch <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #51afef;">self</span>.epochs):
<span class="linenr"> 90: </span>                <span style="color: #51afef;">for</span> start, end <span style="color: #51afef;">in</span> <span style="color: #c678dd;">zip</span>(<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #c678dd;">len</span>(X), <span style="color: #51afef;">self</span>.batchsize), \
<span class="linenr"> 91: </span>                        <span style="color: #c678dd;">range</span>(<span style="color: #51afef;">self</span>.batchsize,<span style="color: #c678dd;">len</span>(X), <span style="color: #51afef;">self</span>.batchsize)):
<span class="linenr"> 92: </span>                    batch = X[<span style="color: #dcaeea;">start</span>:end]
<span class="linenr"> 93: </span>                    cur_w = sess.run(update_w, feed_dict={v0: batch, _w: \
<span class="linenr"> 94: </span>                                        prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr"> 95: </span>                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: \
<span class="linenr"> 96: </span>                                        prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr"> 97: </span>                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: \
<span class="linenr"> 98: </span>                                        prv_w, _hb: prv_hb, _vb: prv_vb})
<span class="linenr"> 99: </span>                    prv_w = cur_w
<span class="linenr">100: </span>                    prv_hb = cur_hb
<span class="linenr">101: </span>                    prv_vb = cur_vb
<span class="linenr">102: </span>                error = sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: \
<span class="linenr">103: </span>                                    cur_vb, _hb: cur_hb})
<span class="linenr">104: </span>                <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">'Epoch: %d'</span> % epoch,<span style="color: #98be65;">'reconstruction error: %f'</span> % error)
<span class="linenr">105: </span>                error_list.append(error)
<span class="linenr">106: </span>            <span style="color: #51afef;">self</span>.w = prv_w
<span class="linenr">107: </span>            <span style="color: #51afef;">self</span>.hb = prv_hb
<span class="linenr">108: </span>            <span style="color: #51afef;">self</span>.vb = prv_vb
<span class="linenr">109: </span>            <span style="color: #51afef;">return</span> error_list
<span class="linenr">110: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#24478;DBN&#29986;&#20986;&#29983;&#25104;&#24433;&#20687;&#65292;&#39023;&#31034;&#29305;&#24501;</span>
<span class="linenr">111: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">dbn_output</span>(<span style="color: #51afef;">self</span>, X):
<span class="linenr">112: </span>
<span class="linenr">113: </span>        input_X = tf.constant(X)
<span class="linenr">114: </span>        forwardOne = tf.nn.sigmoid(tf.matmul(input_X, <span style="color: #51afef;">self</span>.rbmOne.w) + \
<span class="linenr">115: </span>                                   <span style="color: #51afef;">self</span>.rbmOne.hb)
<span class="linenr">116: </span>        forwardTwo = tf.nn.sigmoid(tf.matmul(forwardOne, <span style="color: #51afef;">self</span>.rbmTwo.w) + \
<span class="linenr">117: </span>                                   <span style="color: #51afef;">self</span>.rbmTwo.hb)
<span class="linenr">118: </span>        forward = tf.nn.sigmoid(tf.matmul(forwardTwo, <span style="color: #51afef;">self</span>.rbmThree.w) + \
<span class="linenr">119: </span>                                <span style="color: #51afef;">self</span>.rbmThree.hb)
<span class="linenr">120: </span>
<span class="linenr">121: </span>        _w = tf.constant(<span style="color: #51afef;">self</span>.w)
<span class="linenr">122: </span>        _hb = tf.constant(<span style="color: #51afef;">self</span>.hb)
<span class="linenr">123: </span>        _vb = tf.constant(<span style="color: #51afef;">self</span>.vb)
<span class="linenr">124: </span>
<span class="linenr">125: </span>        out = tf.nn.sigmoid(tf.matmul(forward, _w) + _hb)
<span class="linenr">126: </span>        hiddenGen = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_h_given_v(forward, _w, _hb))
<span class="linenr">127: </span>        visibleGen = <span style="color: #51afef;">self</span>.sample_prob(<span style="color: #51afef;">self</span>.prob_v_given_h(hiddenGen, _w, _vb))
<span class="linenr">128: </span>
<span class="linenr">129: </span>        backwardTwo = tf.nn.sigmoid(tf.matmul(visibleGen, <span style="color: #51afef;">self</span>.rbmThree.w.T) + \
<span class="linenr">130: </span>                                    <span style="color: #51afef;">self</span>.rbmThree.vb)
<span class="linenr">131: </span>        backwardOne = tf.nn.sigmoid(tf.matmul(backwardTwo, <span style="color: #51afef;">self</span>.rbmTwo.w.T) + \
<span class="linenr">132: </span>                                    <span style="color: #51afef;">self</span>.rbmTwo.vb)
<span class="linenr">133: </span>        backward = tf.nn.sigmoid(tf.matmul(backwardOne, <span style="color: #51afef;">self</span>.rbmOne.w.T) + \
<span class="linenr">134: </span>                                 <span style="color: #51afef;">self</span>.rbmOne.vb)
<span class="linenr">135: </span>
<span class="linenr">136: </span>        <span style="color: #51afef;">with</span> tf.compat.v1.Session() <span style="color: #51afef;">as</span> sess:
<span class="linenr">137: </span>            sess.run(tf.compat.v1.global_variables_initializer())
<span class="linenr">138: </span>            <span style="color: #51afef;">return</span> sess.run(out), sess.run(backward)
<span class="linenr">139: </span>
<span class="linenr">140: </span>    <span style="color: #51afef;">def</span> <span style="color: #c678dd;">show_features</span>(<span style="color: #51afef;">self</span>, shape, suptitle, count=-<span style="color: #da8548; font-weight: bold;">1</span>, fn=<span style="color: #98be65;">''</span>):
<span class="linenr">141: </span>        plt.cla()
<span class="linenr">142: </span>        maxw = np.amax(<span style="color: #51afef;">self</span>.w.T)
<span class="linenr">143: </span>        minw = np.amin(<span style="color: #51afef;">self</span>.w.T)
<span class="linenr">144: </span>        count = <span style="color: #51afef;">self</span>._output_size <span style="color: #51afef;">if</span> count == -<span style="color: #da8548; font-weight: bold;">1</span> <span style="color: #51afef;">or</span> count &gt; \
<span class="linenr">145: </span>                <span style="color: #51afef;">self</span>._output_size <span style="color: #51afef;">else</span> count
<span class="linenr">146: </span>        ncols = count <span style="color: #51afef;">if</span> count &lt; <span style="color: #da8548; font-weight: bold;">14</span> <span style="color: #51afef;">else</span> <span style="color: #da8548; font-weight: bold;">14</span>
<span class="linenr">147: </span>        nrows = count//ncols
<span class="linenr">148: </span>        nrows = nrows <span style="color: #51afef;">if</span> nrows &gt; <span style="color: #da8548; font-weight: bold;">2</span> <span style="color: #51afef;">else</span> <span style="color: #da8548; font-weight: bold;">3</span>
<span class="linenr">149: </span>        fig = plt.figure(figsize=(ncols, nrows), dpi=<span style="color: #da8548; font-weight: bold;">100</span>)
<span class="linenr">150: </span>        grid = Grid(fig, rect=<span style="color: #da8548; font-weight: bold;">111</span>, nrows_ncols=(nrows, ncols), axes_pad=<span style="color: #da8548; font-weight: bold;">0.01</span>)
<span class="linenr">151: </span>
<span class="linenr">152: </span>        <span style="color: #51afef;">for</span> i, ax <span style="color: #51afef;">in</span> <span style="color: #c678dd;">enumerate</span>(grid):
<span class="linenr">153: </span>            x = <span style="color: #51afef;">self</span>.w.T[i] <span style="color: #51afef;">if</span> i&lt;<span style="color: #51afef;">self</span>._input_size <span style="color: #51afef;">else</span> np.zeros(shape)
<span class="linenr">154: </span>            x = (x.reshape(<span style="color: #da8548; font-weight: bold;">1</span>, -<span style="color: #da8548; font-weight: bold;">1</span>) - minw)/maxw
<span class="linenr">155: </span>            ax.imshow(x.reshape(*shape), cmap=mpl.cm.Greys)
<span class="linenr">156: </span>            ax.set_axis_off()
<span class="linenr">157: </span>
<span class="linenr">158: </span>        fig.text(<span style="color: #da8548; font-weight: bold;">0.5</span>,<span style="color: #da8548; font-weight: bold;">1</span>, suptitle, fontsize=<span style="color: #da8548; font-weight: bold;">20</span>, horizontalalignment=<span style="color: #98be65;">'center'</span>)
<span class="linenr">159: </span>        fig.tight_layout()
<span class="linenr">160: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">161: </span>        plt.savefig(fn, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">162: </span>        <span style="color: #51afef;">return</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgaec32d8" class="outline-3">
<h3 id="orgaec32d8"><span class="section-number-3">9.8.</span> 訓練DBN</h3>
<div class="outline-text-3" id="text-9-8">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Instantiate DBN Class</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">dbn</span> = DBN(<span style="color: #da8548; font-weight: bold;">784</span>, <span style="color: #da8548; font-weight: bold;">500</span>, <span style="color: #da8548; font-weight: bold;">500</span>, <span style="color: #da8548; font-weight: bold;">1.0</span>, <span style="color: #da8548; font-weight: bold;">50</span>, <span style="color: #da8548; font-weight: bold;">200</span>, rbm_list[<span style="color: #da8548; font-weight: bold;">0</span>], rbm_list[<span style="color: #da8548; font-weight: bold;">1</span>], rbm_list[<span style="color: #da8548; font-weight: bold;">2</span>])
<span class="linenr">3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Train</span>
<span class="linenr">4: </span><span style="color: #dcaeea;">inputX</span> = np.array(X_train)
<span class="linenr">5: </span><span style="color: #dcaeea;">error_list</span> = []
<span class="linenr">6: </span><span style="color: #dcaeea;">error_list</span> = dbn.train(inputX)
</pre>
</div>

<pre class="example" id="org7c45bfe">
Epoch: 0 reconstruction error: 0.088701
....
Epoch: 49 reconstruction error: 0.060786
</pre>
</div>
</div>

<div id="outline-container-orgbd1c4ac" class="outline-3">
<h3 id="orgbd1c4ac"><span class="section-number-3">9.9.</span> 看錯誤</h3>
<div class="outline-text-3" id="text-9-9">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Plot reconstruction errors</span>
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"DBN"</span>)
<span class="linenr">3: </span>pd.Series(error_list).plot(logy=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">4: </span>plt.xlabel(<span style="color: #98be65;">"Epoch"</span>)
<span class="linenr">5: </span>plt.ylabel(<span style="color: #98be65;">"Reconstruction Error"</span>)
<span class="linenr">6: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">7: </span>plt.savefig(<span style="color: #98be65;">'images/DBN-learned-MINST.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(dbn.show_features((<span style="color: #da8548; font-weight: bold;">25</span>,<span style="color: #da8548; font-weight: bold;">20</span>),<span style="color: #98be65;">"DBN learned features from MNIST"</span>, <span style="color: #da8548; font-weight: bold;">56</span>, <span style="color: #98be65;">'images/DBN-learned-from-MNIST.png'</span>))
</pre>
</div>

<pre class="example">
DBN
None
</pre>


<div id="orgf78e803" class="figure">
<p><img src="images/DBN-learned-MINST.png" alt="DBN-learned-MINST.png" width="500" />
</p>
<p><span class="figure-number">Figure 35: </span>Caption</p>
</div>

<div id="org75e3719" class="figure">
<p><img src="images/DBN-learned-from-MNIST.png" alt="DBN-learned-from-MNIST.png" width="500" />
</p>
<p><span class="figure-number">Figure 36: </span>Caption</p>
</div>
</div>
</div>

<div id="outline-container-orgcf1a473" class="outline-3">
<h3 id="orgcf1a473"><span class="section-number-3">9.10.</span> 生成影像以建構更好的影像分類器</h3>
<div class="outline-text-3" id="text-9-10">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Generate images and store them</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">inputXReduced</span> = X_train.loc[:<span style="color: #da8548; font-weight: bold;">4999</span>]
<span class="linenr"> 3: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">20</span>):
<span class="linenr"> 4: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Run "</span>,i)
<span class="linenr"> 5: </span>    <span style="color: #dcaeea;">finalOutput_DBN</span>, <span style="color: #dcaeea;">reconstructedOutput_DBN</span> = dbn.dbn_output(inputXReduced)
<span class="linenr"> 6: </span>    <span style="color: #51afef;">if</span> i==<span style="color: #da8548; font-weight: bold;">0</span>:
<span class="linenr"> 7: </span>        generatedImages = finalOutput_DBN
<span class="linenr"> 8: </span>    <span style="color: #51afef;">else</span>:
<span class="linenr"> 9: </span>        generatedImages = np.append(generatedImages, finalOutput_DBN, axis=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Generate a vector of labels for the generated images</span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36941;&#27511;&#35347;&#32244;label y_train&#30340;&#21069;5000&#20491;label 20&#27425;&#65292;&#29992;&#20358;&#29986;&#29983;labels&#38499;&#21015;</span>
<span class="linenr">12: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">20</span>):
<span class="linenr">13: </span>    <span style="color: #51afef;">if</span> i==<span style="color: #da8548; font-weight: bold;">0</span>:
<span class="linenr">14: </span>        labels = y_train.loc[:<span style="color: #da8548; font-weight: bold;">4999</span>]
<span class="linenr">15: </span>    <span style="color: #51afef;">else</span>:
<span class="linenr">16: </span>        labels = np.append(labels,y_train.loc[:<span style="color: #da8548; font-weight: bold;">4999</span>])
<span class="linenr">17: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Generate images based on the validation set</span>
<span class="linenr">18: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29986;&#29983;&#22522;&#26044;&#39511;&#35657;&#38598;&#30340;&#36664;&#20986;&#20540;(&#24433;&#20687;)</span>
<span class="linenr">19: </span>inputValidation = np.array(X_validation)
<span class="linenr">20: </span>finalOutput_DBN_validation, reconstructedOutput_DBN_validation = \
<span class="linenr">21: </span>    dbn.dbn_output(inputValidation)
<span class="linenr">22: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">View first few reconstructed images</span>
<span class="linenr">23: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">10</span>):
<span class="linenr">24: </span>    plt.cla()
<span class="linenr">25: </span>    plt.clf()
<span class="linenr">26: </span>    example = i
<span class="linenr">27: </span>    reconstructedX = pd.DataFrame(data=reconstructedOutput_DBN, \
<span class="linenr">28: </span>                                  index=X_train[<span style="color: #da8548; font-weight: bold;">0</span>:<span style="color: #da8548; font-weight: bold;">5000</span>].index)
<span class="linenr">29: </span>    fn = f<span style="color: #98be65;">'images/reconstructedX-</span>{i}<span style="color: #98be65;">.png'</span>
<span class="linenr">30: </span>    view_digit(reconstructedX, y_train, example, fn)
<span class="linenr">31: </span>    fn = f<span style="color: #98be65;">'images/X0train-</span>{i}<span style="color: #98be65;">.png'</span>
<span class="linenr">32: </span>    view_digit(X_train, y_train, example, fn)
</pre>
</div>

<pre class="example" id="org96db29c">
Run  0
Run  1
Run  2
Run  3
Run  4
Run  5
Run  6
Run  7
Run  8
Run  9
Run  10
Run  11
Run  12
Run  13
Run  14
Run  15
Run  16
Run  17
Run  18
Run  19
</pre>

<div id="org0b8b48d" class="figure">
<p><img src="images/X0train-0.png" alt="X0train-0.png" width="300" />
</p>
<p><span class="figure-number">Figure 37: </span>Run 1</p>
</div>

<div id="org6a4b780" class="figure">
<p><img src="images/reconstructedX-0.png" alt="reconstructedX-0.png" width="300" />
</p>
</div>

<div id="org100465c" class="figure">
<p><img src="images/X0train-1.png" alt="X0train-1.png" width="300" />
</p>
<p><span class="figure-number">Figure 38: </span>Run 2</p>
</div>

<div id="orgea92866" class="figure">
<p><img src="images/reconstructedX-1.png" alt="reconstructedX-1.png" width="300" />
</p>
</div>

<div id="orge346601" class="figure">
<p><img src="images/X0train-2.png" alt="X0train-2.png" width="300" />
</p>
<p><span class="figure-number">Figure 39: </span>Run 3</p>
</div>

<div id="org0590461" class="figure">
<p><img src="images/reconstructedX-2.png" alt="reconstructedX-2.png" width="300" />
</p>
</div>

<div id="org797e43c" class="figure">
<p><img src="images/X0train-3.png" alt="X0train-3.png" width="300" />
</p>
<p><span class="figure-number">Figure 40: </span>Run 4</p>
</div>

<div id="org1cecaeb" class="figure">
<p><img src="images/reconstructedX-3.png" alt="reconstructedX-3.png" width="300" />
</p>
</div>

<div id="org2d7df5e" class="figure">
<p><img src="images/X0train-4.png" alt="X0train-4.png" width="300" />
</p>
<p><span class="figure-number">Figure 41: </span>Run 5</p>
</div>

<div id="org69e6d98" class="figure">
<p><img src="images/reconstructedX-4.png" alt="reconstructedX-4.png" width="300" />
</p>
</div>

<div id="org63b0851" class="figure">
<p><img src="images/X0train-5.png" alt="X0train-5.png" width="300" />
</p>
<p><span class="figure-number">Figure 42: </span>Run 6</p>
</div>

<div id="org3490bde" class="figure">
<p><img src="images/reconstructedX-5.png" alt="reconstructedX-5.png" width="300" />
</p>
</div>

<div id="orgd8dd70c" class="figure">
<p><img src="images/X0train-6.png" alt="X0train-6.png" width="300" />
</p>
<p><span class="figure-number">Figure 43: </span>Run 7</p>
</div>

<div id="org01f0304" class="figure">
<p><img src="images/reconstructedX-6.png" alt="reconstructedX-6.png" width="300" />
</p>
</div>

<div id="org608fe08" class="figure">
<p><img src="images/X0train-7.png" alt="X0train-7.png" width="300" />
</p>
<p><span class="figure-number">Figure 44: </span>Run 8</p>
</div>

<div id="org295dd29" class="figure">
<p><img src="images/reconstructedX-7.png" alt="reconstructedX-7.png" width="300" />
</p>
</div>

<div id="orge04d4e9" class="figure">
<p><img src="images/X0train-8.png" alt="X0train-8.png" width="300" />
</p>
<p><span class="figure-number">Figure 45: </span>Run 9</p>
</div>

<div id="org9c451c6" class="figure">
<p><img src="images/reconstructedX-8.png" alt="reconstructedX-8.png" width="300" />
</p>
</div>

<div id="org19f2626" class="figure">
<p><img src="images/X0train-9.png" alt="X0train-9.png" width="300" />
</p>
<p><span class="figure-number">Figure 46: </span>Run 10</p>
</div>

<div id="orga60b874" class="figure">
<p><img src="images/reconstructedX-9.png" alt="reconstructedX-9.png" width="300" />
</p>
</div>
</div>
</div>
<div id="outline-container-org3b31ea2" class="outline-3">
<h3 id="org3b31ea2"><span class="section-number-3">9.11.</span> 使用DBN來產生新的影像10次</h3>
<div class="outline-text-3" id="text-9-11">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Generate the several versions of the first digit</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">inputXReduced</span> = X_train.loc[:<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr"> 3: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">10</span>):
<span class="linenr"> 4: </span>    <span style="color: #dcaeea;">example</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr"> 5: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Run "</span>,i)
<span class="linenr"> 6: </span>    <span style="color: #dcaeea;">finalOutput_DBN_fives</span>, <span style="color: #dcaeea;">reconstructedOutput_DBN_fives</span> = \
<span class="linenr"> 7: </span>        dbn.dbn_output(inputXReduced)
<span class="linenr"> 8: </span>    <span style="color: #dcaeea;">reconstructedX_fives</span> = pd.DataFrame(data=reconstructedOutput_DBN_fives, \
<span class="linenr"> 9: </span>                                        index=[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">10: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Generated"</span>)
<span class="linenr">11: </span>    fn = f<span style="color: #98be65;">'images/reconstructedX-fives-</span>{i}<span style="color: #98be65;">.png'</span>
<span class="linenr">12: </span>    view_digit(reconstructedX_fives, y_train.loc[:<span style="color: #da8548; font-weight: bold;">0</span>], example, fn)
</pre>
</div>

<pre class="example" id="orgcca685a">
Run  0
Generated
Run  1
Generated
Run  2
Generated
Run  3
Generated
Run  4
Generated
Run  5
Generated
Run  6
Generated
Run  7
Generated
Run  8
Generated
Run  9
Generated
</pre>
</div>
</div>

<div id="outline-container-org180ee27" class="outline-3">
<h3 id="org180ee27"><span class="section-number-3">9.12.</span> 使用LightGBM建構影像分類器</h3>
<div class="outline-text-3" id="text-9-12">
</div>
<div id="outline-container-orgf6f773a" class="outline-4">
<h4 id="orgf6f773a"><span class="section-number-4">9.12.1.</span> 僅使用監督式學習</h4>
<div class="outline-text-4" id="text-9-12-1">
<p>
這裡先用前3000張有label的MNIST影像建立分類器當對照組
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Set Parameters</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">predictionColumns</span> = [<span style="color: #98be65;">'0'</span>,<span style="color: #98be65;">'1'</span>,<span style="color: #98be65;">'2'</span>,<span style="color: #98be65;">'3'</span>,<span style="color: #98be65;">'4'</span>,<span style="color: #98be65;">'5'</span>,<span style="color: #98be65;">'6'</span>,<span style="color: #98be65;">'7'</span>,<span style="color: #98be65;">'8'</span>,<span style="color: #98be65;">'9'</span>]
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #dcaeea;">params_lightGB</span> = {
<span class="linenr"> 5: </span>    <span style="color: #98be65;">'task'</span>: <span style="color: #98be65;">'train'</span>,
<span class="linenr"> 6: </span>    <span style="color: #98be65;">'num_class'</span>:<span style="color: #da8548; font-weight: bold;">10</span>,
<span class="linenr"> 7: </span>    <span style="color: #98be65;">'boosting'</span>: <span style="color: #98be65;">'gbdt'</span>,
<span class="linenr"> 8: </span>    <span style="color: #98be65;">'objective'</span>: <span style="color: #98be65;">'multiclass'</span>,
<span class="linenr"> 9: </span>    <span style="color: #98be65;">'metric'</span>: <span style="color: #98be65;">'multi_logloss'</span>,
<span class="linenr">10: </span>    <span style="color: #98be65;">'metric_freq'</span>:<span style="color: #da8548; font-weight: bold;">50</span>,
<span class="linenr">11: </span>    <span style="color: #98be65;">'is_training_metric'</span>:<span style="color: #a9a1e1;">False</span>,
<span class="linenr">12: </span>    <span style="color: #98be65;">'max_depth'</span>:<span style="color: #da8548; font-weight: bold;">4</span>,
<span class="linenr">13: </span>    <span style="color: #98be65;">'num_leaves'</span>: <span style="color: #da8548; font-weight: bold;">31</span>,
<span class="linenr">14: </span>    <span style="color: #98be65;">'learning_rate'</span>: <span style="color: #da8548; font-weight: bold;">0.1</span>,
<span class="linenr">15: </span>    <span style="color: #98be65;">'feature_fraction'</span>: <span style="color: #da8548; font-weight: bold;">1.0</span>,
<span class="linenr">16: </span>    <span style="color: #98be65;">'bagging_fraction'</span>: <span style="color: #da8548; font-weight: bold;">1.0</span>,
<span class="linenr">17: </span>    <span style="color: #98be65;">'bagging_freq'</span>: <span style="color: #da8548; font-weight: bold;">0</span>,
<span class="linenr">18: </span>    <span style="color: #98be65;">'bagging_seed'</span>: <span style="color: #da8548; font-weight: bold;">2018</span>,
<span class="linenr">19: </span>    <span style="color: #98be65;">'verbose'</span>: -<span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr">20: </span>    <span style="color: #98be65;">'num_threads'</span>:<span style="color: #da8548; font-weight: bold;">16</span>
<span class="linenr">21: </span>}
<span class="linenr">22: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Train</span>
<span class="linenr">23: </span><span style="color: #dcaeea;">trainingScore</span> = []
<span class="linenr">24: </span><span style="color: #dcaeea;">validationScore</span> = []
<span class="linenr">25: </span><span style="color: #dcaeea;">predictionsLightGBM</span> = pd.DataFrame(data=[], \
<span class="linenr">26: </span>                        index=y_validation.index, \
<span class="linenr">27: </span>                        columns=predictionColumns)
<span class="linenr">28: </span>
<span class="linenr">29: </span>lgb_train = lgb.Dataset(X_train.loc[:<span style="color: #da8548; font-weight: bold;">4999</span>], y_train.loc[:<span style="color: #da8548; font-weight: bold;">4999</span>])
<span class="linenr">30: </span>lgb_eval = lgb.Dataset(X_validation, y_validation, reference=lgb_train)
<span class="linenr">31: </span>gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=<span style="color: #da8548; font-weight: bold;">2000</span>,
<span class="linenr">32: </span>                   valid_sets=lgb_eval, early_stopping_rounds=<span style="color: #da8548; font-weight: bold;">200</span>)
<span class="linenr">33: </span>
<span class="linenr">34: </span>loglossTraining = log_loss(y_train.loc[:<span style="color: #da8548; font-weight: bold;">4999</span>], \
<span class="linenr">35: </span>    gbm.predict(X_train.loc[:<span style="color: #da8548; font-weight: bold;">4999</span>], num_iteration=gbm.best_iteration))
<span class="linenr">36: </span>trainingScore.append(loglossTraining)
<span class="linenr">37: </span>
<span class="linenr">38: </span>predictionsLightGBM.loc[X_validation.index,predictionColumns] = \
<span class="linenr">39: </span>    gbm.predict(X_validation, num_iteration=gbm.best_iteration)
<span class="linenr">40: </span>loglossValidation = log_loss(y_validation,
<span class="linenr">41: </span>    predictionsLightGBM.loc[X_validation.index,predictionColumns])
<span class="linenr">42: </span>validationScore.append(loglossValidation)
<span class="linenr">43: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26597;&#30475;&#23565;&#25976;&#25613;&#22833;&#20989;&#25976;&#21644;&#25972;&#39636;&#31934;&#30906;&#29575;</span>
<span class="linenr">44: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Training Log Loss: '</span>, loglossTraining)
<span class="linenr">45: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Validation Log Loss: '</span>, loglossValidation)
<span class="linenr">46: </span>
<span class="linenr">47: </span>loglossLightGBM = log_loss(y_validation, predictionsLightGBM)
<span class="linenr">48: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'LightGBM Gradient Boosting Log Loss: '</span>, loglossLightGBM)
<span class="linenr">49: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Supervised-only Accuracy</span>
<span class="linenr">50: </span>predictionsLightGBM_firm = np.argmax(np.array(predictionsLightGBM), axis=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">51: </span>accuracyValidation_lightGBM = accuracy_score(np.array(y_validation), \
<span class="linenr">52: </span>                                            predictionsLightGBM_firm)
<span class="linenr">53: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Supervised-Only Accuracy: "</span>, accuracyValidation_lightGBM)
</pre>
</div>

<pre class="example" id="org6e4c59f">
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
[1]	valid_0's multi_logloss: 1.8355
Training until validation scores don't improve for 200 rounds
[2]	valid_0's multi_logloss: 1.5523
...
[335]	valid_0's multi_logloss: 0.221976
Early stopping, best iteration is:
[135]	valid_0's multi_logloss: 0.192358
Training Log Loss:  0.0006489700296153399
Validation Log Loss:  0.19235843980200165
LightGBM Gradient Boosting Log Loss:  0.19235843980200165
Supervised-Only Accuracy:  0.9446
</pre>
</div>
</div>

<div id="outline-container-org79af1fa" class="outline-4">
<h4 id="org79af1fa"><span class="section-number-4">9.12.2.</span> 監督式與非監督式學習並用</h4>
<div class="outline-text-4" id="text-9-12-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Prepare DBN-based DataFrames for LightGBM use</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">generatedImagesDF</span> = pd.DataFrame(data=generatedImages,index=<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">100000</span>))
<span class="linenr"> 3: </span>labelsDF = pd.DataFrame(data=labels,index=<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">100000</span>))
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span>X_train_lgb = pd.DataFrame(data=generatedImagesDF,
<span class="linenr"> 6: </span>                           index=generatedImagesDF.index)
<span class="linenr"> 7: </span>X_validation_lgb = pd.DataFrame(data=finalOutput_DBN_validation,
<span class="linenr"> 8: </span>                                index=X_validation.index)
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Train LightGBM</span>
<span class="linenr">10: </span>trainingScore = []
<span class="linenr">11: </span>validationScore = []
<span class="linenr">12: </span>predictionsDBN = pd.DataFrame(data=[],index=y_validation.index,
<span class="linenr">13: </span>                              columns=predictionColumns)
<span class="linenr">14: </span>
<span class="linenr">15: </span>lgb_train = lgb.Dataset(X_train_lgb, labels)
<span class="linenr">16: </span>lgb_eval = lgb.Dataset(X_validation_lgb, y_validation, reference=lgb_train)
<span class="linenr">17: </span>gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=<span style="color: #da8548; font-weight: bold;">2000</span>,
<span class="linenr">18: </span>                   valid_sets=lgb_eval, early_stopping_rounds=<span style="color: #da8548; font-weight: bold;">200</span>)
<span class="linenr">19: </span>
<span class="linenr">20: </span>loglossTraining = log_loss(labelsDF, gbm.predict(X_train_lgb, \
<span class="linenr">21: </span>                            num_iteration=gbm.best_iteration))
<span class="linenr">22: </span>trainingScore.append(loglossTraining)
<span class="linenr">23: </span>
<span class="linenr">24: </span>predictionsDBN.loc[X_validation.index,predictionColumns] = \
<span class="linenr">25: </span>    gbm.predict(X_validation_lgb, num_iteration=gbm.best_iteration)
<span class="linenr">26: </span>loglossValidation = log_loss(y_validation,
<span class="linenr">27: </span>    predictionsDBN.loc[X_validation.index,predictionColumns])
<span class="linenr">28: </span>validationScore.append(loglossValidation)
<span class="linenr">29: </span>
<span class="linenr">30: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Training Log Loss: '</span>, loglossTraining)
<span class="linenr">31: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Validation Log Loss: '</span>, loglossValidation)
<span class="linenr">32: </span>
<span class="linenr">33: </span>loglossDBN = log_loss(y_validation, predictionsDBN)
<span class="linenr">34: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'LightGBM Gradient Boosting Log Loss: '</span>, loglossDBN)
<span class="linenr">35: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">DBN-Based Solution Accuracy</span>
<span class="linenr">36: </span>predictionsDBN_firm = np.argmax(np.array(predictionsDBN), axis=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">37: </span>accuracyValidation_DBN = accuracy_score(np.array(y_validation), \
<span class="linenr">38: </span>                                        predictionsDBN_firm)
<span class="linenr">39: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"DBN-Based Solution Accuracy: "</span>, accuracyValidation_DBN)
</pre>
</div>

<pre class="example" id="orgb75186f">
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
[1]	valid_0's multi_logloss: 1.66314
Training until validation scores don't improve for 200 rounds
[2]	valid_0's multi_logloss: 1.35732
...
[260]	valid_0's multi_logloss: 0.226954
[261]	valid_0's multi_logloss: 0.227106
[262]	valid_0's multi_logloss: 0.227215
[263]	valid_0's multi_logloss: 0.227329
[264]	valid_0's multi_logloss: 0.227494
Early stopping, best iteration is:
[64]	valid_0's multi_logloss: 0.155201
Training Log Loss:  0.003464589940206874
Validation Log Loss:  0.15520095263526515
LightGBM Gradient Boosting Log Loss:  0.15520095263526515
DBN-Based Solution Accuracy:  0.9561
</pre>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Hands-On Machine Learning with Scikit-Learn: Aurelien Geron
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://towardsai.net/p/programming/decision-trees-explained-with-a-practical-example-fe47872d3b53">Decision Trees Explained With a Practical Example</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2022-07-02 Sat 20:49</p>
</div>
</body>
</html>
