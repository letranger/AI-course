<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-07-03 Sun 20:11 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Machine Learning</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/white.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Machine Learning</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org15422aa">1. 機器學習</a>
<ul>
<li><a href="#orged4e0bf">1.1. 簡介</a></li>
<li><a href="#org6ff2a65">1.2. 何謂機器學習</a></li>
</ul>
</li>
<li><a href="#org47b0ac3">2. 機器學習概念釐清</a>
<ul>
<li><a href="#orgbfd2332">2.1. Machine Learning v.s. Statistics</a></li>
<li><a href="#org50f113d">2.2. Machine Learning v.s. Traditional Programming</a></li>
<li><a href="#orgcf17320">2.3. Training Phase v.s. Inference Phase</a></li>
</ul>
</li>
<li><a href="#orgdfd08f3">3. 典型的機器學習MODEL Training</a>
<ul>
<li><a href="#org4dbc4aa">3.1. Process of learning</a></li>
<li><a href="#org3918a0d">3.2. Example of training</a></li>
<li><a href="#orgaa82f1b">3.3. Model v.s. Layer: Training step by step</a></li>
<li><a href="#orgf3e9cd8">3.4. compile v.s. fit</a></li>
</ul>
</li>
<li><a href="#orge0e7d51">4. 機器學習如何解決問題</a>
<ul>
<li><a href="#org06b95b8">4.1. 使用機器學習處理問題的幾個步驟：</a></li>
<li><a href="#org7073669">4.2. 現實生活中的應用</a></li>
</ul>
</li>
<li><a href="#org93fe83e">5. 機器學習的類型</a>
<ul>
<li><a href="#orgd38d63c">5.1. 監督式學習(Supervised learning)</a></li>
<li><a href="#orgebc8e98">5.2. 非監督式學習(Unsupervised learning)</a></li>
<li><a href="#orge47dba9">5.3. 強化學習(Reinforcement learning)</a></li>
<li><a href="#org712b5aa">5.4. 自監督式學習(Self-supervised learning)</a></li>
<li><a href="#org7de209e">5.5. 深度學習 v.s.強化學習</a></li>
<li><a href="#org72eeb7b">5.6. Batch and Online Learning</a></li>
<li><a href="#org2c71afd">5.7. Instance-Based Versus model-Based Learning</a></li>
</ul>
</li>
<li><a href="#org1b1e555">6. Data Representations</a>
<ul>
<li><a href="#orgfca56e5">6.1. Images</a></li>
<li><a href="#org56d9abc">6.2. Words and Documents</a></li>
<li><a href="#org10fa79f">6.3. Yes/No or Ratings</a></li>
<li><a href="#org066bff0">6.4. One-Hot Encodings</a></li>
</ul>
</li>
<li><a href="#org0d11844">7. 機器學習的主要挑戰</a>
<ul>
<li><a href="#org58a7619">7.1. Insufficient quantity of training data</a></li>
<li><a href="#orgf08f8fc">7.2. Nonrepresentative training data</a></li>
<li><a href="#orgc19f64b">7.3. Poor-quality data</a></li>
<li><a href="#org54546d6">7.4. Irrelevant features</a></li>
<li><a href="#orgb1a990c">7.5. Overfitting the training data</a></li>
<li><a href="#org753bf9a">7.6. Underfitting the training data</a></li>
</ul>
</li>
<li><a href="#orgb7d330f">8. Machine Learning 的基本類型</a>
<ul>
<li><a href="#orged13efe">8.1. Nonlinear Models 非線性模型</a></li>
<li><a href="#org0eed2a3">8.2. Reinforcement Learning</a></li>
</ul>
</li>
<li><a href="#org4553425">9. Classfication</a>
<ul>
<li><a href="#org06b4329">9.1. Model construction: describing a set of predetermined classes</a></li>
<li><a href="#org06589c9">9.2. Model usage: for classifying future or unknown objects</a></li>
</ul>
</li>
<li><a href="#orgb785fba">10. 學習資源</a>
<ul>
<li><a href="#org94fcb42">10.1. Machine Learning [台大李宏毅]</a></li>
<li><a href="#orgad84254">10.2. Digital Speech Processing</a></li>
</ul>
</li>
<li><a href="#orga73dd2a">11. code references</a></li>
</ul>
</div>
</div>

<div id="outline-container-org15422aa" class="outline-2">
<h2 id="org15422aa"><span class="section-number-2">1.</span> 機器學習</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-orged4e0bf" class="outline-3">
<h3 id="orged4e0bf"><span class="section-number-3">1.1.</span> 簡介</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>機器學習是<a href="AI-Introduction.html">人工智慧</a>的一個分支。<a href="AI-Introduction.html">人工智慧</a>的研究歷史有著一條從以「推理」為重點，到以「知識」為重點，再到以 「學習」為重點的自然、清晰的脈絡。<br /></li>
<li>機器學習是實現<a href="AI-Introduction.html">人工智慧</a>的一個途徑，即以機器學習為手段解決<a href="AI-Introduction.html">人工智慧</a>中的問題。<br /></li>
<li>機器學習理論主要是設計和分析一些讓電腦可以自動「學習」 的演算法。機器學習演算法是一類從資料中自動分析獲得規 律，並利用規律對未知資料進行預測的演算法。<br /></li>
<li>機器學習已廣泛應用於資料探勘、電腦視覺、自然語言處理、<br /></li>
<li>生物特徵辨識、搜尋引擎、醫學診斷、檢測信用卡欺詐、證券市場分析、DNA 序列測序、語音和手寫辨識、戰略遊戲和機器人等領域<br /></li>
<li>機器學習是一門<a href="AI-Introduction.html">人工智慧</a>的科學，該領域的主要研究物件是<a href="AI-Introduction.html">人工智慧</a>，特別是如何=在經驗學習中=改善具體演算法的效能。<br /></li>
<li>機器學習是對能通過經驗=自動改進=的電腦演算法研究<br /></li>
<li>機器學習是用資料或以往的經驗，以此最佳化電 腦程式的效能標準。<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org6ff2a65" class="outline-3">
<h3 id="org6ff2a65"><span class="section-number-3">1.2.</span> 何謂機器學習</h3>
<div class="outline-text-3" id="text-1-2">
<p>
機器學習的定義之一：一個可以與其環境做互動的系統。具有感知器(sensor)，可以讓機器了解它們所處的環境，以及它們也具有相關的工具可以讓機器做出回應<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>。<br />
機器學習可以大致分為三類：監督式學習、非監督式學習、強化學習，如圖<a href="#org5f5425a">1</a><sup><a id="fnr.1.100" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>。<br />
</p>

<div id="org5f5425a" class="figure">
<p><img src="images/DifferentLearningTypes.png" alt="DifferentLearningTypes.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 1: </span>三種不同的機器學習</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org47b0ac3" class="outline-2">
<h2 id="org47b0ac3"><span class="section-number-2">2.</span> 機器學習概念釐清</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orgbfd2332" class="outline-3">
<h3 id="orgbfd2332"><span class="section-number-3">2.1.</span> Machine Learning v.s. Statistics</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>統計: 目的在由樣本(sample)找出真相(universe)，如，由台灣 2350 萬人口中，只選出 1000 人，得知全台生活型態、政治傾向。<br /></li>
<li>Machine learning: 目的在讓電腦由歷史資料中學習處理新的資料以解決問題。如，由醫生判讀 X 光片的資料學習判讀新的 X 光片；由一個人的刷卡及繳費行為預測他的信貸是否能準時還款？<br /></li>
<li>Machine learning 不在意真實資料的分佈，而在於根據已知推測未知。<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org50f113d" class="outline-3">
<h3 id="org50f113d"><span class="section-number-3">2.2.</span> Machine Learning v.s. Traditional Programming</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li>傳統的程式設計pattern是將資料及規則餵給程式，經由程式判斷(if-else)產生答案<br /></li>
<li>Meachine learning是將資料(features)和答案(label)餵給model，然後由model學習出規則<br /></li>
</ul>

<div id="org10d324c" class="figure">
<p><img src="images/MLTP.png" alt="MLTP.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 2: </span>Traditional Programming v.s. Machine Learning</p>
</div>
</div>
</div>

<div id="outline-container-orgcf17320" class="outline-3">
<h3 id="orgcf17320"><span class="section-number-3">2.3.</span> Training Phase v.s. Inference Phase</h3>
<div class="outline-text-3" id="text-2-3">

<div id="org7565f2c" class="figure">
<p><img src="images/TPIP.png" alt="TPIP.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 3: </span>Training and Inference Phase of ML</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgdfd08f3" class="outline-2">
<h2 id="orgdfd08f3"><span class="section-number-2">3.</span> 典型的機器學習MODEL Training</h2>
<div class="outline-text-2" id="text-3">
<p>
以&ldquo;rock, paper, and scissors&rdquo;辨識為例<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>:<br />
</p>
<ol class="org-ol">
<li>將三種圖案的image讀入model中<br /></li>
<li>於model中建立神經元(可視為function)，學習不同image的特徵<br /></li>
<li>根據上述神經元讀取的特徵值(features)，配合該image之答案(label)，進行學習<br /></li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">model</span> = tf.keras.models.Sequence([
<span class="linenr">2: </span>    tf.keras.layers.Flatten(input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>)),
<span class="linenr">3: </span>    tf.keras.layers.Dense(<span style="color: #da8548; font-weight: bold;">512</span>, activation=<span style="color: #98be65;">'relu),</span>
<span class="linenr">4: </span><span style="color: #98be65;">    tf.keras.layers.Dense(3, activatio='</span>softmax<span style="color: #98be65;">')</span>
<span class="linenr">5: </span><span style="color: #98be65;">])</span>
<span class="linenr">6: </span>
<span class="linenr">7: </span><span style="color: #98be65;">model.compile(loss='</span>categorical_crossentropy<span style="color: #98be65;">', optimizer='</span>rmsprop<span style="color: #98be65;">')</span>
<span class="linenr">8: </span>
<span class="linenr">9: </span><span style="color: #98be65;">model.fit(...., epochs=100)</span>
</pre>
</div>
</div>
<div id="outline-container-org4dbc4aa" class="outline-3">
<h3 id="org4dbc4aa"><span class="section-number-3">3.1.</span> Process of learning</h3>
<div class="outline-text-3" id="text-3-1">
<p>
可先將512個神經元視為512個function，每個function裡有許多變數，這些變數的初始值為random assign，接下來每個function陸續讀取image的所有feature(即圖的每個pixel，這裡可以將之視為傳入該function的parameters)，然後根據function中的變數值，開始學習要如何調整function裡的變數值才能輸出這個image的正確答案(label)，每個神經元同時進行學習與變數值調校。<br />
</p>
</div>
<ol class="org-ol">
<li><a id="org81bba9f"></a>function 示意圖<br />
<div class="outline-text-4" id="text-3-1-1">

<div id="orgf9b13da" class="figure">
<p><img src="images/function-dg.png" alt="function-dg.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 4: </span>Function</p>
</div>

<p>
在訓練的過程中，我們根據每個function所輸入的參數(parameters)，調整function裡的變數值(這些最初是random得來的)，希望能得到與該輸入值(所有的parameters)所相對應的答案。<br />
</p>

<p>
在傳統的程式設計觀點，輸入function的數值為參數；但在神經網路的觀點，輸入值為features，function稱為neuron，neuron裡的變數稱為parameters，所有neuron裡的parameter均為神經網路訓練過程中要調整的對象。<br />
</p>

<div id="orgdfe21b0" class="figure">
<p><img src="images/neuron-dg.png" alt="neuron-dg.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 5: </span>Neuron</p>
</div>
</div>
</li>
</ol>
</div>
<div id="outline-container-org3918a0d" class="outline-3">
<h3 id="org3918a0d"><span class="section-number-3">3.2.</span> Example of training</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li><p>
輸入image為rock<br />
</p>

<div id="orgbb17376" class="figure">
<p><img src="images/stone.jpg" alt="stone.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 6: </span>Stone</p>
</div></li>
<li><p>
輸入image為paper<br />
</p>

<div id="orgad1f865" class="figure">
<p><img src="images/paper.jpg" alt="paper.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 7: </span>Paper</p>
</div></li>
</ul>

<p>
接下來，<br />
</p>
</div>
</div>
<div id="outline-container-orgaa82f1b" class="outline-3">
<h3 id="orgaa82f1b"><span class="section-number-3">3.3.</span> Model v.s. Layer: Training step by step</h3>
<div class="outline-text-3" id="text-3-3">
<ul class="org-ul">
<li><p>
Input layer<br />
此的輸入為image，對model來說，其feature為150*150*3<br />
</p>

<div id="orge78ec33" class="figure">
<p><img src="images/input_shape.jpg" alt="input_shape.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 8: </span>input_shape</p>
</div></li>
<li><p>
Hidden layer<br />
中間層(hidden layer)有512個神經元，可視為512個function<br />
</p>

<div id="org6c77563" class="figure">
<p><img src="images/hidden_layer.jpg" alt="hidden_layer.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 9: </span>hidden_layer</p>
</div></li>
<li><p>
Output layer<br />
輸出層(output layer)則輸出三種可能的答案<br />
</p>

<div id="org615e80b" class="figure">
<p><img src="images/output_layer.jpg" alt="output_layer.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 10: </span>output_layer</p>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgf3e9cd8" class="outline-3">
<h3 id="orgf3e9cd8"><span class="section-number-3">3.4.</span> compile v.s. fit</h3>
<div class="outline-text-3" id="text-3-4">
<ul class="org-ul">
<li>compile: Compile與傳統程式設計概念不同，此處旨在訂定兩個model training中最重要的關鍵: loss function與optimizer。剛才提及每個function(或neuron)都對於產生答案(label)做出了貢獻，然而這個答案到底好或不好，必須要有一個評估機制，loss function的目的就在評估每一次所有neuron所產生的答案是否足夠好(以此例來看至少正確率必須高過1/3)，然後把評估結果丟給optimizer，由它來決定下一次猜測時neuron裡的parameters要如何調整。<br /></li>
<li>fit: 如此重複不斷的進行&ldquo;輸入feature-&gt;猜測答案-&gt;評估答案-&gt;修正parameter-&gt;輸入features-&gt;猜測答案-&gt;評估答案-&gt;修正parameter&#x2026;.&rdquo;，希望最終能找到各neuron中最佳的parameters值，每一次的訓練稱為一次epoch。這就是fit在做的事，也是實際訓練的動作，訓練所需時間視輸入值、model複雜程度與硬體效能而定，也許僅需數分鐘，也許要耗時數週。<br /></li>
</ul>

<div id="orga59a39d" class="figure">
<p><img src="images/compile_phase.jpg" alt="compile_phase.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 11: </span>compile-phase</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orge0e7d51" class="outline-2">
<h2 id="orge0e7d51"><span class="section-number-2">4.</span> 機器學習如何解決問題</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org06b95b8" class="outline-3">
<h3 id="org06b95b8"><span class="section-number-3">4.1.</span> 使用機器學習處理問題的幾個步驟：</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>數據收集(Data Collection): 在監督式學習下還要蒐集正確的標記<br /></li>
<li>數據處理(Data Processing): 包含「數據清理」，例如：刪除「冗餘」或「高度相關的特徵」，或補滿「遺漏值」。<br /></li>
<li>建立測試案例(Creation of the test case): 通常包括：「訓練數據集」(training dataset)用來訓練演算法、「測試數據集」(test dataset)用來測試訓練完成的演算法、以及「驗證數據集」(validation dataset)用來進行最終測試(在不斷的訓練-測試之後)。<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org7073669" class="outline-3">
<h3 id="org7073669"><span class="section-number-3">4.2.</span> 現實生活中的應用</h3>
<div class="outline-text-3" id="text-4-2">
<p>
近年來的機器學習範例：<br />
</p>
<ul class="org-ul">
<li>AlphaGo: 基於深度學習所製作的「<a href="AI-Introduction.html">人工智慧</a>機」，在 2016 年擊敗世界圍棋冠軍 Lee Sedol。AlphaGo 的優勢在於這個程式並不是專門開發來下圍棋的，而是運用「強化學習」與「深度學習」，透過下了數以千計次的圍棋，學習到如何下圍棋。<br /></li>
<li>澳大利亞：2015 年舉辦一場「預測西澳大利亞租屋價錢」的比賽<br /></li>
<li>2009 年 Netflix 推出一項總奬金 100 萬美元的競賽，用來改進預測使用者喜愛影片的正確性<br /></li>
<li>AlhpaGo Zero: 2017 年 10 月 19 日，AlphaGo 團隊在《自然》上發表文章介紹了 AlphaGo Zero，文中指出此版本不採用人類玩家的棋譜，且比之前的所有版本都要強大。透過自我對弈，AlphaGo Zero 在三天內以 100 比 0 的戰績戰勝了 AlphaGo Lee，花了 21 天達到 AlphaGo Master 的水平，用 40 天超越了所有舊版本。DeepMind 聯合創始人兼 CEO 傑米斯·哈薩比斯說，AlphaGo Zero「不再受限於人類認知」，很強大。由於專家數據「經常很貴、不可靠或是無法取得」，不藉助人類專家的數據集訓練<a href="AI-Introduction.html">人工智慧</a>，對於<a href="AI-Introduction.html">人工智慧</a>開發超人技能具有重大意義[4]，因為這樣的 AI 不是學習人，是透過對自我的反思和獨有的創造力直接超越人類<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>。<br /></li>
<li>繼 AlphaGo 後，同一團隊(DeepMind)繼續打造出 AlphaZero，不再依賴人類棋士的知識與棋譜，只給遊戲規則。在 34 小時的訓練後（約自我訓練 2100 萬局[1]:Table S3），AlphaZero 以 60 勝 40 敗的成績打敗 AlphaGo Zero<sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup>。<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org93fe83e" class="outline-2">
<h2 id="org93fe83e"><span class="section-number-2">5.</span> 機器學習的類型</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgd38d63c" class="outline-3">
<h3 id="orgd38d63c"><span class="section-number-3">5.1.</span> 監督式學習(Supervised learning)</h3>
<div class="outline-text-3" id="text-5-1">
<ul class="org-ul">
<li>目前九成以上的機器學習應用均屬此類<br /></li>
<li>監督式學習指在訓練過程中直接告訴機器答案，也就是將資料進行標註(label)，例如，在 1000 張訓練集照片中標註「貓/狗」。<br /></li>
<li>從給定的訓練資料集中學習出一個函式，當新的資料到來時，可以根據這個函式預測結果。<br /></li>
<li>監督學習的訓練集要求是包括輸入和輸出， 也可以說是特徵和目標。 訓練集中的目標是由人標註的。<br /></li>
<li>為迄今為止最常見的機器學習，泛指一群的機器學習演算法，是從一組「已標記」的「訓練數據集」(training dataset)來學習(訓練)，並導出模型。然後，以此一模型對「未標記」的類似數據進行預測分類，其運作流程如圖<a href="#org359f2b8">12</a><sup><a id="fnr.1.100" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>所示。典型的例子為早期電子郵件的垃圾信件是讓使用者先去標記某些信為垃圾郵件，然後藉由這些被標記的郵件來推論找出其他可能的垃圾郵件；由此看來，我們以為 Gmail 很好心的提供給我們為信件加註「垃圾」、「廣告」的功能，其實是 Google 利用我們當免費勞工為他們提供信件加註標籤的工作。<br /></li>
</ul>

<div id="org359f2b8" class="figure">
<p><img src="images/FlowChartOfSupervisedLearning.png" alt="FlowChartOfSupervisedLearning.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 12: </span>監督式學習流程圖</p>
</div>
</div>
<ol class="org-ol">
<li><a id="orgd14af64"></a>典型應用<br />
<div class="outline-text-4" id="text-5-1-1">
<ul class="org-ul">
<li>Credit/loan approval:信用評比與貸款通過<br /></li>
<li>Medical diagnosis: if a tumor is cancerous or benign(是否有 XX 癌症)<br /></li>
<li>Fraud detection: if a transaction is fraudulent 詐騙或正常交易<br /></li>
<li>垃圾郵件(SPAM)或正常郵件<br /></li>
<li>Web page categorization 網站分類: which category it is<br /></li>
<li>資安應用: 取得有漏洞程式碼資料集(label)，評估其他程式是否有漏洞<br /></li>
</ul>
</div>
</li>
<li><a id="orgf6078e2"></a>範例：<br />
<div class="outline-text-4" id="text-5-1-2">
<ul class="org-ul">
<li>分類：基於從訓練集資料觀測到的分類類別來標籤、預測新數據的類別，如上述的垃圾郵件即為典型的二元分類工作(如圖<a href="#org5b7dc1f">13</a>)，類別分類工作也可以進行「多類別分類」(multi-class classification)，如典型的 MNist 手寫數字辨識，即是將手寫的 0-9 數字進行預測辨識，並給出一個 0-9 的類別標籤。<br /></li>
</ul>

<div id="org5b7dc1f" class="figure">
<p><img src="images/01_03.png" alt="01_03.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 13: </span>典型的分類</p>
</div>
<ul class="org-ul">
<li>線性迴歸: 利用輸入數據的「特徵」來預測出一個「值」，例如，根據房屋的地點、坪數、樓層、房間數等變數, 發掘出這些變數之間的關係，進而預測房價，如圖<a href="#orga4168c3">14</a>。<br /></li>
</ul>

<div id="orga4168c3" class="figure">
<p><img src="images/01_04.png" alt="01_04.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 14: </span>典型的迴歸</p>
</div>
<ul class="org-ul">
<li>決策樹: 精典例子為「鳶尾花數據集」(<a href="http://archive.ics.uci.deu/ml/datasets/Iris">http://archive.ics.uci.deu/ml/datasets/Iris</a>)。<br /></li>
<li>支援向量機: 主要用來處理分類問題，它不僅能將數據分門別類，甚至遇可以找到最大化的「分離超平面」（類似於三維以上空間中的一個平面），會最大化每個樣本點與該「超平面」的差。此外，當數據是「不可線性分離」時，支援向量機還可以透過「軟邊界」(soft margin)和「核技巧」(kernel trick)來處理。<br /></li>
</ul>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgebc8e98" class="outline-3">
<h3 id="orgebc8e98"><span class="section-number-3">5.2.</span> 非監督式學習(Unsupervised learning)</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>非監親式學習只有觀測值，單純給電腦大量觀測資料，然後從這些資料找出潛在規則。例如：將 10 萬張片依據電腦自己歸納的規則分為數個不同的群組。<br /></li>
<li>在「監督式學習」中，我們事先會知道訓練集數據的正確答案(label)，並依此訓練我們的模型；在強化學習的環境中，我們會為代理人定義如何度量特定行動的奬勵；然而，在「非監督式學習」的環境中，我們面對的是未標記類別的數據或未知結構的數據。而是讓演算法導出結論。最典型的例子就是「集群」(clustering)，即，讓演算法自己根據數據的特性把它們依某種特質分類為不同子集合，這裡的子集合不一定要是有限集合，也可能是無界子集(unbounded subsets)。「受限玻爾茲曼機」以及「深度信念網路」(deep belief networks, DBN)都屬此類。<br /></li>
<li>非監督式學習經常被運用於資料分析的前置階段，用來先將資料分群或降低維度(減少變數量)，以利後續的分析或監督式學習的進行。<br /></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org9db141b"></a>範例：<br />
<div class="outline-text-4" id="text-5-2-1">
<ul class="org-ul">
<li>集群(cluster): 是一種「探索式數據分析」(exploratory data analysis)技術，它允許我們先組織一堆資訊到一個有意義的「子集群」(clusters)中，而無需任何先驗知識。<br /></li>
<li>Cluster analysis (or clustering, data segmentation, &#x2026;): Finding similarities between data according to the characteristics found in the data and grouping similar data objects into clusters<br /></li>
<li>K-means: 將數據集中的每個樣本分類到 k 個不同的子集合中，它隨機選擇 k 個點，這些點稱為「質心」(centroid)，代表這 k 個不同子集合的中心點，然後對於每個「質心」，我們選擇最接近它的一點，群組起來&#x2026;..。<br /></li>
<li>生成對抗網路(GAN)<br /></li>
<li>資料沒有答案(如解讀古文)<br /></li>
<li>Principal Component Analysis 主成份分析<br /></li>
</ul>
</div>
</li>
<li><a id="org4212ee9"></a>非監督式學習分群的原理<br />
<ol class="org-ol">
<li><a id="orgade3e97"></a>Linear projection<br />
<div class="outline-text-5" id="text-5-2-2-1">
<ul class="org-ul">
<li>PCA: Principal component analysis，用來識別整個feature set中哪些特徵最為重要，且最能解釋資料實例間的可變性。<br />
<ul class="org-ul">
<li>standard PCA<br /></li>
<li>incremental PCA<br /></li>
<li>sparse PCA<br /></li>
<li>kernel PCA<br /></li>
</ul></li>
<li>SVD: Singular value decomposition，降低原來features matrix的rank，使原來的matrix可以分解成數個較小rank的matrix。<br /></li>
<li>Random projection<br /></li>
<li>PCA<br /></li>
</ul>

<div id="org69dbba1" class="figure">
<p><img src="images/PCA.jpg" alt="PCA.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 15: </span>PCA</p>
</div>
</div>
</li>
<li><a id="org068b655"></a>Nonlinear dimensionality reduction<br />
<div class="outline-text-5" id="text-5-2-2-2">
<ul class="org-ul">
<li>Isomap<br /></li>
<li>t-SNE: t-distributed stochastic neighbor embedding<br /></li>
<li>Dictionary learning<br /></li>
<li>ICA: Independent component analysis<br /></li>
<li>LDA: Latent Dirichlet allocation<br /></li>
<li>MDS: Multidimensional scaling<br /></li>
<li>LLE: Locally linear embedding<br /></li>
</ul>
</div>
</li>
<li><a id="org4c99997"></a>Dimensionality reduction<br />
<div class="outline-text-5" id="text-5-2-2-3">
<ul class="org-ul">
<li>找出原始資料裡最主要的方面來代替原始資料，使得在損失少部分原始資訊的基礎上，最大程度的降低原始資料的維度。<br /></li>
<li>維度縮減讓非監督式學習能更正確地辨識patterns，並更有效率地解決大規模資料所導致的昂貴運算問題<br /></li>
<li>降維原理<br /></li>
</ul>

<div id="orgf57e18b" class="figure">
<p><img src="images/DimensionalityReduction-1.jpg" alt="DimensionalityReduction-1.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 16: </span>基本的降維#1</p>
</div>
<ul class="org-ul">
<li>降維的選擇<br /></li>
</ul>

<div id="org14267aa" class="figure">
<p><img src="images/DimensionalityReduction-2.jpg" alt="DimensionalityReduction-2.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 17: </span>基本的降維#2</p>
</div>
</div>
</li>
</ol>
</li>
<li><a id="org981ff52"></a>face recognition 做法<br />
<div class="outline-text-4" id="text-5-2-3">
<ol class="org-ol">
<li>2D 圖形 轉 1 維向量<br /></li>
<li>經由 PCA 計算，取得主要 factor，進行降維度(projection)<br /></li>
<li>取得合理的維度，進行特徵描述<br /></li>
</ol>
</div>
</li>
</ol>
</div>

<div id="outline-container-orge47dba9" class="outline-3">
<h3 id="orge47dba9"><span class="section-number-3">5.3.</span> 強化學習(<a id="org6951646"></a>Reinforcement learning)</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>機器為了達成目標，隨著環境的變動，而逐步調整其行為，並評估每一個行動之後所到 的回饋是正向的或負向的，即，在 try-and-error 的過程中一步步從失敗中找出成功的路徑。<br /></li>
<li>較常用於以下領域：電腦遊戲、下棋、自駕車、機器人。<br /></li>
<li>AlphaGo：先以監督式學習(以人類棋譜來訓練)訓練出早期版的 AlphaGo，接下來以增強式學習兩個最期版的 AlphaGo 對奕(40 天內對奕 3000 萬盤棋)。<br /></li>
<li>2017 年的 AlphaZero 則放棄監督式學習(人類棋譜)，完全採取強化學習的模式，三天後摸索出自己的圍棋下法，成為有史以來棋力最強的版本。(不再以人類為師，所以才能超越人類？)<br /></li>
<li>Google 也將強化學習用於機房伺服器管理，持續偵測機房室內外用電、溫度、建立模型，由模型決定每台伺服器的運轉(全速、低速、休眠、關機)，並達到省電 40%的目標。<br /></li>
<li>強化學習的效果之所以優於監督式學習，主要原因是：監督式學習是人示範給電腦看，電腦照著做，但如果人做的不夠好，電腦再厲害也無法超越(例如，醫師給的 X 光片在判讀上本身就出現誤解 )；而強化學習則是在做中學，進一步脫離人的指導(或人類的經驗限制)，自行發展出更好的規則。<br /></li>
<li>強化學習其實就是訓練一個 AI 可以通過每一次的錯誤來學習，就跟我們小時候學騎腳踏車一樣，一開始學的時候會一直跌倒，然後經過幾次的失敗後，我們就可以上手也不會跌倒了<sup><a id="fnr.1.100" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>。強化學習在過去曾被長期忽視，但在 Google DeepMind 成功將其應用來玩 Atari 遊戲後，就開始受到許多關注。<br /></li>
<li>強化學習的目標在於開發一個系統（或代理人，agent）,他會藉由與環境的互動來改進自身的效能。由於當前的環境狀態資訊通常就包含了所謂「奬勵信號」(reward signal)，強化學習的目的就是找到一個最好的 Policy(策略)，可以讓 reward 最多。所以也可以把「強化學習」視為與「監督式學習」相關聯的領域，然而在強化學習中，環境回饋不能視為真實正的事實（或是說，正確的標籤），只能將之視為：測量函數對特定行動所觀測到並回報的一個度量值。如圖<a href="#org0764582">18</a>，Agent<br /></li>
<li>最常見的應用是教機器如何「玩遊戲」，在這種情境下，我們不會對某個動作貼標籤說它是「好」或「壞」，而是根據遊戲的結果（輸或是贏）或是遊戲中的信號（得分或失分）來做為回饋。<br /></li>
</ul>


<div id="org0764582" class="figure">
<p><img src="ReinforcementLearning.png" alt="ReinforcementLearning.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 18: </span>強化學習流程圖</p>
</div>
</div>
<ol class="org-ol">
<li><a id="org1fdded9"></a>範例<br />
<div class="outline-text-4" id="text-5-3-1">
<p>
典型的 reinforcement learning 包括<br />
</p>
<ul class="org-ul">
<li>DQN<br /></li>
<li>q-learning<br /></li>
</ul>
</div>
</li>
<li><a id="org1c205b7"></a>Flappy bird: 在這個遊戲中，我們需要簡單的點擊操作來控制小鳥，躲過各種水管，飛的越遠越好，因為飛的越遠就能獲得更高的積分獎勵。這就是一個典型的強化學習場景：<br />
<div class="outline-text-4" id="text-5-3-2">
<ul class="org-ul">
<li>機器有一個明確的小鳥角色——代理<br /></li>
<li>需要控制小鳥飛的更遠——目標<br /></li>
<li>整個遊戲過程中需要躲避各種水管——環境<br /></li>
<li>躲避水管的方法是讓小鳥用力飛一下——行動<br /></li>
<li>飛的越遠，就會獲得越多的積分——獎勵<br /></li>
</ul>

<div id="orge25ec59" class="figure">
<p><img src="images/ReinforceLearningGame.jpg" alt="ReinforceLearningGame.jpg" /><br />
</p>
<p><span class="figure-number">Figure 19: </span>強化學習流程圖</p>
</div>
</div>
</li>
</ol>
</div>

<div id="outline-container-org712b5aa" class="outline-3">
<h3 id="org712b5aa"><span class="section-number-3">5.4.</span> 自監督式學習(Self-supervised learning)</h3>
<div class="outline-text-3" id="text-5-4">
<p>
這是監督式學習的特例，是一種沒有人工標註標籤的監督式學習，它們的標籤是從輸入資料自己生成的，通常是使用啟發式演算法(heuristic algorithm)。例如：自動編碼器(autoencoders)，它生成的標籤是從未經修改的輸入資料取得的，同樣的，從影片之前的影像來預測下一幅影格(frame)、從文章之前的字詞來預測下一個字詞等，都是這類應用。<br />
</p>

<p>
Yann Lecun 在 IJCAI 2018 上的演講中提及自監督學習的特色在於能通過輸入的某一部分預測其它部分。在空間層面上包括圖像補全、圖像變換等，在時間層面上包括時序數據預測、視頻幀預測等。Yann LeCun 總結了三類學習範式，分別是強化學習、監督學習和自監督學習，相比於強化學習和監督學習，自監督學習將輸入和輸出當成完整的整體。它們的區別和聯繫在於反饋信息的逐漸增多，模型表徵複雜度、適用任務類型也大幅增加，同時任務中涉及的人類工程比重也大大減少，意味著自動化程度的增加。<br />
</p>

<p>
在這場演講中，LeCun 認為機器學習的未來不會是監督學習，當然也不會純粹是強化學習，它應該是包含了深度模塊的自監督學習。那麼下一個問題是，自監督學習能夠產生一般的背景知識嗎？這裡重點是模型需要推斷出背景知識，它需要從真實世界收集的背景知識推理出當前它希望預測的任務。如下 LeCun 舉了一個例子，如果接收到一個自然語句，模型應該推斷出當前場景的各種背景知識。對於基於模型的經典最優控制，我們可能需要初始化一個序列來模擬世界，並通過梯度下降調整控制序列來最優化目標函數。而目前我們可以通過強化學習的方式模擬世界，這些模型不僅需要預測下一個可能的動作，同時還需要預測一系列可能的未來。<br />
</p>

<p>
(原文網址：<a href="https://kknews.cc/tech/2lryvjz.html">https://kknews.cc/tech/2lryvjz.html</a>)<br />
</p>
</div>
</div>

<div id="outline-container-org7de209e" class="outline-3">
<h3 id="org7de209e"><span class="section-number-3">5.5.</span> <a href="Deeplearning.html">深度學習</a> v.s.強化學習</h3>
<div class="outline-text-3" id="text-5-5">
<p>
深度學習：Deep Learning,是一種機器學習的技術，由於深度學習在現代機器學習中的比重和價值非常巨大，因此常常將深度學習單獨拿出來說。最初的深度學習網絡是利用神經網絡來解決特徵層分佈的一種學習過程。通常我們瞭解的 DNN（深度神經網絡），CNN（卷積神經網絡），RNN（循環神經網絡），LSTM（長短期記憶網絡）都是隸屬於深度學習的範疇。也是現代機器學習最常用的一些手段。通過這些手段，深度學習在視覺識別，語音識別，自然語言處理（NLP）等領域取得了使用傳統機器學習算法所無法取得的成就。<br />
</p>

<p>
強化學習：<a href="#org0eed2a3">8.2</a>，又稱再勵學習或者評價學習。也是機器學習的技術之一。所謂強化學習就是智能系統從環境到行為映射的學習，以使獎勵信號（強化信號）函數值最大，由於外部給出的信息很少，強化學習系統必須依靠自身的經歷進行自我學習。通過這種學習獲取知識，改進行動方案以適應環境。強化學習最關鍵的三個因素是狀態，行為和環境獎勵。關於強化學習和深度學習的實例，最典型的莫過於谷歌的 AlphaGo 和 AlphaZero 兩位了，前者通過深度學習中的深度卷積神經網絡，在訓練了大約三千萬組人類的下棋數據，無數度電的情況下才搞出來的模型，而後者使用強化學習的方式，通過自己和自己下棋的方式搞出來的模型。而最終的實驗結果也很讓人震撼。AlphaGo 干敗了人類圍棋頂尖高手,而 AlphaZero 干敗了 AlphaGo.<br />
</p>

<p>
(原文網址：<a href="https://kknews.cc/tech/xln95b8.html">https://kknews.cc/tech/xln95b8.html</a>)<br />
</p>
</div>
</div>

<div id="outline-container-org72eeb7b" class="outline-3">
<h3 id="org72eeb7b"><span class="section-number-3">5.6.</span> Batch and Online Learning<sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup></h3>
<div class="outline-text-3" id="text-5-6">
</div>
<ol class="org-ol">
<li><a id="org8eeea55"></a>Batch learning: In <i>batch learning</i>, the system is incapable of learning incrementally; it must be trained using all the available data.<br /></li>
<li><a id="orga01be7f"></a>Online learning:<br />
<div class="outline-text-4" id="text-5-6-2">
<ul class="org-ul">
<li>In <i>online learning</i>, you train the system incrementally by feeding it data instances sequentially, either individually or in small groups called <i>mini-batches</i>.<br /></li>
<li>Online learning is great for systems that receive data as a continuous flow (e.g., stock prices) and need to adapt to change rapidly or autonomously.<br /></li>
<li>Online learning algorithms can also be used to train systems on huge datasets that cannot fit in one machine&rsquo;s main memory (this is called <i>out-of-core</i> learning).<br /></li>
</ul>
</div>
</li>
</ol>
</div>

<div id="outline-container-org2c71afd" class="outline-3">
<h3 id="org2c71afd"><span class="section-number-3">5.7.</span> Instance-Based Versus model-Based Learning<sup><a id="fnr.5.100" class="footref" href="#fn.5" role="doc-backlink">5</a></sup></h3>
<div class="outline-text-3" id="text-5-7">
</div>
<ol class="org-ol">
<li><a id="org901e689"></a>Instance-based learning: the system learns the examples by heart, then generalizes to new cases by using a similarity measure to compare them the the learned examples.<br />
<div class="outline-text-4" id="text-5-7-1">
<ul class="org-ul">
<li>以垃圾郵件偵測為例，早期做法是由使用者將特定寄件人設定為垃圾來源，之後將同一寄件者寄出之郵件全標為垃圾；<br /></li>
<li>而 AI 的做法則是可以找出與現有被標為垃圾郵件十分「相似」的郵件，也將之標為垃圾郵件。<br /></li>
<li>重點在於相似性的計算<br /></li>
</ul>
</div>
</li>
<li><a id="orgb661298"></a>Model-based learning: Another way to generalize from a set of examples is to build a model of these examples and then use that model to make <i>predictions</i>.<br />
<div class="outline-text-4" id="text-5-7-2">
<ul class="org-ul">
<li>例，以 linear model 來預測人圴生產總值與該國人民滿意度的關係：<br />
<ol class="org-ol">
<li>model selection: decide to select what kind of model: \[lifeSatisfaction = \theta_0 + \theta_1 \times GDP \]<br /></li>
<li>define parameter value: how do you know which vsalues (\[\theta_0, \theta_1\]) will make your model perform best?<br /></li>
<li>evaluate model performance: you can either define a utility function (or <i>fitness function</i>) that measures how <i>good</i> your model is, or you can define a <i>cost function</i> that measures how <i>bad</i> it is.<br /></li>
</ol></li>
</ul>

<div id="org195b19a" class="figure">
<p><img src="images/GDP.jpg" alt="GDP.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 20: </span>The linear model that fits the training data best</p>
</div>
<ul class="org-ul">
<li>CODE<br /></li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Download the data</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> urllib.request
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> os
<span class="linenr"> 4: </span><span style="color: #dcaeea;">datapath</span> = os.path.join(<span style="color: #98be65;">"datasets"</span>, <span style="color: #98be65;">"lifesat"</span>, <span style="color: #98be65;">""</span>)
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">prepare_country_stats</span>(oecd_bli, gdp_per_capita):
<span class="linenr"> 7: </span>    <span style="color: #dcaeea;">oecd_bli</span> = oecd_bli[oecd_bli[<span style="color: #98be65;">"INEQUALITY"</span>]==<span style="color: #98be65;">"TOT"</span>]
<span class="linenr"> 8: </span>    oecd_bli = oecd_bli.pivot(index=<span style="color: #98be65;">"Country"</span>, columns=<span style="color: #98be65;">"Indicator"</span>, values=<span style="color: #98be65;">"Value"</span>)
<span class="linenr"> 9: </span>    gdp_per_capita.rename(columns={<span style="color: #98be65;">"2015"</span>: <span style="color: #98be65;">"GDP per capita"</span>}, inplace=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">10: </span>    gdp_per_capita.set_index(<span style="color: #98be65;">"Country"</span>, inplace=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">11: </span>    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,
<span class="linenr">12: </span>                                  left_index=<span style="color: #a9a1e1;">True</span>, right_index=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">13: </span>    full_country_stats.sort_values(by=<span style="color: #98be65;">"GDP per capita"</span>, inplace=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">14: </span>    remove_indices = [<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">6</span>, <span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">33</span>, <span style="color: #da8548; font-weight: bold;">34</span>, <span style="color: #da8548; font-weight: bold;">35</span>]
<span class="linenr">15: </span>    keep_indices = <span style="color: #c678dd;">list</span>(<span style="color: #c678dd;">set</span>(<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">36</span>)) - <span style="color: #c678dd;">set</span>(remove_indices))
<span class="linenr">16: </span>    <span style="color: #51afef;">return</span> full_country_stats[[<span style="color: #98be65;">"GDP per capita"</span>, <span style="color: #98be65;">'Life satisfaction'</span>]].iloc[keep_indices]
<span class="linenr">17: </span>
<span class="linenr">18: </span>DOWNLOAD_ROOT = <span style="color: #98be65;">"https://raw.githubusercontent.com/ageron/handson-ml2/master/"</span>
<span class="linenr">19: </span>os.makedirs(datapath, exist_ok=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">20: </span><span style="color: #51afef;">for</span> filename <span style="color: #51afef;">in</span> (<span style="color: #98be65;">"oecd_bli_2015.csv"</span>, <span style="color: #98be65;">"gdp_per_capita.csv"</span>):
<span class="linenr">21: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Downloading"</span>, filename)
<span class="linenr">22: </span>    url = DOWNLOAD_ROOT + <span style="color: #98be65;">"datasets/lifesat/"</span> + filename
<span class="linenr">23: </span>    urllib.request.urlretrieve(url, datapath + filename)
<span class="linenr">24: </span>
<span class="linenr">25: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">26: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">27: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr">28: </span><span style="color: #51afef;">import</span> sklearn.linear_model
<span class="linenr">29: </span>
<span class="linenr">30: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Load the data</span>
<span class="linenr">31: </span>oecd_bli = pd.read_csv(<span style="color: #98be65;">"./datasets/lifesat/oecd_bli_2015.csv"</span>, thousands=<span style="color: #98be65;">','</span>)
<span class="linenr">32: </span>gdp_per_capita = pd.read_csv(<span style="color: #98be65;">"./datasets/lifesat/gdp_per_capita.csv"</span>,thousands=<span style="color: #98be65;">','</span>,delimiter=<span style="color: #98be65;">'\t'</span>, encoding=<span style="color: #98be65;">'latin1'</span>, na_values=<span style="color: #98be65;">"n/a"</span>)
<span class="linenr">33: </span>
<span class="linenr">34: </span>
<span class="linenr">35: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Prepare the data</span>
<span class="linenr">36: </span>country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)
<span class="linenr">37: </span>X = np.c_[country_stats[<span style="color: #98be65;">"GDP per capita"</span>]]
<span class="linenr">38: </span>y = np.c_[country_stats[<span style="color: #98be65;">"Life satisfaction"</span>]]
<span class="linenr">39: </span>
<span class="linenr">40: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Visualize the data</span>
<span class="linenr">41: </span>plt.clf()
<span class="linenr">42: </span>
<span class="linenr">43: </span>country_stats.plot(kind=<span style="color: #98be65;">'scatter'</span>, x=<span style="color: #98be65;">"GDP per capita"</span>, y=<span style="color: #98be65;">'Life satisfaction'</span>)
<span class="linenr">44: </span><span style="color: #51afef;">import</span> matplotlib <span style="color: #51afef;">as</span> mpl
<span class="linenr">45: </span>mpl.rc(<span style="color: #98be65;">'axes'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">14</span>)
<span class="linenr">46: </span>mpl.rc(<span style="color: #98be65;">'xtick'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">12</span>)
<span class="linenr">47: </span>mpl.rc(<span style="color: #98be65;">'ytick'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">12</span>)
<span class="linenr">48: </span>plt.plot()
<span class="linenr">49: </span>
<span class="linenr">50: </span>plt.savefig(<span style="color: #98be65;">"images/GDP.png"</span>)
<span class="linenr">51: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Select a linear model</span>
<span class="linenr">52: </span>model = sklearn.linear_model.LinearRegression()
<span class="linenr">53: </span>
<span class="linenr">54: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Train the model</span>
<span class="linenr">55: </span>model.fit(X, y)
<span class="linenr">56: </span>
<span class="linenr">57: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Make a prediction for Cyprus</span>
<span class="linenr">58: </span>X_new = [[<span style="color: #da8548; font-weight: bold;">22587</span>]]  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Cyprus's GDP per capita</span>
<span class="linenr">59: </span><span style="color: #c678dd;">print</span>(model.predict(X_new)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">outputs [[ 5.96242338]]</span>
<span class="linenr">60: </span>
</pre>
</div>

<pre class="example">
Downloading oecd_bli_2015.csv
Downloading gdp_per_capita.csv
[[5.96242338]]
</pre>


<div id="org632b08e" class="figure">
<p><img src="images/GDP.png" alt="GDP.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 21: </span>The linear model that fits the training data best</p>
</div>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org1b1e555" class="outline-2">
<h2 id="org1b1e555"><span class="section-number-2">6.</span> Data Representations</h2>
<div class="outline-text-2" id="text-6">
<p>
How can we represent data (images, text, user preferences, etc.) in a way that computers can understand? -&gt; Organize information into a vector<sup><a id="fnr.2.100" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>.<br />
</p>
<ul class="org-ul">
<li>A vector is a 1-dimensional array of numbers. It has both a magnitude(length) and a direction.<br /></li>
<li><p>
A feature vector is a vector whose entries represent the &ldquo;features&rdquo; of some object.<br />
</p>

<div id="org02a0f0a" class="figure">
<p><img src="images/feature-vector.jpg" alt="feature-vector.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 22: </span>Feature Vector</p>
</div></li>
</ul>
</div>
<div id="outline-container-orgfca56e5" class="outline-3">
<h3 id="orgfca56e5"><span class="section-number-3">6.1.</span> Images</h3>
<div class="outline-text-3" id="text-6-1">
<p>
In black and white images, <b>black and white pixels</b> correspond to 0s and 1s. Grayscale pixels are numbers between 0 and 255. Both assemble into a 1-dimensional array of numbers.<br />
</p>

<div id="org10ca9b2" class="figure">
<p><img src="images/image-data-rep.jpg" alt="image-data-rep.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 23: </span>Image data representations</p>
</div>
</div>
</div>
<div id="outline-container-org56d9abc" class="outline-3">
<h3 id="org56d9abc"><span class="section-number-3">6.2.</span> Words and Documents</h3>
<div class="outline-text-3" id="text-6-2">
<p>
Given a collection of doucments (e.g. Wikipedia articles), assign to every word a vector whose \(i^{th}\) entry is the number of times the word appears in the \(i^{th}\) document.<br />
</p>
<p width="500">
<img src="images/word-rep.jpg" alt="word-rep.jpg" width="500" /><br />
These vectors can assemble into a large matrix, useful for <b>latent semantic analysis</b>.<br />
</p>
</div>
</div>
<div id="outline-container-org10fa79f" class="outline-3">
<h3 id="org10fa79f"><span class="section-number-3">6.3.</span> Yes/No or Ratings</h3>
<div class="outline-text-3" id="text-6-3">
<p>
Given users and items (e.g. movies), vectors can indicate if a user has interacted with the item (1=yes, 0=no) or the user&rsquo;s ratings, say a number between 0 and 5.<br />
</p>

<div id="org09e99ed" class="figure">
<p><img src="images/yn-rep.jpg" alt="yn-rep.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 24: </span>Y/N or Ratings</p>
</div>
</div>
</div>
<div id="outline-container-org066bff0" class="outline-3">
<h3 id="org066bff0"><span class="section-number-3">6.4.</span> One-Hot Encodings</h3>
<div class="outline-text-3" id="text-6-4">
<p>
Assign to each word a vector with one 1 and 0s elsewhere. This is called a one-hot encoding (or a &ldquo;standard basis vector&rdquo;). For example, suppose our language only has four words:<br />
</p>

<div id="orgfb144af" class="figure">
<p><img src="images/word-one-hot.jpg" alt="word-one-hot.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 25: </span>words one-hot encoding</p>
</div>
</div>
<ol class="org-ol">
<li><a id="org3e4926f"></a>drawbacks to consider:<br />
<ol class="org-ol">
<li><a id="orge732a44"></a>These vectors can be very sparse<br />
<div class="outline-text-5" id="text-6-4-1-1">
<ul class="org-ul">
<li>A &ldquo;sparse&rdquo; vector is one with lots of zeros<br /></li>
<li>500,000 users and 1,000,000 movies<br /></li>
</ul>
</div>
</li>
<li><a id="orga410563"></a>Possible lack lf <b>meaningful relationships between</b> vectors<br />
<div class="outline-text-5" id="text-6-4-1-2">
<ul class="org-ul">
<li>One-hot encodings are never &ldquo;similar.&rdquo;<br /></li>
<li>Similarity is measured by the <b>dot product.</b><br /></li>
</ul>
</div>
</li>
</ol>
</li>
</ol>
</div>
</div>

<div id="outline-container-org0d11844" class="outline-2">
<h2 id="org0d11844"><span class="section-number-2">7.</span> 機器學習的主要挑戰<sup><a id="fnr.5.100" class="footref" href="#fn.5" role="doc-backlink">5</a></sup></h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org58a7619" class="outline-3">
<h3 id="org58a7619"><span class="section-number-3">7.1.</span> Insufficient quantity of training data</h3>
<div class="outline-text-3" id="text-7-1">
<p>
Even for very simple problems you typically need thousands of examples, and for complex problems such as image or speech recognition you may need millions of examples. The idea that data matters more than algorithms for complex problems was further popularized by Peter norvig et al. in a paper titled &ldquo;The Unreasonable Effectiveness of Data&rdquo;, published in 2009.<br />
</p>
</div>
</div>

<div id="outline-container-orgf08f8fc" class="outline-3">
<h3 id="orgf08f8fc"><span class="section-number-3">7.2.</span> Nonrepresentative training data</h3>
<div class="outline-text-3" id="text-7-2">
<ul class="org-ul">
<li>In order to generalize well, it is crucial that your training data be representative of the new cases you want to generalize to.<br /></li>
<li>Perhaps the most famous example of sampling bias happened during the US presidential election in 1936, which pitted Landon against Roosevelt: the <i>Literary Digest</i> conducted a very large poll, sending mail to about 10 million people. The flaw was in the <i>Literary Digest&rsquo;s</i> sampling method:<br />
<ol class="org-ol">
<li>First, to obtain the addresses to send the polls to, the <i>Literary Digest</i> use telephone directories, lists of magazine subscribers, club membership lists, and the like.<br /></li>
<li>Second, less than 25% of the people who were polled answered.<br /></li>
</ol></li>
</ul>

<div id="org10bc9f1" class="figure">
<p><img src="images/GDP2.jpg" alt="GDP2.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 26: </span>加入更多資料會使 modle 更具代表性</p>
</div>
</div>
</div>

<div id="outline-container-orgc19f64b" class="outline-3">
<h3 id="orgc19f64b"><span class="section-number-3">7.3.</span> Poor-quality data</h3>
<div class="outline-text-3" id="text-7-3">
<p>
Obviously, if your training data is full of errors, outliers, and noise (e.g., due to poor-quality measurements), it will make it harder for the system to detect the underlying patterns, so your system is less likely to perform well.<br />
</p>
</div>
</div>

<div id="outline-container-org54546d6" class="outline-3">
<h3 id="org54546d6"><span class="section-number-3">7.4.</span> Irrelevant features</h3>
</div>

<div id="outline-container-orgb1a990c" class="outline-3">
<h3 id="orgb1a990c"><span class="section-number-3">7.5.</span> Overfitting the training data</h3>
<div class="outline-text-3" id="text-7-5">
<ul class="org-ul">
<li>Overfitting happens when the model is too complex relative to the amount and noisiness of the training data. Here are possible solutions:<br />
<ol class="org-ol">
<li>Simplify the model by selecting one with fewer parameters.<br /></li>
<li>Gather more training data.<br /></li>
<li>Reduce the noise in the training data (e.g., fix data errors and remove outliers).<br /></li>
</ol></li>
<li>Constraining a model to make it simpler and reduce the risk of overfitting is called <i>regularization</i>.<br /></li>
<li>The amount of regularization to apply during learning can be controlled by a <i>hyperparameter</i>. A hyperparameter is a parameter of a learning algorithm (not of the model).<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org753bf9a" class="outline-3">
<h3 id="org753bf9a"><span class="section-number-3">7.6.</span> Underfitting the training data</h3>
<div class="outline-text-3" id="text-7-6">
<p>
Underfitting occurs when your model is too simple to learn the underlying structure of the data.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgb7d330f" class="outline-2">
<h2 id="orgb7d330f"><span class="section-number-2">8.</span> Machine Learning 的基本類型</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-orged13efe" class="outline-3">
<h3 id="orged13efe"><span class="section-number-3">8.1.</span> Nonlinear Models 非線性模型</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<ol class="org-ol">
<li><a id="orge4c4ebe"></a>常用的 Nonlinear Models<br />
<ol class="org-ol">
<li><a id="org562fb0f"></a>Supervised Learning<br />
<div class="outline-text-5" id="text-8-1-1-1">
<ul class="org-ul">
<li>Decision tree<br /></li>
<li>Ensemble models: Random forest, XGBoost<br /></li>
<li>Neural network<br /></li>
</ul>
</div>
</li>
<li><a id="org10e784e"></a>Unsupervised Learning<br />
<div class="outline-text-5" id="text-8-1-1-2">
<ul class="org-ul">
<li>tSNE(t-Distributed Stochastic Neighbor Embedding)<br /></li>
</ul>
</div>
</li>
</ol>
</li>
<li><a id="orgeb3b190"></a>Decision Tree<br />
<ol class="org-ol">
<li><a id="orgda58e3f"></a>example: <a href="https://en.akinator.com">https://en.akinator.com</a><br /></li>
<li><a id="org3dc2b10"></a>要定義很多 rule 才能把 tree 建起來<br /></li>
</ol>
</li>
<li><a id="org4c39c7f"></a>Ensemble Models<br />
<ol class="org-ol">
<li><a id="org0490829"></a>用多棵樹來決定，做法為<br />
<div class="outline-text-5" id="text-8-1-3-1">
<ol class="org-ol">
<li>Get a set of classifiers, f1(x),f2(x),f3(x),&#x2026;<br /></li>
<li>Aggregate the classifiers (properly)<br /></li>
</ol>
</div>
</li>
</ol>
</li>
<li><a id="orgfb08fa5"></a>選取 model 的考量<br />
<div class="outline-text-4" id="text-8-1-4">
<ul class="org-ul">
<li>Bias v.s. Variance<br /></li>
<li>Error from bias<br /></li>
<li>Error from variance<br /></li>
<li>Error observed<br /></li>
<li>underfitting v.s. overfitting<br />
overfitting: 完全符合 training data, 但 testing data 效果很差<br /></li>
</ul>
</div>
</li>
<li><a id="orgbd0735d"></a>Bagging<br />
<ol class="org-ol">
<li><a id="org57ad6cc"></a>This approach would be helpful when your model is complex, easy to overfit.<br /></li>
<li><a id="org24321ae"></a>適用系統:<br />
<div class="outline-text-5" id="text-8-1-5-2">
<ul class="org-ul">
<li>decision tree: 只要樹夠深，可以 train 到 100%，但是對新進來的資料完全無用，即 overfitting<br /></li>
</ul>
</div>
</li>
<li><a id="org73f0cb2"></a>Random Forest<br />
<div class="outline-text-5" id="text-8-1-5-3">
<ul class="org-ul">
<li>將 decision tree 應用到 bagging 的方式<br /></li>
<li>做法：每次從 M 個特徵抽出 m 個來建 decision tree<br /></li>
</ul>
</div>
</li>
</ol>
</li>
<li><a id="org236a692"></a>XGBoost<br />
<ol class="org-ol">
<li><a id="org28c5afc"></a>eXtreme Gradient Boosting<br /></li>
<li><a id="org2d9f022"></a>Kaggle 機器學習競賽常用 solution<br /></li>
<li><a id="org08cc257"></a>為一種集思廣益的策略<br />
<div class="outline-text-5" id="text-8-1-6-3">
<ul class="org-ul">
<li>hello \[E=mc^2\]<br /></li>
<li>test<br /></li>
</ul>
</div>
</li>
<li><a id="org169ab92"></a>一次一次加入一棵新的 tree,每加一棵新 tree 都要讓 loss 降低<br /></li>
</ol>
</li>
<li><a id="orgac32501"></a>CNN<br />
<ol class="org-ol">
<li><a id="org883380b"></a>目的在減少類神經網路每一個 layer 的 feature 數量，以減化連結複雜度<br /></li>
<li><a id="orgd6f56d9"></a>CNN 主要用來處理圖片: A neuron does not have to see the whole image to discover the pattern.<br /></li>
</ol>
</li>
<li><a id="org5c9d47a"></a>CNN in Keras<br /></li>
</ol>
</div>

<div id="outline-container-org0eed2a3" class="outline-3">
<h3 id="org0eed2a3"><span class="section-number-3">8.2.</span> Reinforcement Learning</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<ol class="org-ol">
<li><a id="org4eb6b38"></a>談機器與環境之間的互動，如圍棋、走迷宮、玩遊戲<br /></li>
<li><a id="orgb140601"></a>監督式學習 v.s. 增強式學習<br />
<ol class="org-ol">
<li><a id="orgd4d9673"></a>監督式學習會有一個 tutor 或判斷依據，以圍棋來說是有一個棋譜<br /></li>
<li><a id="orgfd64670"></a>增強式學習沒有依據，完全從行為的經驗去自行判斷，以 alpha-go 為例，是以兩台 alpha-go 多次互相對奕來訓練，用這種方式的好處是可以生成大量資料<br /></li>
<li><a id="orga2eedab"></a>Reinforcement Learning 的應用實例<br />
<div class="outline-text-5" id="text-8-2-2-3">
<ul class="org-ul">
<li>開直升機<br /></li>
<li>玩賽車<br /></li>
<li>打 GAME<br /></li>
</ul>
</div>
</li>
</ol>
</li>
<li><a id="orgd608bc8"></a>Reinforcement Learning 的性質<br />
<ol class="org-ol">
<li><a id="org6be2475"></a>Reward delay<br />
<ol class="org-ol">
<li><a id="orgdb19018"></a>space invader: 只有 fire 才有 reward<br /></li>
</ol>
</li>
<li><a id="org893738d"></a>機器人的行為會影響後續&#x2026;..<br /></li>
</ol>
</li>
<li><a id="orge8c9867"></a>Critic 是評估 actor 的方式<br /></li>
<li><a id="org58dd0f8"></a>How to estimate V<br />
<div class="outline-text-4" id="text-8-2-5">
<ol class="org-ol">
<li>Monte-Carlo based approach<br /></li>
<li>Temporal-difference approach<br /></li>
</ol>
</div>
</li>
<li><a id="org55ecaa2"></a>Asynchronous: A3C<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org4553425" class="outline-2">
<h2 id="org4553425"><span class="section-number-2">9.</span> Classfication</h2>
<div class="outline-text-2" id="text-9">
<p>
兩步驟<br />
</p>
</div>
<div id="outline-container-org06b4329" class="outline-3">
<h3 id="org06b4329"><span class="section-number-3">9.1.</span> Model construction: describing a set of predetermined classes</h3>
<div class="outline-text-3" id="text-9-1">
<ul class="org-ul">
<li>Each tuple/sample is assumed to belong to a predefined class, as determined by the class label attribute<br /></li>
<li>The set of tuples used for model construction is training set<br /></li>
<li>The model is represented as classfication urles, decision trees, or mathematical formulae.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org06589c9" class="outline-3">
<h3 id="org06589c9"><span class="section-number-3">9.2.</span> Model usage: for classifying future or unknown objects</h3>
<div class="outline-text-3" id="text-9-2">
<ul class="org-ul">
<li>Estimate accuracy of the model<br />
<ul class="org-ul">
<li>The Known label of test sample is compared with the classified result from the model<br /></li>
<li>Accuracy rate is the percentage of test set samples that are conrrectly classified by the model<br /></li>
<li>Test set is independent of training set (otherwise overfitting)<br /></li>
</ul></li>
<li>If the test set is used to select models, it is called validation (set) set.<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgb785fba" class="outline-2">
<h2 id="orgb785fba"><span class="section-number-2">10.</span> 學習資源</h2>
<div class="outline-text-2" id="text-10">
</div>
<div id="outline-container-org94fcb42" class="outline-3">
<h3 id="org94fcb42"><span class="section-number-3">10.1.</span> Machine Learning [台大李宏毅]</h3>
<div class="outline-text-3" id="text-10-1">
</div>
<ol class="org-ol">
<li><a id="org114ec9b"></a>Lecture 0<br />
<div class="outline-text-4" id="text-10-1-1">
<ul class="org-ul">
<li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html">ML19: 台大機器學習課程大綱</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=CXgbekl66jc">ML Lecture 0-1: Introduction of Machine Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=On1N8u1z2Ng">ML Lecture 0-2: Why we need to learn machine learning?</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgd2abdc3"></a>Lecture 1<br />
<div class="outline-text-4" id="text-10-1-2">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fegAeph9UaA">ML Lecture 1: Regression - Case Study</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1UqCjFQiiy0">ML Lecture 1: Regression - Demo</a><br /></li>
</ul>
</div>
</li>
<li><a id="org88ba9bd"></a>Lecture 2<br />
<div class="outline-text-4" id="text-10-1-3">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=D_S6y0Jm6dQ">ML Lecture 2: Where does the error come from?</a><br /></li>
</ul>
</div>
</li>
<li><a id="org9c8c77c"></a>Lecture 3<br />
<div class="outline-text-4" id="text-10-1-4">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=yKKNr-QKz2Q">ML Lecture 3-1: Gradient Descent</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1_HBTJyWgNA">ML Lecture 3-2: Gradient Descent (Demo by AOE)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=wzPAInDF_gI">ML Lecture 3-3: Gradient Descent (Demo by Minecraft)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org197287d"></a>Lecture 4<br />
<div class="outline-text-4" id="text-10-1-5">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fZAZUYEeIMg">ML Lecture 4: Classification</a><br /></li>
</ul>
</div>
</li>
<li><a id="org537cc09"></a>Lecture 5<br />
<div class="outline-text-4" id="text-10-1-6">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=hSXFuypLukA">ML Lecture 5: Logistic Regression</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgb53f75b"></a>Lecture 6<br />
<div class="outline-text-4" id="text-10-1-7">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Dr-WRlEFefw">ML Lecture 6: Brief Introduction of Deep Learning</a><br /></li>
</ul>
</div>
</li>
<li><a id="org4139ec7"></a>Lecture 7<br />
<div class="outline-text-4" id="text-10-1-8">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=ibJpTrp5mcE">ML Lecture 7: Backpropagation</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=gDp2LXGnVLQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=3&amp;t=0s">Anomaly Detection (1/7)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4">Next Step of Machine Learning (Hung-yi Lee, NTU, 2019)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org1f94993"></a>Lecture 8<br />
<div class="outline-text-4" id="text-10-1-9">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Lx3l4lOrquw">ML Lecture 8-1: “Hello world” of deep learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=5BJDJd-dzzg">ML Lecture 8-2: Keras 2.0</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=L8unuZNpWw8">ML Lecture 8-3: Keras Demo</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgaae4659"></a>Explainable ML<br />
<div class="outline-text-4" id="text-10-1-10">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=lnjrn3bF9lA">Explainable ML (1/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&amp;list=PL9McrqOpq3mUCXF5E8rVLjw8f878zkBfX&amp;index=16">Explainable ML (2/8)</a><br /></li>
<li>Explainable ML (3/8)<br /></li>
<li><a href="https://www.youtube.com/watch?v=yORbWn7UsBs">Explainable ML (4/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (5/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=K1mWgthGS-A">Explainable ML (6/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (7/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Explainable ML (8/8)</a><br /></li>
</ol>
</div>
</li>
<li><a id="org1b66712"></a><span class="todo TODO">TODO</span> Attack ML Models<br />
<div class="outline-text-4" id="text-10-1-11">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=NI6yb0WgMBM">Attack ML Models (1/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=zOdg05BwE7I">Attack ML Models (2/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=F9N5zF7N0qY">Attack ML Models (3/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ">Attack ML Models (4/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=2mgLPZJOHNk">Attack ML Models (5/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=z2nmPDLEXI0">Attack ML Models (6/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=KH48zq2RfBA&amp;t=1s">Attack ML Models (7/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Attack ML Models (8/8)</a><br /></li>
</ol>
</div>
</li>
<li><a id="org30c5afd"></a>Lecture 9<br />
<div class="outline-text-4" id="text-10-1-12">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=xki61j7z-30">ML Lecture 9-1: Tips for Training DNN</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Ky1ku1miDow">ML Lecture 9-2: Keras Demo 2</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=F1vek6ULo9w">ML Lecture 9-3: Fizz Buzz in Tensorflow (sequel)</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgf1c281c"></a>Lecture 10<br />
<div class="outline-text-4" id="text-10-1-13">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=FrKWiRv254g">ML Lecture 10: Convolutional Neural Network</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=XsC9byQkUH8">ML Lecture 11: Why Deep?</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=fX_guE7JNnY">ML Lecture 12: Semi-supervised</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=iwh5o_M4BNU">ML Lecture 13: Unsupervised Learning - Linear Methods</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=X7PH3NuYW0Q">ML Lecture 14: Unsupervised Learning - Word Embedding</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=GBUEjkpoxXc">ML Lecture 15: Unsupervised Learning - Neighbor Embedding</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=yyKaACh_j3M&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=45&amp;t=0s">Meta Learning – Metric-based (1/3)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Tk5B4seA-AU">ML Lecture 16: Unsupervised Learning - Auto-encoder</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=YNUek8ioAJk">ML Lecture 17: Unsupervised Learning - Deep Generative Model (Part I)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=8zomhgKrsmQ">ML Lecture 18: Unsupervised Learning - Deep Generative Model (Part II)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=48&amp;t=0s">More about Auto-encoder (1/4)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=qD6iD4TFsdQ">ML Lecture 19: Transfer Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=7qT5P9KJnWo&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=25">Life Long Learning (1/7)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ZjfjPzXw6og&amp;feature=youtu.be">Sequence-to-sequence Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=EkAqYbpCYAc&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=33&amp;t=0s">Meta Learning – MAML (1/9)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=QSEPStBgwRQ">ML Lecture 20: Support Vector Machine (SVM)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=xCGidAeyS4M">ML Lecture 21-1: Recurrent Neural Network (Part I)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=rTqmWlnwz_0">ML Lecture 21-2: Recurrent Neural Network (Part II)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=YIuBHB9Ejok&amp;feature=youtu.be">Unsupervised Syntactic Parsing (ft. 莊永松同學)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=tH9FH1DH5n0">ML Lecture 22: Ensemble</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=W8XF3ME8G2I">ML Lecture 23-1: Deep Reinforcement Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=y8UPGr36ccI">ML Lecture 23-2: Policy Gradient (Supplementary Explanation)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=2-JNBzCq77c">ML Lecture 23-3: Reinforcement Learning (including Q-learning)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_">Deep Reinforcement Learning, 2018</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=dPp8rCAnU_A&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=52&amp;t=0s">Network Compression (1/6)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ufcKFjdpT98&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58&amp;t=0s">GAN (Quick Review)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw">Generative Adversarial Network (GAN), 2018</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58">Transformer</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=UYPa347-DdE&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=62&amp;t=0s">ELMO, BERT, GPT</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=uXY18nzdSsM&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=59">Flow-based Generative Model</a><br /></li>
<li><a href="https://brohrer.mcknote.com/zh-Hant/statistics/how_bayesian_inference_works.html">貝葉斯推斷的運作原理</a><br /></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgad84254" class="outline-3">
<h3 id="orgad84254"><span class="section-number-3">10.2.</span> Digital Speech Processing</h3>
<div class="outline-text-3" id="text-10-2">
<ul class="org-ul">
<li><a href="http://ocw.aca.ntu.edu.tw/ntu-ocw/ocw/cou/104S204/1">第一章 Introduction to Digital Speech Processing  </a><br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orga73dd2a" class="outline-2">
<h2 id="orga73dd2a"><span class="section-number-2">11.</span> code references</h2>
<div class="outline-text-2" id="text-11">
<ul class="org-ul">
<li><a href="https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0">Visualizing intermediate activation in Convolutional Neural Networks with Keras</a>: 查看 training 中 image 的成像<br /></li>
</ul>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://github.com/rasbt/python-machine-learning-book-2nd-edition">python-machine-learning-book-2nd-edition</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://youtu.be/LlKAna21fLE">A friendly introduction to linear algebra for ML (ML Tech Talks)</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/zh-tw/AlphaGo_Zero">AlphaGo Zero</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/wiki/AlphaZero">AlphaZero</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/F014278520">Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems</a><br />
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2022-07-03 Sun 20:11</p>
</div>
</body>
</html>
